This file is a comprehensive codebase snapshot for the BowersWorld-com project, generated to facilitate analysis and development.

================================================================
File Summary
================================================================

Purpose:
--------
This document provides a consolidated view of the project's source code, scripts,
HTML, and text files, excluding any files specified in the .gitignore file. 
It serves as a reference for developers, making it easier to understand the 
codebase structure and functionality in a single document.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
5. List of Program files
6. List of Documents

================================================================
Directory Structure
================================================================
.
‚îú‚îÄ‚îÄ ./AGENTS.md
‚îú‚îÄ‚îÄ ./AndersonLibrary_Himalaya_GPU.csv
‚îú‚îÄ‚îÄ ./AndersonLibrary_Himalaya_GPU.xlsx
‚îú‚îÄ‚îÄ ./Assets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/arrow.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/BowersWorld.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/exit.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/hide.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/icon.png
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/icons
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Assets/library
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./Assets/Max.png
‚îú‚îÄ‚îÄ ./CLAUDE.md
‚îú‚îÄ‚îÄ ./CreateLibraryCSV
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./CreateLibraryCSV/Complete Anderson's Library Collection Analysis.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./CreateLibraryCSV/DigitalAlexandria.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./CreateLibraryCSV/Resumable PDF Metadata Extractor.py
‚îú‚îÄ‚îÄ ./CreateThumbs
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./CreateThumbs/ConvertToThumbnailsPart2.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./CreateThumbs/ConvertToThumbnails.py
‚îú‚îÄ‚îÄ ./HimalayaGPUExtractor_Protected.py
‚îú‚îÄ‚îÄ ./HIMALAYA PROGRESS REPORT.md
‚îú‚îÄ‚îÄ ./HTML
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./HTML/GoogleAuthorzeTest.html
‚îú‚îÄ‚îÄ ./index.html
‚îú‚îÄ‚îÄ ./Legacy
‚îú‚îÄ‚îÄ ./library
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/admin
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/app
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/assets
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/auth
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/auth/login.html
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./library/auth/register.html
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/css
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/index.html
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./library/js
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./library/js/GoogleDriveAuth.js
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./library/setup
‚îú‚îÄ‚îÄ ./MigrateToEnhancedSchema.py
‚îú‚îÄ‚îÄ ./README.md
‚îú‚îÄ‚îÄ ./requirements.txt
‚îú‚îÄ‚îÄ ./Scripts
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Scripts/Deployment
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Scripts/Development
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./Scripts/Development/BowersWorldSetup.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Scripts/Maintenance
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Scripts/Migration
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./Scripts/System
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/CodebaseSum.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/GitHubAutoUpdate.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/GitHubUpdateSite.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/GPU OCR Speed Test.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/ListFilesByDate.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/MarkdownToText.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/Project_Backup.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ ./Scripts/System/UpdateFiles.py
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ ./Scripts/System/update_site.bat
‚îú‚îÄ‚îÄ ./shared
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./shared/css
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./shared/css/himalaya-theme.css
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./shared/js
‚îú‚îÄ‚îÄ ./Source
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Source/AI
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Source/Core
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Source/Interface
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./Source/Plugins
‚îú‚îÄ‚îÄ ./Tests
‚îú‚îÄ‚îÄ ./Updates
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Updates/mylibrary_schema.sql
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Updates/mysql_conversion_helper.sql
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ ./Updates/next_steps_plan.md
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ ./Updates/sample_queries.sql
‚îî‚îÄ‚îÄ ./WebPages
    ‚îú‚îÄ‚îÄ ./WebPages/Components
    ‚îî‚îÄ‚îÄ ./WebPages/Templates

35 directories, 41 files

================================================================
Files
================================================================

================
File: AGENTS.md
================
# AGENTS.md - BowersWorld-com Development Guide

## Build/Test Commands
```bash
# Install dependencies
pip install -r requirements.txt

# Start development server
python DigitalAlexandria.py

# Run tests (when implemented)
pytest Tests/

# Run single test file
pytest Tests/test_specific.py

# Database operations
python DigitalAlexandria.py admin --optimize
python DigitalAlexandria.py setup --sample-data
```

## Code Style Guidelines (AIDEV-PascalCase-1.7)
- **Files/Modules**: PascalCase.py
- **Classes**: PascalCase
- **Functions/Methods**: PascalCase  
- **Variables**: PascalCase
- **Constants**: ALLCAPSWITHUNDERSCORES
- **Imports**: Standard library first, then third-party, then local imports
- **Type hints**: Required for all function parameters and returns
- **Docstrings**: Required for all classes and functions
- **Error handling**: Use try/except blocks with specific exception types

## File Headers
All Python files must include standardized headers with file path, dates, author (Herb Bowers - Project Himalaya), purpose, and AIDEV-PascalCase-1.7 compliance notation.
================
File: CLAUDE.md
================
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

**BowersWorld-com** (codename: Digital Alexandria) is a comprehensive digital library management system built with Python. The system manages Anderson's Library Collection with AI-powered classification, full-text search, and modern web interfaces.

## Key Commands

### Starting the Application
```bash
python DigitalAlexandria.py
```
Main entry point that starts the FastAPI web server on localhost:8080

### Development Setup
```bash
pip install -r requirements.txt
```
Install all required dependencies including FastAPI, SQLAlchemy, spaCy, transformers, and other ML libraries

### Data Migration
```bash
python MigrateToEnhancedSchema.py
```
Migrates existing library data to the enhanced database schema with AI classification support

### Code Quality
```bash
python -m flake8 .
python -m black .
python -m pytest
```
Standard Python linting, formatting, and testing commands (configurations may exist in project)

## Architecture

### Core Structure
- **Source/**: Main application code (currently empty directories for Core/, AI/, Interface/, Plugins/)
- **Scripts/**: Utility scripts for deployment, development, maintenance, migration, and system tasks
- **CreateLibraryCSV/**: Data processing scripts for PDF metadata extraction and library analysis
- **Data/**: Library data including Books/, Covers/, and book metadata
- **Config/**: Configuration files
- **WebPages/**: Web interface files

### Technology Stack
- **Backend**: FastAPI with Python 3.11+
- **Database**: SQLite with full-text search capabilities
- **AI/ML**: spaCy, transformers, sentence-transformers for NLP and semantic search
- **Data Processing**: pandas, PyMuPDF for PDF handling
- **Web Framework**: FastAPI (backend), planned React frontend
- **Desktop Legacy**: PySide6 for desktop interface (Andy.py)

### Key Configuration Files
- `alexandria_config.json`: Main project configuration with architecture patterns and feature flags
- `search_engine_config.json`: API endpoints and search system configuration including Open Library, Google Books APIs
- `requirements.txt`: Python dependencies with ML/AI libraries

### Data Flow
1. PDF metadata extraction via `Resumable PDF Metadata Extractor.py`
2. Library analysis through `Complete Anderson's Library Collection Analysis.py`
3. Database migration using `MigrateToEnhancedSchema.py`
4. Web interface served through `DigitalAlexandria.py`

## Important Notes

- Uses AIDEV-PascalCase-1.7/1.8 coding standard
- Includes comprehensive book metadata from Anderson's Library Collection
- Supports multiple API integrations (Open Library, Google Books, Library of Congress)
- Features AI-powered book classification and semantic search
- Plugin system architecture with hook-based extensions planned
- Multi-user collaboration features planned

## Database Schema
The system uses an enhanced SQLite schema supporting:
- Full-text search capabilities
- AI classification metadata
- Book metadata with covers and thumbnails
- User management and collaboration features
================
File: CreateLibraryCSV/Complete Anderson's Library Collection Analysis.py
================
#!/usr/bin/env python3
"""
Complete Anderson's Library Collection Analysis and LC Enhancement Preparation
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

def analyze_complete_collection():
    """Analyze the complete 1,219 PDF collection"""
    
    csv_path = "/home/herb/Desktop/BowersWorld-com/AndersonLibrary_PDFMetadata.csv"
    
    print("üìö Anderson's Library - Complete Collection Analysis")
    print("=" * 70)
    
    # Load the complete dataset
    try:
        df = pd.read_csv(csv_path)
        print(f"‚úÖ Loaded {len(df)} PDF records - COMPLETE COLLECTION!")
    except Exception as e:
        print(f"‚ùå Error loading CSV: {e}")
        return
    
    print()
    print("üéØ COLLECTION OVERVIEW:")
    print("-" * 50)
    print(f"üìö Total books: {len(df)}")
    
    # File statistics
    df['file_size_mb'] = pd.to_numeric(df['file_size_mb'], errors='coerce')
    df['page_count'] = pd.to_numeric(df['page_count'], errors='coerce')
    
    total_size_gb = df['file_size_mb'].sum() / 1024
    avg_size_mb = df['file_size_mb'].mean()
    total_pages = df['page_count'].sum()
    avg_pages = df['page_count'].mean()
    
    print(f"üíæ Total collection size: {total_size_gb:.1f} GB")
    print(f"üìÑ Average file size: {avg_size_mb:.1f} MB")
    print(f"üìñ Total pages: {total_pages:,} pages")
    print(f"üìñ Average pages per book: {avg_pages:.0f} pages")
    
    print()
    print("üìà METADATA EXTRACTION SUCCESS RATES:")
    print("-" * 50)
    
    # Calculate success rates for the complete collection
    pdf_titles = df['pdf_title'].notna() & (df['pdf_title'].str.strip() != '')
    pdf_authors = df['pdf_author'].notna() & (df['pdf_author'].str.strip() != '')
    extracted_isbns = df['extracted_isbn'].notna() & (df['extracted_isbn'].str.strip() != '')
    extracted_years = df['extracted_year'].notna()
    extracted_publishers = df['extracted_publisher'].notna() & (df['extracted_publisher'].str.strip() != '')
    
    total = len(df)
    print(f"üìñ PDF Titles: {pdf_titles.sum()}/{total} ({pdf_titles.sum()/total*100:.1f}%)")
    print(f"‚úçÔ∏è PDF Authors: {pdf_authors.sum()}/{total} ({pdf_authors.sum()/total*100:.1f}%)")
    print(f"üî¢ ISBNs: {extracted_isbns.sum()}/{total} ({extracted_isbns.sum()/total*100:.1f}%)")
    print(f"üìÖ Years: {extracted_years.sum()}/{total} ({extracted_years.sum()/total*100:.1f}%)")
    print(f"üè¢ Publishers: {extracted_publishers.sum()}/{total} ({extracted_publishers.sum()/total*100:.1f}%)")
    
    print()
    print("üìÖ PUBLICATION TIMELINE:")
    print("-" * 50)
    
    years = df['extracted_year'].dropna()
    # Filter to only numeric years (4-digit years between 1000-2100)
    numeric_years = pd.to_numeric(years, errors='coerce')
    valid_years = numeric_years[(numeric_years >= 1000) & (numeric_years <= 2100)]
    
    if len(valid_years) > 0:
        print(f"üìä Years extracted: {len(years)} books ({len(valid_years)} valid years)")
        print(f"üìÖ Earliest: {int(valid_years.min())}")
        print(f"üìÖ Latest: {int(valid_years.max())}")
        print(f"üìÖ Median year: {int(valid_years.median())}")
        
        # Decade breakdown
        print("\nüìà By decade:")
        decade_counts = ((valid_years // 10) * 10).value_counts().sort_index()
        for decade, count in decade_counts.tail(6).items():  # Last 6 decades
            print(f"  {int(decade)}s: {count} books")
    
    print()
    print("üéØ LIBRARY OF CONGRESS READINESS ASSESSMENT:")
    print("-" * 50)
    
    # Enhanced readiness assessment for complete collection
    # High confidence: Has title AND (author OR ISBN OR year)
    high_confidence = (
        pdf_titles & 
        (pdf_authors | extracted_isbns | extracted_years)
    )
    
    # Medium confidence: Has title OR (author AND year) OR ISBN
    medium_confidence = (
        ~high_confidence & 
        (pdf_titles | (pdf_authors & extracted_years) | extracted_isbns)
    )
    
    # Excellent confidence: Has title AND author AND (ISBN OR year)
    excellent_confidence = (
        pdf_titles & pdf_authors & (extracted_isbns | extracted_years)
    )
    
    low_confidence = ~(high_confidence | medium_confidence)
    
    print(f"üèÜ EXCELLENT (Title + Author + ISBN/Year): {excellent_confidence.sum()} books")
    print(f"üü¢ HIGH confidence: {high_confidence.sum()} books")
    print(f"üü° MEDIUM confidence: {medium_confidence.sum()} books")
    print(f"üî¥ LOW confidence: {low_confidence.sum()} books")
    
    print()
    print("üìä LC ENHANCEMENT STRATEGY:")
    print("-" * 50)
    
    # Calculate expected LC success rates
    isbn_books = extracted_isbns.sum()
    title_author_books = (pdf_titles & pdf_authors).sum()
    title_only_books = (pdf_titles & ~pdf_authors).sum()
    
    # Estimated LC success rates based on data quality
    estimated_isbn_success = isbn_books * 0.85  # 85% success for ISBN lookups
    estimated_title_author_success = title_author_books * 0.75  # 75% for title+author
    estimated_title_only_success = title_only_books * 0.50  # 50% for title only
    
    total_estimated_success = estimated_isbn_success + estimated_title_author_success + estimated_title_only_success
    
    print(f"üìö Books with ISBNs: {isbn_books} (expected 85% LC success)")
    print(f"üìö Books with Title+Author: {title_author_books} (expected 75% LC success)")
    print(f"üìö Books with Title only: {title_only_books} (expected 50% LC success)")
    print(f"üéØ ESTIMATED LC ENHANCEMENT: ~{total_estimated_success:.0f} books ({total_estimated_success/total*100:.1f}%)")
    
    print()
    print("üìñ SAMPLE HIGH-QUALITY RECORDS:")
    print("-" * 50)
    
    # Show best examples
    excellent_samples = df[excellent_confidence].head(5)
    for idx, row in excellent_samples.iterrows():
        print(f"\nüìö {row['filename']}")
        if pd.notna(row['pdf_title']) and row['pdf_title'].strip():
            print(f"   üìñ Title: {row['pdf_title']}")
        if pd.notna(row['pdf_author']) and row['pdf_author'].strip():
            print(f"   ‚úçÔ∏è Author: {row['pdf_author']}")
        if pd.notna(row['extracted_isbn']) and row['extracted_isbn'].strip():
            print(f"   üî¢ ISBN: {row['extracted_isbn']}")
        if pd.notna(row['extracted_year']):
            print(f"   üìÖ Year: {int(row['extracted_year'])}")
        if pd.notna(row['extracted_publisher']) and row['extracted_publisher'].strip():
            print(f"   üè¢ Publisher: {row['extracted_publisher']}")
    
    print()
    print("üöÄ NEXT PHASE PREPARATION:")
    print("-" * 50)
    print("1. ‚úÖ Complete PDF metadata extraction (DONE!)")
    print("2. üîÑ Library of Congress API integration")
    print("3. üîÑ Batch LC data enhancement")
    print("4. üîÑ Manual curation and verification")
    print("5. üîÑ Database schema enhancement")
    print("6. üîÑ Professional catalog integration")
    
    return df

def create_lc_enhancement_queue(df):
    """Create prioritized queue for LC enhancement"""
    
    output_path = "/home/herb/Desktop/BowersWorld-com/AndersonLibrary_LCEnhancementQueue.xlsx"
    
    print("\nüîß Creating LC Enhancement Queue...")
    print("-" * 50)
    
    # Clean and prepare data
    df_clean = df.copy()
    
    # Clean text fields
    text_columns = ['pdf_title', 'pdf_author', 'pdf_subject', 'pdf_creator', 'pdf_producer', 
                   'extracted_publisher', 'first_page_text', 'title_page_text', 'copyright_page_text']
    
    for col in text_columns:
        if col in df_clean.columns:
            df_clean[col] = df_clean[col].fillna('').astype(str)
            # Remove problematic characters for Excel
            df_clean[col] = df_clean[col].str.replace(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', regex=True)
            # Limit length
            df_clean[col] = df_clean[col].str[:32767]
    
    # Create priority scoring
    df_clean['lc_priority_score'] = 0
    
    # Add points for data quality
    df_clean.loc[df_clean['pdf_title'].str.len() > 0, 'lc_priority_score'] += 10
    df_clean.loc[df_clean['pdf_author'].str.len() > 0, 'lc_priority_score'] += 10  
    df_clean.loc[df_clean['extracted_isbn'].notna() & (df_clean['extracted_isbn'].str.len() > 0), 'lc_priority_score'] += 20
    df_clean.loc[df_clean['extracted_year'].notna(), 'lc_priority_score'] += 5
    df_clean.loc[df_clean['extracted_publisher'].str.len() > 0, 'lc_priority_score'] += 5
    
    # Sort by priority (highest first)
    df_sorted = df_clean.sort_values('lc_priority_score', ascending=False)
    
    # Add LC enhancement columns
    df_sorted['lc_search_query'] = ''
    df_sorted['lc_api_status'] = 'pending'
    df_sorted['lc_match_found'] = ''
    df_sorted['lc_confidence'] = ''
    df_sorted['lc_title'] = ''
    df_sorted['lc_author'] = ''
    df_sorted['lc_subjects'] = ''
    df_sorted['lc_classification'] = ''
    df_sorted['lc_isbn'] = ''
    df_sorted['lc_publisher'] = ''
    df_sorted['lc_year'] = ''
    df_sorted['lc_description'] = ''
    df_sorted['manual_notes'] = ''
    df_sorted['verification_status'] = 'pending'
    
    # Select and reorder columns for LC workflow
    lc_columns = [
        'filename', 'lc_priority_score',
        'pdf_title', 'pdf_author', 'extracted_isbn', 'extracted_year', 'extracted_publisher',
        'lc_search_query', 'lc_api_status', 'lc_match_found', 'lc_confidence',
        'lc_title', 'lc_author', 'lc_subjects', 'lc_classification', 
        'lc_isbn', 'lc_publisher', 'lc_year', 'lc_description',
        'manual_notes', 'verification_status',
        'file_size_mb', 'page_count', 'extraction_method'
    ]
    
    # Keep only available columns
    available_columns = [col for col in lc_columns if col in df_sorted.columns]
    lc_queue = df_sorted[available_columns]
    
    # Save the enhancement queue
    try:
        lc_queue.to_excel(output_path, index=False, engine='openpyxl')
        print(f"‚úÖ LC Enhancement Queue saved: {output_path}")
        
        # Print priority breakdown
        high_priority = (lc_queue['lc_priority_score'] >= 30).sum()
        medium_priority = ((lc_queue['lc_priority_score'] >= 20) & (lc_queue['lc_priority_score'] < 30)).sum()
        low_priority = (lc_queue['lc_priority_score'] < 20).sum()
        
        print(f"\nüìä Priority Breakdown:")
        print(f"   üèÜ High Priority (30+ points): {high_priority} books")
        print(f"   üü° Medium Priority (20-29 points): {medium_priority} books")
        print(f"   ‚ö™ Low Priority (<20 points): {low_priority} books")
        
    except Exception as e:
        print(f"‚ùå Error saving Excel: {e}")
        # Fallback to CSV
        csv_path = output_path.replace('.xlsx', '.csv')
        lc_queue.to_csv(csv_path, index=False)
        print(f"‚úÖ Saved as CSV instead: {csv_path}")
    
    return lc_queue

if __name__ == "__main__":
    # Analyze the complete collection
    df = analyze_complete_collection()
    
    if df is not None:
        # Create LC enhancement queue
        lc_queue = create_lc_enhancement_queue(df)
        
        print(f"\nüéâ ANALYSIS COMPLETE!")
        print(f"üìä Full metadata: AndersonLibrary_PDFMetadata.csv")
        print(f"üöÄ LC queue ready: AndersonLibrary_LCEnhancementQueue.xlsx")
        print(f"\nüèõÔ∏è Ready to begin Library of Congress data enhancement!")
================
File: CreateLibraryCSV/DigitalAlexandria.py
================
#!/usr/bin/env python3
import sys
from pathlib import Path

def main():
    try:
        from fastapi import FastAPI
        from fastapi.responses import HTMLResponse
        import uvicorn
        
        app = FastAPI(title="BowersWorld-com")
        
        @app.get("/", response_class=HTMLResponse)
        def home():
            return """
            <html><body style="font-family: Arial; margin: 40px;">
            <h1>üèõÔ∏è BowersWorld-com Digital Alexandria</h1>
            <p>‚úÖ System Online and Ready!</p>
            <h3>Features:</h3>
            <ul>
                <li>Digital Library Management</li>
                <li>Full-text Search</li>
                <li>API Integration</li>
                <li>Modern Web Interface</li>
            </ul>
            <p><strong>Status:</strong> Operational</p>
            </body></html>
            """
        
        print("üåê Starting BowersWorld-com...")
        print("   Access: http://localhost:8080")
        uvicorn.run(app, host="localhost", port=8080)
        
    except ImportError:
        print("‚ö†Ô∏è FastAPI not available. Install with:")
        print("   pip install fastapi uvicorn")

if __name__ == "__main__":
    main()
s
================
File: CreateLibraryCSV/Resumable PDF Metadata Extractor.py
================
#!/usr/bin/env python3
"""
Resumable PDF Metadata Extractor - Continue where previous extraction left off
"""

import os
import csv
import sqlite3
from pathlib import Path
import PyPDF2
import pandas as pd
from datetime import datetime
import re
import fitz  # PyMuPDF
import warnings
warnings.filterwarnings("ignore")

# Configuration
PDF_DIRECTORY = "/home/herb/Desktop/Not Backed Up/Anderson's Library/Andy/Anderson eBooks"
DATABASE_PATH = "/home/herb/Desktop/BowersWorld-com/Assets/my_library.db"
OUTPUT_CSV = "/home/herb/Desktop/BowersWorld-com/AndersonLibrary_PDFMetadata.csv"
PROGRESS_INTERVAL = 25

# Text extraction patterns
ISBN_PATTERN = re.compile(r'ISBN[:\-\s]*([0-9\-X]{10,17})', re.IGNORECASE)
YEAR_PATTERN = re.compile(r'(19|20)\d{2}')
PUBLISHER_PATTERN = re.compile(r'Published by[:\s]*([^.\n\r]{5,50})', re.IGNORECASE)
COPYRIGHT_PATTERN = re.compile(r'Copyright[:\s]*¬©?\s*(\d{4})', re.IGNORECASE)
EDITION_PATTERN = re.compile(r'(\d+)(st|nd|rd|th)\s+edition', re.IGNORECASE)

class ResumablePDFExtractor:
    def __init__(self, PDFDirectory, DatabasePath, OutputFile):
        self.PDFDirectory = Path(PDFDirectory)
        self.DatabasePath = DatabasePath
        self.OutputFile = OutputFile
        self.ProcessedCount = 0
        self.ErrorCount = 0
        self.SkippedCount = 0
        self.ExtractedData = []
        
        # Load existing data if available
        self.LoadExistingData()
        self.LoadDatabaseInfo()
    
    def LoadExistingData(self):
        """Load previously processed PDFs to resume extraction"""
        self.ProcessedFiles = set()
        
        if os.path.exists(self.OutputFile):
            try:
                existing_df = pd.read_csv(self.OutputFile)
                self.ProcessedFiles = set(existing_df['filename'].str.replace('.pdf', '', regex=False))
                print(f"‚úÖ Found {len(self.ProcessedFiles)} previously processed PDFs")
                print(f"üìÑ Will resume extraction for remaining files...")
            except Exception as e:
                print(f"‚ö†Ô∏è Could not load existing CSV: {e}")
                print("üìÑ Starting fresh extraction...")
                self.ProcessedFiles = set()
        else:
            print("üìÑ No existing CSV found, starting fresh extraction...")
    
    def LoadDatabaseInfo(self):
        """Load existing book data from SQLite database"""
        self.DatabaseBooks = {}
        
        if os.path.exists(self.DatabasePath):
            try:
                conn = sqlite3.connect(self.DatabasePath)
                cursor = conn.cursor()
                
                query = '''
                    SELECT b.title, c.category, s.subject 
                    FROM books b
                    LEFT JOIN subjects s ON b.subject_id = s.id
                    LEFT JOIN categories c ON s.category_id = c.id
                '''
                
                books = cursor.execute(query).fetchall()
                
                for title, category, subject in books:
                    self.DatabaseBooks[title] = {
                        'category': category or 'Unknown',
                        'subject': subject or 'Unknown'
                    }
                
                conn.close()
                print(f"‚úÖ Loaded {len(self.DatabaseBooks)} books from database")
                
            except Exception as DbError:
                print(f"‚ö†Ô∏è Database error: {DbError}")
                self.DatabaseBooks = {}
        else:
            print(f"‚ö†Ô∏è Database not found at {self.DatabasePath}")
            self.DatabaseBooks = {}
    
    def ExtractPDFMetadata(self, PDFPath):
        """Extract metadata from a single PDF file with improved error handling"""
        Metadata = {
            'filename': PDFPath.name,
            'file_size_mb': round(PDFPath.stat().st_size / (1024*1024), 2),
            'pdf_title': '',
            'pdf_author': '',
            'pdf_subject': '',
            'pdf_creator': '',
            'pdf_producer': '',
            'pdf_creation_date': '',
            'page_count': 0,
            'extracted_isbn': '',
            'extracted_year': '',
            'extracted_publisher': '',
            'extracted_edition': '',
            'first_page_text': '',
            'title_page_text': '',
            'copyright_page_text': '',
            'database_category': 'Not Found',
            'database_subject': 'Not Found',
            'extraction_method': 'None',
            'errors': ''
        }
        
        # Get database info for this book
        BookTitle = PDFPath.stem
        if BookTitle in self.DatabaseBooks:
            Metadata['database_category'] = self.DatabaseBooks[BookTitle]['category']
            Metadata['database_subject'] = self.DatabaseBooks[BookTitle]['subject']
        
        ErrorMessages = []
        
        # Try PyMuPDF first
        try:
            PDFDocument = fitz.open(str(PDFPath))
            Metadata['page_count'] = len(PDFDocument)
            Metadata['extraction_method'] = 'PyMuPDF'
            
            # Extract PDF metadata with safe string conversion
            PDFMetadata = PDFDocument.metadata
            Metadata['pdf_title'] = str(PDFMetadata.get('title', '')).strip()
            Metadata['pdf_author'] = str(PDFMetadata.get('author', '')).strip()
            Metadata['pdf_subject'] = str(PDFMetadata.get('subject', '')).strip()
            Metadata['pdf_creator'] = str(PDFMetadata.get('creator', '')).strip()
            Metadata['pdf_producer'] = str(PDFMetadata.get('producer', '')).strip()
            
            if PDFMetadata.get('creationDate'):
                Metadata['pdf_creation_date'] = str(PDFMetadata['creationDate'])[:10]
            
            # Extract text from key pages with size limits
            if len(PDFDocument) > 0:
                try:
                    FirstPage = PDFDocument[0]
                    Metadata['first_page_text'] = FirstPage.get_text()[:1000]
                except:
                    pass
                
                if len(PDFDocument) > 1:
                    try:
                        TitlePage = PDFDocument[1]
                        Metadata['title_page_text'] = TitlePage.get_text()[:1000]
                    except:
                        pass
                
                # Look for copyright page
                for PageNum in range(min(4, len(PDFDocument))):
                    try:
                        PageText = PDFDocument[PageNum].get_text()
                        if 'copyright' in PageText.lower() or '¬©' in PageText:
                            Metadata['copyright_page_text'] = PageText[:1000]
                            break
                    except:
                        continue
            
            PDFDocument.close()
            
        except Exception as PyMuPDFError:
            ErrorMessages.append(f"PyMuPDF: {str(PyMuPDFError)[:100]}")
            
            # Fallback to PyPDF2
            try:
                with open(PDFPath, 'rb') as PDFFile:
                    PDFReader = PyPDF2.PdfReader(PDFFile)
                    Metadata['page_count'] = len(PDFReader.pages)
                    Metadata['extraction_method'] = 'PyPDF2'
                    
                    if PDFReader.metadata:
                        Metadata['pdf_title'] = str(PDFReader.metadata.get('/Title', '')).strip()
                        Metadata['pdf_author'] = str(PDFReader.metadata.get('/Author', '')).strip()
                        Metadata['pdf_subject'] = str(PDFReader.metadata.get('/Subject', '')).strip()
                        Metadata['pdf_creator'] = str(PDFReader.metadata.get('/Creator', '')).strip()
                        Metadata['pdf_producer'] = str(PDFReader.metadata.get('/Producer', '')).strip()
                        
                        CreationDate = PDFReader.metadata.get('/CreationDate')
                        if CreationDate:
                            Metadata['pdf_creation_date'] = str(CreationDate)[:10]
                    
                    # Extract text from first few pages
                    if len(PDFReader.pages) > 0:
                        try:
                            Metadata['first_page_text'] = PDFReader.pages[0].extract_text()[:1000]
                        except:
                            pass
                        
                        if len(PDFReader.pages) > 1:
                            try:
                                Metadata['title_page_text'] = PDFReader.pages[1].extract_text()[:1000]
                            except:
                                pass
                        
                        # Look for copyright page
                        for PageNum in range(min(4, len(PDFReader.pages))):
                            try:
                                PageText = PDFReader.pages[PageNum].extract_text()
                                if 'copyright' in PageText.lower() or '¬©' in PageText:
                                    Metadata['copyright_page_text'] = PageText[:1000]
                                    break
                            except:
                                continue
                
            except Exception as PyPDF2Error:
                ErrorMessages.append(f"PyPDF2: {str(PyPDF2Error)[:100]}")
                Metadata['extraction_method'] = 'Failed'
        
        # Extract specific information from text
        AllText = ' '.join(filter(None, [
            Metadata.get('first_page_text', ''),
            Metadata.get('title_page_text', ''),
            Metadata.get('copyright_page_text', '')
        ]))
        
        if AllText:
            # Extract ISBN
            ISBNMatch = ISBN_PATTERN.search(AllText)
            if ISBNMatch:
                Metadata['extracted_isbn'] = ISBNMatch.group(1).replace('-', '').replace(' ', '')
            
            # Extract publication year
            YearMatches = YEAR_PATTERN.findall(AllText)
            if YearMatches:
                Years = [int(year) for year in YearMatches if 1900 <= int(year) <= 2025]
                if Years:
                    Metadata['extracted_year'] = max(Years)
            
            # Extract publisher
            PublisherMatch = PUBLISHER_PATTERN.search(AllText)
            if PublisherMatch:
                Metadata['extracted_publisher'] = PublisherMatch.group(1).strip()
            
            # Extract copyright year if no publication year found
            if not Metadata['extracted_year']:
                CopyrightMatch = COPYRIGHT_PATTERN.search(AllText)
                if CopyrightMatch:
                    Metadata['extracted_year'] = int(CopyrightMatch.group(1))
            
            # Extract edition
            EditionMatch = EDITION_PATTERN.search(AllText)
            if EditionMatch:
                Metadata['extracted_edition'] = f"{EditionMatch.group(1)}{EditionMatch.group(2)} edition"
        
        # Store errors as string
        Metadata['errors'] = '; '.join(ErrorMessages) if ErrorMessages else ''
        
        return Metadata
    
    def ProcessRemainingPDFs(self):
        """Process only PDFs that haven't been processed yet"""
        print(f"üìö Resumable PDF Metadata Extractor")
        print("=" * 60)
        print(f"üìÇ PDF Directory: {self.PDFDirectory}")
        print(f"üìä Output CSV: {self.OutputFile}")
        print("=" * 60)
        
        if not self.PDFDirectory.exists():
            print(f"‚ùå PDF directory not found: {self.PDFDirectory}")
            return False
        
        # Find all PDF files
        AllPDFFiles = list(self.PDFDirectory.glob("*.pdf"))
        TotalFiles = len(AllPDFFiles)
        
        # Filter out already processed files
        UnprocessedFiles = [
            pdf for pdf in AllPDFFiles 
            if pdf.stem not in self.ProcessedFiles
        ]
        
        RemainingCount = len(UnprocessedFiles)
        
        print(f"üìÅ Total PDFs in directory: {TotalFiles}")
        print(f"‚úÖ Already processed: {len(self.ProcessedFiles)}")
        print(f"‚è≥ Remaining to process: {RemainingCount}")
        
        if RemainingCount == 0:
            print("üéâ All PDFs have been processed!")
            return True
        
        print(f"üîÑ Starting extraction of remaining {RemainingCount} files...\n")
        
        # Process remaining PDFs
        for FileIndex, PDFFile in enumerate(UnprocessedFiles, 1):
            try:
                print(f"[{FileIndex:4d}/{RemainingCount}] Processing: {PDFFile.name}")
                
                ExtractedMetadata = self.ExtractPDFMetadata(PDFFile)
                self.AppendToCSV(ExtractedMetadata)
                self.ProcessedCount += 1
                
                # Show progress
                if FileIndex % PROGRESS_INTERVAL == 0:
                    self.ShowProgress(FileIndex, RemainingCount)
                
            except Exception as ProcessingError:
                print(f"   ‚ùå Critical error processing {PDFFile.name}: {ProcessingError}")
                self.ErrorCount += 1
                # Continue processing other files
                continue
        
        # Final progress
        self.ShowProgress(RemainingCount, RemainingCount)
        self.GenerateReport(TotalFiles, len(self.ProcessedFiles) + self.ProcessedCount)
        
        return True
    
    def AppendToCSV(self, BookData):
        """Append a single record to CSV file"""
        file_exists = os.path.exists(self.OutputFile)
        
        # Define CSV columns
        Columns = [
            'filename', 'file_size_mb', 'page_count',
            'database_category', 'database_subject',
            'pdf_title', 'pdf_author', 'pdf_subject', 'pdf_creator', 'pdf_producer',
            'pdf_creation_date', 'extracted_isbn', 'extracted_year', 
            'extracted_publisher', 'extracted_edition',
            'first_page_text', 'title_page_text', 'copyright_page_text',
            'extraction_method', 'errors'
        ]
        
        try:
            with open(self.OutputFile, 'a', newline='', encoding='utf-8') as CSVFile:
                Writer = csv.DictWriter(CSVFile, fieldnames=Columns)
                
                # Write header only if file is new
                if not file_exists:
                    Writer.writeheader()
                
                Writer.writerow(BookData)
                
        except Exception as SaveError:
            print(f"‚ùå Error appending to CSV: {SaveError}")
    
    def ShowProgress(self, Current, Total):
        """Show processing progress"""
        ProcessedPct = (Current / Total) * 100
        
        print(f"\nüìä Progress: {Current}/{Total} ({ProcessedPct:.1f}%)")
        print(f"   ‚úÖ Successfully processed: {self.ProcessedCount}")
        print(f"   ‚ùå Errors: {self.ErrorCount}")
        print()
    
    def GenerateReport(self, TotalInDirectory, TotalProcessed):
        """Generate final report"""
        print("\n" + "=" * 60)
        print("üìä RESUMABLE EXTRACTION COMPLETE!")
        print("=" * 60)
        print(f"üìÅ Total PDFs in directory: {TotalInDirectory}")
        print(f"‚úÖ Total processed: {TotalProcessed}")
        print(f"‚ùå Total errors: {self.ErrorCount}")
        print(f"üìà Success rate: {((TotalProcessed - self.ErrorCount) / TotalInDirectory * 100):.1f}%")
        print()
        
        if TotalProcessed == TotalInDirectory:
            print("üéâ ALL PDFs SUCCESSFULLY PROCESSED!")
            print("üìä Ready for Library of Congress data enhancement!")
        else:
            missing = TotalInDirectory - TotalProcessed
            print(f"‚ö†Ô∏è {missing} PDFs still need processing")
            print("üîÑ Run the script again to continue")
        
        print("=" * 60)

if __name__ == "__main__":
    # Run resumable extraction
    Extractor = ResumablePDFExtractor(
        PDFDirectory=PDF_DIRECTORY,
        DatabasePath=DATABASE_PATH, 
        OutputFile=OUTPUT_CSV
    )
    
    Success = Extractor.ProcessRemainingPDFs()
    
    if Success:
        print(f"\nüéâ Extraction session complete!")
        print(f"üìä Results appended to: {OUTPUT_CSV}")
    else:
        print(f"\n‚ùå Extraction failed!")
        exit(1)
================
File: CreateThumbs/ConvertToThumbnails.py
================
#!/usr/bin/env python3
"""
File: ConvertToThumbnails.py
Path: /home/herb/Desktop/BowersWorld-com/ConvertToThumbnails.py
Standard: AIDEV-PascalCase-1.7
Created: 2025-06-25
Author: Herb Bowers - Project Himalaya
Description: Convert PNG book covers to web-optimized thumbnails for Anderson's Library
"""

import os
import sys
from pathlib import Path
from PIL import Image
import time
from datetime import datetime

# Configuration
SOURCE_DIR = "/home/herb/Desktop/BowersWorld-com/Covers"
OUTPUT_DIR = "/home/herb/Desktop/BowersWorld-com/Thumbs"
THUMBNAIL_SIZE = (64, 85)  # Width x Height - optimized for book covers
QUALITY_SETTING = 85  # PNG optimization level
PROGRESS_INTERVAL = 25  # Show progress every N files

def CreateOutputDirectory(OutputPath):
    """
    Create the output directory if it doesn't exist
    
    Args:
        OutputPath: Path to create
        
    Returns:
        bool: True if successful, False otherwise
    """
    try:
        Path(OutputPath).mkdir(parents=True, exist_ok=True)
        print(f"‚úÖ Output directory ready: {OutputPath}")
        return True
    except Exception as CreateError:
        print(f"‚ùå Failed to create output directory: {CreateError}")
        return False

def ValidateSourceDirectory(SourcePath):
    """
    Validate that source directory exists and contains PNG files
    
    Args:
        SourcePath: Path to validate
        
    Returns:
        tuple: (bool: valid, int: png_count)
    """
    if not os.path.exists(SourcePath):
        print(f"‚ùå Source directory not found: {SourcePath}")
        return False, 0
    
    PngFiles = list(Path(SourcePath).glob("*.png"))
    PngCount = len(PngFiles)
    
    if PngCount == 0:
        print(f"‚ö†Ô∏è No PNG files found in: {SourcePath}")
        return False, 0
    
    print(f"üìÅ Found {PngCount} PNG files in source directory")
    return True, PngCount

def ConvertSingleImage(SourcePath, OutputPath, ThumbnailSize):
    """
    Convert a single PNG file to thumbnail
    
    Args:
        SourcePath: Path to source PNG file
        OutputPath: Path for output thumbnail
        ThumbnailSize: Tuple of (width, height)
        
    Returns:
        tuple: (bool: success, int: original_size, int: thumbnail_size)
    """
    try:
        # Get original file size
        OriginalSize = os.path.getsize(SourcePath)
        
        # Open and process image
        with Image.open(SourcePath) as OriginalImage:
            # Convert RGBA to RGB if necessary (remove transparency)
            if OriginalImage.mode in ('RGBA', 'LA'):
                # Create white background
                RgbImage = Image.new('RGB', OriginalImage.size, (255, 255, 255))
                if OriginalImage.mode == 'RGBA':
                    RgbImage.paste(OriginalImage, mask=OriginalImage.split()[-1])
                else:
                    RgbImage.paste(OriginalImage, mask=OriginalImage.split()[-1])
                ProcessedImage = RgbImage
            else:
                ProcessedImage = OriginalImage.copy()
            
            # Create thumbnail while maintaining aspect ratio
            ProcessedImage.thumbnail(ThumbnailSize, Image.Resampling.LANCZOS)
            
            # Save optimized thumbnail
            ProcessedImage.save(OutputPath, 'PNG', optimize=True, quality=QUALITY_SETTING)
        
        # Get thumbnail file size
        ThumbnailSize = os.path.getsize(OutputPath)
        
        return True, OriginalSize, ThumbnailSize
        
    except Exception as ConversionError:
        print(f"‚ùå Error converting {SourcePath}: {ConversionError}")
        return False, 0, 0

def FormatFileSize(SizeInBytes):
    """
    Format file size in human-readable format
    
    Args:
        SizeInBytes: Size in bytes
        
    Returns:
        str: Formatted size string
    """
    for Unit in ['B', 'KB', 'MB', 'GB']:
        if SizeInBytes < 1024.0:
            return f"{SizeInBytes:.1f} {Unit}"
        SizeInBytes /= 1024.0
    return f"{SizeInBytes:.1f} TB"

def GenerateThumbnails():
    """
    Main function to convert all PNG files to thumbnails
    
    Returns:
        bool: True if successful, False otherwise
    """
    StartTime = time.time()
    
    print("üé® Anderson's Library Thumbnail Generator")
    print("=" * 50)
    print(f"üìÇ Source: {SOURCE_DIR}")
    print(f"üìÅ Output: {OUTPUT_DIR}")
    print(f"üìè Size: {THUMBNAIL_SIZE[0]}x{THUMBNAIL_SIZE[1]} pixels")
    print("=" * 50)
    
    # Validate source directory
    IsValid, TotalFiles = ValidateSourceDirectory(SOURCE_DIR)
    if not IsValid:
        return False
    
    # Create output directory
    if not CreateOutputDirectory(OUTPUT_DIR):
        return False
    
    # Process all PNG files
    ProcessedCount = 0
    ErrorCount = 0
    TotalOriginalSize = 0
    TotalThumbnailSize = 0
    SkippedCount = 0
    
    PngFiles = list(Path(SOURCE_DIR).glob("*.png"))
    
    print(f"üîÑ Starting conversion of {len(PngFiles)} files...")
    print()
    
    for FileIndex, SourceFile in enumerate(PngFiles, 1):
        FileName = SourceFile.name
        OutputFile = Path(OUTPUT_DIR) / FileName
        
        # Check if thumbnail already exists
        if OutputFile.exists():
            print(f"‚è≠Ô∏è Skipping {FileName} (already exists)")
            SkippedCount += 1
            continue
        
        # Convert image
        Success, OriginalSize, ThumbnailSize = ConvertSingleImage(
            str(SourceFile), str(OutputFile), THUMBNAIL_SIZE
        )
        
        if Success:
            ProcessedCount += 1
            TotalOriginalSize += OriginalSize
            TotalThumbnailSize += ThumbnailSize
            
            # Calculate compression ratio
            CompressionRatio = (1 - (ThumbnailSize / OriginalSize)) * 100 if OriginalSize > 0 else 0
            
            # Show progress
            if ProcessedCount % PROGRESS_INTERVAL == 0 or FileIndex == len(PngFiles):
                print(f"üì∏ Processed {ProcessedCount}/{TotalFiles}: {FileName}")
                print(f"   üìä {FormatFileSize(OriginalSize)} ‚Üí {FormatFileSize(ThumbnailSize)} ({CompressionRatio:.1f}% reduction)")
                
        else:
            ErrorCount += 1
    
    # Calculate final statistics
    EndTime = time.time()
    ProcessingTime = EndTime - StartTime
    
    print()
    print("=" * 50)
    print("‚úÖ THUMBNAIL CONVERSION COMPLETE!")
    print("=" * 50)
    print(f"üìä Files processed: {ProcessedCount}")
    print(f"‚è≠Ô∏è Files skipped: {SkippedCount}")
    print(f"‚ùå Errors: {ErrorCount}")
    print(f"‚è±Ô∏è Processing time: {ProcessingTime:.1f} seconds")
    
    if ProcessedCount > 0:
        # Size comparison
        TotalReduction = (1 - (TotalThumbnailSize / TotalOriginalSize)) * 100 if TotalOriginalSize > 0 else 0
        AverageOriginalSize = TotalOriginalSize / ProcessedCount
        AverageThumbnailSize = TotalThumbnailSize / ProcessedCount
        
        print()
        print("üìà SIZE ANALYSIS:")
        print(f"   Original total: {FormatFileSize(TotalOriginalSize)}")
        print(f"   Thumbnail total: {FormatFileSize(TotalThumbnailSize)}")
        print(f"   Total reduction: {TotalReduction:.1f}%")
        print(f"   Average original: {FormatFileSize(AverageOriginalSize)}")
        print(f"   Average thumbnail: {FormatFileSize(AverageThumbnailSize)}")
        
        # Performance metrics
        FilesPerSecond = ProcessedCount / ProcessingTime if ProcessingTime > 0 else 0
        print(f"   Processing speed: {FilesPerSecond:.1f} files/second")
    
    print()
    print(f"üìÅ Thumbnails saved to: {OUTPUT_DIR}")
    print("üéâ Ready for web deployment!")
    
    return ErrorCount == 0

def ShowUsageInformation():
    """Display usage information for the script"""
    print("üìö Anderson's Library Thumbnail Generator")
    print()
    print("USAGE:")
    print("  python ConvertToThumbnails.py")
    print()
    print("CONFIGURATION:")
    print(f"  Source Directory: {SOURCE_DIR}")
    print(f"  Output Directory: {OUTPUT_DIR}")
    print(f"  Thumbnail Size: {THUMBNAIL_SIZE[0]}x{THUMBNAIL_SIZE[1]} pixels")
    print()
    print("FEATURES:")
    print("  ‚úÖ Maintains aspect ratio")
    print("  ‚úÖ Optimizes file size")
    print("  ‚úÖ Handles RGBA to RGB conversion")
    print("  ‚úÖ Progress tracking")
    print("  ‚úÖ Error handling")
    print("  ‚úÖ Skips existing files")
    print()
    print("OUTPUT:")
    print("  ‚Ä¢ Creates optimized PNG thumbnails")
    print("  ‚Ä¢ Typically 95%+ smaller than originals")
    print("  ‚Ä¢ Perfect for web deployment")

def ValidateEnvironment():
    """
    Validate that required dependencies are available
    
    Returns:
        bool: True if environment is ready
    """
    try:
        import PIL
        print(f"‚úÖ PIL/Pillow version: {PIL.__version__}")
        return True
    except ImportError:
        print("‚ùå PIL/Pillow not found!")
        print("   Install with: pip install Pillow")
        return False

if __name__ == "__main__":
    # Handle command line arguments
    if len(sys.argv) > 1 and sys.argv[1] in ['-h', '--help', 'help']:
        ShowUsageInformation()
        sys.exit(0)
    
    # Validate environment
    if not ValidateEnvironment():
        sys.exit(1)
    
    # Run thumbnail generation
    try:
        Success = GenerateThumbnails()
        ExitCode = 0 if Success else 1
        
        if Success:
            print(f"\nüéâ Thumbnail generation completed successfully!")
            print(f"   Ready to integrate with Anderson's Library web interface")
        else:
            print(f"\n‚ö†Ô∏è Thumbnail generation completed with errors")
            print(f"   Check the output above for details")
        
        sys.exit(ExitCode)
        
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Conversion interrupted by user")
        print("   Partial results may be available in the output directory")
        sys.exit(1)
    except Exception as UnexpectedError:
        print(f"\n‚ùå Unexpected error: {UnexpectedError}")
        print("   Please check file permissions and available disk space")
        sys.exit(1)
================
File: CreateThumbs/ConvertToThumbnailsPart2.py
================
#!/usr/bin/env python3
"""
Fix Problematic PNG Files - Simple metadata stripping approach
"""

import os
from PIL import Image
import io

# The problematic files
PROBLEMATIC_FILES = [
    "/home/herb/Desktop/BowersWorld-com/Covers/Algebra Based and AP Physics 2.png",
    "/home/herb/Desktop/BowersWorld-com/Covers/Trigonometry for Dummies.png"
]

OUTPUT_DIR = "/home/herb/Desktop/BowersWorld-com/Thumbs"
THUMBNAIL_SIZE = (64, 85)

def fix_and_convert_png(source_path, output_path):
    """
    Fix PNG by completely stripping metadata and converting to thumbnail
    """
    try:
        print(f"üîß Fixing: {os.path.basename(source_path)}")
        
        # Method 1: Try loading with warnings ignored
        try:
            import warnings
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                img = Image.open(source_path)
                img.load()  # Force load the image data
        except Exception:
            # Method 2: Load as raw pixel data and rebuild
            print(f"   üîÑ Trying alternative loading method...")
            with open(source_path, 'rb') as f:
                # Read file as bytes
                img_bytes = f.read()
            
            # Load into PIL and immediately convert to clean format
            img_stream = io.BytesIO(img_bytes)
            img = Image.open(img_stream)
            img.load()
        
        # Convert to clean RGB format (strips all metadata)
        if img.mode in ('RGBA', 'LA', 'P'):
            # Create white background
            clean_img = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            if img.mode in ('RGBA', 'LA'):
                clean_img.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
        else:
            # Convert to RGB to strip metadata
            clean_img = img.convert('RGB')
        
        # Create thumbnail
        clean_img.thumbnail(THUMBNAIL_SIZE, Image.Resampling.LANCZOS)
        
        # Save as clean PNG (no metadata)
        clean_img.save(output_path, 'PNG', optimize=True)
        
        # Clean up
        img.close()
        clean_img.close()
        
        # Check result
        if os.path.exists(output_path):
            original_size = os.path.getsize(source_path)
            thumbnail_size = os.path.getsize(output_path)
            reduction = (1 - (thumbnail_size / original_size)) * 100
            
            print(f"   ‚úÖ Success: {original_size//1024} KB ‚Üí {thumbnail_size//1024} KB ({reduction:.1f}% reduction)")
            return True
        else:
            print(f"   ‚ùå Failed to create thumbnail")
            return False
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        
        # Last resort: Try with different image library or manual pixel extraction
        try:
            print(f"   üîÑ Trying emergency fallback...")
            # Create a simple placeholder thumbnail
            placeholder = Image.new('RGB', THUMBNAIL_SIZE, (200, 200, 200))
            # Add some text to indicate it's a placeholder
            placeholder.save(output_path, 'PNG')
            print(f"   ‚ö†Ô∏è Created placeholder thumbnail")
            return True
        except:
            return False

def main():
    print("üîß Fixing Problematic PNG Files")
    print("=" * 40)
    
    fixed_count = 0
    
    for source_file in PROBLEMATIC_FILES:
        if os.path.exists(source_file):
            filename = os.path.basename(source_file)
            output_file = os.path.join(OUTPUT_DIR, filename)
            
            if fix_and_convert_png(source_file, output_file):
                fixed_count += 1
        else:
            print(f"‚ö†Ô∏è File not found: {os.path.basename(source_file)}")
    
    print()
    print(f"‚úÖ Fixed {fixed_count} problematic files")
    print(f"üéâ All thumbnails now complete!")

if __name__ == "__main__":
    main()
================
File: HIMALAYA PROGRESS REPORT.md
================
üèîÔ∏è HIMALAYA PROGRESS REPORT (ENHANCED BIBLIOGRAPHIC): 1219/1219 (100.0%)
   ‚úÖ Successfully processed: 1219
   üîç OCR extractions: 140
   ‚ö° Enhanced extractions: 20
   üöÄ GPU utilization: 100.0%
   ‚è∞ Timeout protections: 0
   üõ°Ô∏è Corrupted PDFs handled: 0
   üìö BIBLIOGRAPHIC EXTRACTION:
      üìñ ISBNs extracted: 872
      üèõÔ∏è LCCNs extracted: 219 (NEW!)
      üì∞ ISSNs extracted: 34 (NEW!)
      üåê OCLC numbers: 0 (NEW!)
      üîó DOIs extracted: 135
      üè¢ Publishers found: 890
   ‚è±Ô∏è Avg time per PDF: 2.3s
   üïí Est. remaining: 0 minutes
   ‚ùå Errors: 0

================================================================================
üèîÔ∏è HIMALAYA ENHANCED BIBLIOGRAPHIC EXTRACTION COMPLETE!
================================================================================
üìÅ Total PDFs in directory: 1219
‚úÖ Total processed: 1219
üîç OCR extractions performed: 140
‚ö° Enhanced extractions: 20
‚è∞ Timeout protections triggered: 0
üõ°Ô∏è Corrupted PDFs handled gracefully: 0
‚ùå Total errors: 0

üìö BIBLIOGRAPHIC IDENTIFIER EXTRACTION RESULTS:
   üìñ ISBNs: 872 (71.5%)
   üèõÔ∏è LCCNs: 219 (18.0%) ‚ú® NEW!
   üì∞ ISSNs: 34 (2.8%) ‚ú® NEW!
   üåê OCLC: 0 (0.0%) ‚ú® NEW!
   üîó DOIs: 135 (11.1%)
   üè¢ Publishers: 890 (73.0%)
   üìä Total bibliographic identifiers: 2150

üìà Success rate: 100.0%

üéâ ALL PDFs PROCESSED WITH ENHANCED BIBLIOGRAPHIC EXTRACTION!
üìä Enhanced database migration ready with maximum content extraction!
üõ°Ô∏è Zero infinite hangs - timeout protection working perfectly!
üìö Comprehensive bibliographic identifiers extracted!
üîÑ Output: /home/herb/Desktop/BowersWorld-com/AndersonLibrary_Himalaya_GPU.csv
================================================================================
üèîÔ∏è Himalaya enhanced bibliographic extraction complete!

üéâ Enhanced bibliographic Himalaya extraction complete!
üìä Results saved to: /home/herb/Desktop/BowersWorld-com/AndersonLibrary_Himalaya_GPU.csv
üõ°Ô∏è Zero infinite hangs - corruption handled gracefully!
üìö Enhanced bibliographic identifiers extracted successfully!
terminate called without an active exception
Aborted (core dumped)

================
File: HTML/GoogleAuthorzeTest.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Modern Google Identity Services Test</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 2rem; background: #f0f0f0; }
        .container { max-width: 600px; margin: 0 auto; background: white; padding: 2rem; border-radius: 8px; }
        .status { padding: 1rem; margin: 1rem 0; border-radius: 4px; }
        .success { background: #d4edda; color: #155724; }
        .error { background: #f8d7da; color: #721c24; }
        .info { background: #d1ecf1; color: #0c5460; }
        .modern-note { background: #e8f5e8; border: 2px solid #28a745; color: #155724; padding: 1rem; border-radius: 4px; margin: 1rem 0; }
        button { padding: 0.75rem 1.5rem; margin: 0.5rem; background: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; }
        button:hover { background: #0056b3; }
        pre { background: #f8f9fa; padding: 1rem; border-radius: 4px; overflow-x: auto; font-size: 0.9rem; }
        .sign-in-container { margin: 2rem 0; padding: 1rem; border: 2px dashed #007bff; border-radius: 8px; text-align: center; }
        #g_id_signin { margin: 1rem auto; }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ Modern Google Identity Services Test</h1>
        
        <div class="modern-note">
            <strong>‚úÖ Using Google Identity Services (2025)</strong><br>
            This replaces the deprecated gapi.auth2 library with the modern approach.
        </div>

        <div class="sign-in-container">
            <h3>üîê Sign In With Google</h3>
            <p>Click the button below to test modern Google authentication:</p>
            
            <!-- This div will automatically become a Google Sign-In button -->
            <div id="g_id_signin" data-type="standard" data-theme="outline" data-size="large"></div>
            
            <button onclick="requestAccessToken()">üîë Request API Access Token</button>
            <button onclick="testDriveAPI()">üìÅ Test Drive API</button>
        </div>
        
        <div id="status" class="status info">Ready to test modern Google authentication</div>
        <div id="log"><pre>Log will appear here...</pre></div>
    </div>

    <!-- Load Google Identity Services library -->
    <script src="https://accounts.google.com/gsi/client" async defer></script>
    
    <!-- Load Google API Client Library for API calls -->
    <script src="https://apis.google.com/js/api.js" async defer></script>
    
    <script>
        let accessToken = null;
        let gapiLoaded = false;

        function setStatus(message, type = 'info') {
            const statusDiv = document.getElementById('status');
            statusDiv.textContent = message;
            statusDiv.className = `status ${type}`;
        }

        function log(message) {
            const logDiv = document.getElementById('log');
            const timestamp = new Date().toLocaleTimeString();
            logDiv.innerHTML += `[${timestamp}] ${message}\n`;
            console.log(message);
        }

        // Initialize Google Identity Services when page loads
        window.onload = function() {
            log('üöÄ Modern Google Identity Services Test Ready');
            log('üìã Using Google Identity Services (NOT deprecated gapi.auth2)');
            
            // Configure Google Identity Services
            google.accounts.id.initialize({
                client_id: '906077568035-3ofuni3d731kk5m732nbv040j27b5glt.apps.googleusercontent.com',
                callback: handleCredentialResponse,
                auto_select: false,
                cancel_on_tap_outside: false
            });

            // Render the sign-in button
            google.accounts.id.renderButton(
                document.getElementById('g_id_signin'),
                { 
                    type: 'standard',
                    theme: 'outline', 
                    size: 'large',
                    text: 'signin_with',
                    shape: 'rectangular'
                }
            );

            log('‚úÖ Google Identity Services initialized');
            
            // Load Google API client for API calls
            gapi.load('client', initializeGapi);
        };

        function initializeGapi() {
            gapi.client.init({
                apiKey: 'AlzaSyCCcl8l3ws715qCl9W9nLLJu6WZt',
                discoveryDocs: ['https://www.googleapis.com/discovery/v1/apis/drive/v3/rest']
            }).then(() => {
                gapiLoaded = true;
                log('‚úÖ Google API client initialized');
            }).catch(error => {
                log('‚ùå Error initializing Google API client: ' + error.message);
            });
        }

        // Handle sign-in response (authentication)
        function handleCredentialResponse(response) {
            log('üéâ Sign-in successful!');
            log('‚úÖ Received credential: ' + response.credential.substring(0, 50) + '...');
            
            // Decode the JWT token to get user info
            const payload = parseJwt(response.credential);
            log(`‚úÖ Welcome ${payload.name} (${payload.email})`);
            
            setStatus('üéâ Authentication successful! Now you can request API access.', 'success');
        }

        // Request access token for API calls (authorization)
        function requestAccessToken() {
            log('üîê Requesting access token for API access...');
            
            const client = google.accounts.oauth2.initTokenClient({
                client_id: '906077568035-3ofuni3d731kk5m732nbv040j27b5glt.apps.googleusercontent.com',
                scope: 'https://www.googleapis.com/auth/drive.readonly https://www.googleapis.com/auth/userinfo.email',
                callback: (tokenResponse) => {
                    accessToken = tokenResponse.access_token;
                    log('‚úÖ Access token received!');
                    log(`‚úÖ Token: ${accessToken.substring(0, 30)}...`);
                    
                    // Set the token for Google API client
                    gapi.client.setToken({
                        access_token: accessToken
                    });
                    
                    setStatus('üéâ API access token obtained! You can now test APIs.', 'success');
                },
                error_callback: (error) => {
                    log('‚ùå Error getting access token: ' + JSON.stringify(error));
                    setStatus('‚ùå Failed to get access token', 'error');
                }
            });
            
            client.requestAccessToken();
        }

        // Test Drive API call using direct fetch (no manual copying needed!)
        async function testDriveAPI() {
            if (!accessToken) {
                log('‚ö†Ô∏è No access token available. Please request API access first.');
                setStatus('‚ö†Ô∏è Request API access token first', 'error');
                return;
            }

            log('üîÑ Testing Google Drive API directly...');
            log(`üîë Using token: ${accessToken.substring(0, 30)}...`);

            try {
                // Test with user info first (simpler)
                log('üîÑ Step 1: Testing user info API...');
                const userResponse = await fetch('https://www.googleapis.com/oauth2/v2/userinfo', {
                    headers: {
                        'Authorization': `Bearer ${accessToken}`,
                        'Content-Type': 'application/json'
                    }
                });

                if (userResponse.ok) {
                    const userData = await userResponse.json();
                    log('‚úÖ User info API works!');
                    log(`‚úÖ User: ${userData.name} (${userData.email})`);

                    // Now try Drive API
                    log('üîÑ Step 2: Testing Drive API...');
                    const driveResponse = await fetch('https://www.googleapis.com/drive/v3/about?fields=user,storageQuota', {
                        headers: {
                            'Authorization': `Bearer ${accessToken}`,
                            'Content-Type': 'application/json'
                        }
                    });

                    if (driveResponse.ok) {
                        const driveData = await driveResponse.json();
                        log('üéâ Drive API test successful!');
                        log(`‚úÖ Drive User: ${driveData.user.displayName}`);
                        log(`‚úÖ Storage used: ${Math.round(driveData.storageQuota.usage / 1024 / 1024)} MB`);
                        setStatus('üéâ Both APIs working perfectly!', 'success');
                    } else {
                        const errorText = await driveResponse.text();
                        log(`‚ùå Drive API failed: ${driveResponse.status}`);
                        log(`‚ùå Error: ${errorText}`);
                        setStatus('‚ùå Drive API failed - check scopes', 'error');
                    }
                } else {
                    const errorText = await userResponse.text();
                    log(`‚ùå User info API failed: ${userResponse.status}`);
                    log(`‚ùå Error: ${errorText}`);
                    setStatus('‚ùå API access failed - token issue', 'error');
                }

            } catch (error) {
                log('‚ùå Network error: ' + error.message);
                setStatus('‚ùå Network error during API test', 'error');
            }
        }

        // Helper function to decode JWT
        function parseJwt(token) {
            try {
                const base64Url = token.split('.')[1];
                const base64 = base64Url.replace(/-/g, '+').replace(/_/g, '/');
                const jsonPayload = decodeURIComponent(atob(base64).split('').map(function(c) {
                    return '%' + ('00' + c.charCodeAt(0).toString(16)).slice(-2);
                }).join(''));
                return JSON.parse(jsonPayload);
            } catch (error) {
                log('Error parsing JWT: ' + error.message);
                return {};
            }
        }

        // Show/hide one tap prompt
        function showOneTap() {
            google.accounts.id.prompt((notification) => {
                if (notification.isNotDisplayed() || notification.isSkippedMoment()) {
                    log('‚ö†Ô∏è One Tap prompt not displayed or skipped');
                } else {
                    log('‚úÖ One Tap prompt displayed');
                }
            });
        }
    </script>
</body>
</html>
================
File: HimalayaGPUExtractor_Protected.py
================
#!/usr/bin/env python3
# File: HimalayaGPUExtractor_Protected.py
# Path: BowersWorld-com/Scripts/Himalaya/HimalayaGPUExtractor_Protected.py
# Standard: AIDEV-PascalCase-1.8
# Created: 2025-07-02
# Last Modified: 2025-07-02  11:45AM
"""
Description: Himalaya-standard GPU-accelerated PDF text extraction with comprehensive bibliographic data extraction and timeout protection

CRITICAL ENHANCEMENTS:
- Advanced bibliographic identifier extraction (ISBN, LCCN, ISSN, OCLC, DOI)
- Enhanced publisher and metadata extraction with priority searching
- Timeout protection to prevent infinite hangs on corrupted PDFs
- GPU hardware acceleration with intelligent CPU fallback
- Advanced validation and normalization of extracted identifiers
- Multiple extraction strategies with quality scoring

Hardware: RTX 4070 GPU-optimized with CPU fallback
Expected improvements: ISBN 45.7%‚Üí75%+, New LCCN extraction 40-60%, Publisher 28.4%‚Üí65%+

Author: Herb Bowers - Project Himalaya
Contact: HimalayaProject1@gmail.com
"""

import os
import csv
import sqlite3
import time
import signal
from pathlib import Path
import PyPDF2
import pandas as pd
from datetime import datetime
import re
import fitz  # PyMuPDF
import warnings
import tempfile
import threading
warnings.filterwarnings("ignore")

# Core dependencies
import numpy as np
from PIL import Image
from pdf2image import convert_from_path
import pdfplumber

# ===== TIMEOUT PROTECTION CLASSES =====

class TimeoutError(Exception):
    pass

class PDFTimeout:
    """Timeout protection for PDF operations"""
    
    def __init__(self, Seconds, OperationName="PDF operation"):
        self.Seconds = Seconds
        self.OperationName = OperationName
        self.Timer = None
    
    def __enter__(self):
        self.Timer = threading.Timer(self.Seconds, self._TimeoutHandler)
        self.Timer.start()
        return self
    
    def __exit__(self, ExcType, ExcVal, ExcTb):
        if self.Timer:
            self.Timer.cancel()
    
    def _TimeoutHandler(self):
        raise TimeoutError(f"{self.OperationName} timed out after {self.Seconds} seconds")

def TimeoutProtected(TimeoutSeconds):
    """Decorator for timeout protection"""
    def Decorator(Func):
        def Wrapper(*Args, **Kwargs):
            Result = [None]
            Exception = [None]
            
            def Target():
                try:
                    Result[0] = Func(*Args, **Kwargs)
                except Exception as E:
                    Exception[0] = E
            
            Thread = threading.Thread(target=Target)
            Thread.daemon = True
            Thread.start()
            Thread.join(TimeoutSeconds)
            
            if Thread.is_alive():
                # Thread is still running - timeout occurred
                raise TimeoutError(f"Function {Func.__name__} timed out after {TimeoutSeconds} seconds")
            
            if Exception[0]:
                raise Exception[0]
            
            return Result[0]
        return Wrapper
    return Decorator

# ===== CONFIGURATION - HIMALAYA ENHANCED =====

PDF_DIRECTORY = "/home/herb/Desktop/Not Backed Up/Anderson's Library/Andy/Anderson eBooks"
DATABASE_PATH = "/home/herb/Desktop/BowersWorld-com/Assets/my_library.db"
OUTPUT_CSV = "/home/herb/Desktop/BowersWorld-com/AndersonLibrary_Himalaya_GPU.csv"
PROGRESS_INTERVAL = 5

# Himalaya text extraction limits
MAX_TEXT_LENGTH = 20000
MAX_PAGES_TO_PROCESS = 12
OCR_DPI = 350
GPU_BATCH_SIZE = 4

# Timeout settings
PDF_OPEN_TIMEOUT = 15  # seconds to open PDF
PAGE_PROCESS_TIMEOUT = 10  # seconds per page
OCR_TIMEOUT = 45  # seconds for OCR operation
TOTAL_PDF_TIMEOUT = 120  # seconds for entire PDF processing

# ===== ENHANCED BIBLIOGRAPHIC EXTRACTION PATTERNS =====

# Enhanced ISBN Patterns - Multiple formats and contexts
ISBN_PATTERNS = [
    # Standard ISBN with labels
    re.compile(r'ISBN[:\-\s]*(\d{1,5}[\-\s]?\d{1,7}[\-\s]?\d{1,7}[\-\s]?[\dxX])', re.IGNORECASE),
    re.compile(r'ISBN[:\-\s]*(\d{3}[\-\s]?\d{1,5}[\-\s]?\d{1,7}[\-\s]?\d{1,7}[\-\s]?[\dxX])', re.IGNORECASE),
    
    # ISBN in context
    re.compile(r'(?:International Standard Book Number|Book Number|Catalog[ue]? Number)[:\-\s]*(\d{10,17}[\dxX]?)', re.IGNORECASE),
    
    # ISBN in CIP/Library of Congress data
    re.compile(r'(?:Library of Congress|CIP|Cataloging)[^.]*?ISBN[:\-\s]*(\d{10,17}[\dxX]?)', re.IGNORECASE | re.DOTALL),
    
    # Bare ISBN patterns (with word boundaries)
    re.compile(r'\b(\d{3}[\-\s]?\d{1,5}[\-\s]?\d{1,7}[\-\s]?\d{1,7}[\-\s]?[\dxX])\b'),  # 13-digit
    re.compile(r'\b(\d{1,5}[\-\s]?\d{1,7}[\-\s]?\d{1,7}[\-\s]?[\dxX])\b(?=.*book)', re.IGNORECASE),  # 10-digit with context
    
    # Multiple ISBN formats on same line
    re.compile(r'ISBN[:\-\s]*(\d+[\-\s\d]*[\dxX])', re.IGNORECASE),
]

# Library of Congress Control Number (LCCN) Patterns - NEW!
LCCN_PATTERNS = [
    # Standard LCCN formats
    re.compile(r'(?:LCCN|Library of Congress Control Number)[:\-\s]*(\d{8,12})', re.IGNORECASE),
    re.compile(r'(?:LC Control Number|LC Number)[:\-\s]*(\d{8,12})', re.IGNORECASE),
    
    # LCCN in various formats
    re.compile(r'LCCN[:\-\s]*(\d{4}[\-]?\d{6,8})', re.IGNORECASE),
    
    # Library of Congress Card Number (older format)
    re.compile(r'(?:Library of Congress Card Number|LC Card Number)[:\-\s]*(\d{2}[\-]?\d{6,8})', re.IGNORECASE),
    
    # In cataloging-in-publication data
    re.compile(r'(?:Cataloging[^.]*?|CIP[^.]*?)(?:LCCN|Control Number)[:\-\s]*(\d{8,12})', re.IGNORECASE | re.DOTALL),
    
    # LCCN with additional context
    re.compile(r'(?:\d{3}\.\d+[^.]*?)LCCN[:\-\s]*(\d{8,12})', re.IGNORECASE),
]

# ISSN Patterns for Periodicals - NEW!
ISSN_PATTERNS = [
    re.compile(r'ISSN[:\-\s]*(\d{4}[\-]?\d{4})', re.IGNORECASE),
    re.compile(r'(?:International Standard Serial Number)[:\-\s]*(\d{4}[\-]?\d{4})', re.IGNORECASE),
    re.compile(r'(?:Serial Number|Periodical Number)[:\-\s]*(\d{4}[\-]?\d{4})', re.IGNORECASE),
]

# OCLC WorldCat Numbers - NEW!
OCLC_PATTERNS = [
    re.compile(r'OCLC[:\-\s]*(\d{8,12})', re.IGNORECASE),
    re.compile(r'(?:WorldCat|OCLC Number)[:\-\s]*(\d{8,12})', re.IGNORECASE),
    re.compile(r'(?:OCLC|WorldCat)[^.]*?(\d{8,12})', re.IGNORECASE),
]

# Enhanced DOI Patterns
DOI_PATTERNS = [
    re.compile(r'DOI[:\-\s]*(10\.\d+/[^\s\n\r]{1,100})', re.IGNORECASE),
    re.compile(r'(?:Digital Object Identifier)[:\-\s]*(10\.\d+/[^\s\n\r]{1,100})', re.IGNORECASE),
    re.compile(r'https?://(?:dx\.)?doi\.org/(10\.\d+/[^\s\n\r]{1,100})', re.IGNORECASE),
    re.compile(r'doi\.org/(10\.\d+/[^\s\n\r]{1,100})', re.IGNORECASE),
]

# Enhanced Publisher Patterns
PUBLISHER_PATTERNS = [
    # Standard publisher formats
    re.compile(r'Published by[:\s]*([^.\n\r]{5,100})', re.IGNORECASE),
    re.compile(r'Publisher[:\s]*([^.\n\r]{5,100})', re.IGNORECASE),
    
    # Major academic publishers
    re.compile(r'(Academic Press|MIT Press|Cambridge University Press|Oxford University Press|Springer|Wiley|Elsevier|McGraw[- ]?Hill|Pearson|Cengage Learning|Cengage|Thomson|Wadsworth)', re.IGNORECASE),
    
    # Technical publishers
    re.compile(r'(O\'?Reilly Media|O\'?Reilly|Addison[- ]?Wesley|Prentice Hall|No Starch Press|Manning Publications|Pragmatic Bookshelf|Apress|Packt Publishing)', re.IGNORECASE),
    
    # Copyright line publishers
    re.compile(r'¬©\s*\d{4}[^.\n]*?([A-Z][^.\n]{10,50}(?:Press|Publications?|Inc\.?|LLC|Corp\.?))', re.IGNORECASE),
    
    # Imprint information
    re.compile(r'(?:An? )?([^.\n]{5,50})\s+imprint', re.IGNORECASE),
    
    # University presses
    re.compile(r'([^.\n]{5,50}University Press)', re.IGNORECASE),
]

# Enhanced Year Patterns with Priority
YEAR_PATTERNS = [
    # Copyright years (highest priority)
    re.compile(r'¬©\s*(\d{4})', re.IGNORECASE),
    re.compile(r'Copyright[:\s]*¬©?\s*(\d{4})', re.IGNORECASE),
    
    # Publication years
    re.compile(r'Published[^.\n]*?(\d{4})', re.IGNORECASE),
    re.compile(r'Publication[^.\n]*?(\d{4})', re.IGNORECASE),
    
    # Edition years
    re.compile(r'(\d{4})\s+edition', re.IGNORECASE),
    
    # General year pattern (last resort)
    re.compile(r'\b(19\d{2}|20[0-2]\d)\b'),
]

# Enhanced Edition Patterns
EDITION_PATTERNS = [
    re.compile(r'(\d+)(?:st|nd|rd|th)\s+edition', re.IGNORECASE),
    re.compile(r'(\d+)(?:st|nd|rd|th)\s+ed\.?', re.IGNORECASE),
    re.compile(r'(first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth)\s+edition', re.IGNORECASE),
    re.compile(r'edition[:\s]*(\d+)', re.IGNORECASE),
    re.compile(r'(revised|updated|expanded|international|global)\s+edition', re.IGNORECASE),
]

# ===== VALIDATION AND NORMALIZATION FUNCTIONS =====

def ValidateISBN(ISBN: str) -> str:
    """Validate and normalize ISBN"""
    if not ISBN:
        return ''
    
    # Clean ISBN (remove spaces, hyphens)
    CleanISBN = re.sub(r'[\s\-]', '', ISBN.upper())
    
    # Check for valid length and format
    if len(CleanISBN) == 10:
        if re.match(r'^\d{9}[\dX]$', CleanISBN):
            return CleanISBN
    elif len(CleanISBN) == 13:
        if re.match(r'^\d{13}$', CleanISBN):
            return CleanISBN
    elif 10 <= len(CleanISBN) <= 17:
        # Try to extract valid ISBN from longer string
        ISBNMatch = re.search(r'(\d{9}[\dX]|\d{13})', CleanISBN)
        if ISBNMatch:
            return ISBNMatch.group(1)
    
    return ''

def ValidateLCCN(LCCN: str) -> str:
    """Validate and normalize LCCN"""
    if not LCCN:
        return ''
    
    # Clean LCCN (remove spaces, hyphens)
    CleanLCCN = re.sub(r'[\s\-]', '', LCCN)
    
    # Check for valid format (8-12 digits)
    if re.match(r'^\d{8,12}$', CleanLCCN):
        return CleanLCCN
    
    return ''

def ValidateISSN(ISSN: str) -> str:
    """Validate and normalize ISSN"""
    if not ISSN:
        return ''
    
    # Clean ISSN
    CleanISSN = re.sub(r'[\s]', '', ISSN)
    
    # Add hyphen if missing
    if len(CleanISSN) == 8 and '-' not in CleanISSN:
        CleanISSN = CleanISSN[:4] + '-' + CleanISSN[4:]
    
    # Validate format
    if re.match(r'^\d{4}-\d{4}$', CleanISSN):
        return CleanISSN
    
    return ''

def ExtractWithPatterns(Text: str, Patterns: list, Validator=None) -> str:
    """Extract first valid match from multiple patterns with optional validation"""
    for Pattern in Patterns:
        Matches = Pattern.findall(Text)
        for Match in Matches:
            Extracted = Match if isinstance(Match, str) else Match[0] if Match else ''
            if Extracted:
                if Validator:
                    Validated = Validator(Extracted)
                    if Validated:
                        return Validated
                else:
                    return Extracted.strip()
    return ''

# ===== HIMALAYA HARDWARE MANAGER =====

class HimalayaHardwareManager:
    """Himalaya-standard hardware acceleration management"""
    
    def __init__(self):
        print("üèîÔ∏è INITIALIZING HIMALAYA HARDWARE MANAGER")
        print("=" * 60)
        
        self.GPUCapabilities = self.DetectGPUCapabilities()
        self.OCREngines = self.InitializeOCREngines()
        self.PerformanceMetrics = {
            'GPU_Operations': 0,
            'CPU_Operations': 0,
            'GPU_Time': 0.0,
            'CPU_Time': 0.0,
            'GPU_Errors': 0,
            'Fallback_Switches': 0,
            'Total_OCR_Operations': 0,
            'Timeout_Failures': 0
        }
        
        self.ActiveEngine = self.SelectOptimalEngine()
        self.LogHimalayaConfiguration()
    
    def DetectGPUCapabilities(self):
        """Detect RTX 4070 and CUDA capabilities"""
        Capabilities = {
            'CUDA_Available': False,
            'GPU_Name': 'None',
            'GPU_Memory_GB': 0,
            'GPU_Compute_Capability': None,
            'CUDA_Version': None
        }
        
        try:
            import torch
            if torch.cuda.is_available():
                Capabilities['CUDA_Available'] = True
                Capabilities['GPU_Name'] = torch.cuda.get_device_name(0)
                Capabilities['GPU_Memory_GB'] = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                Capabilities['GPU_Compute_Capability'] = torch.cuda.get_device_capability(0)
                Capabilities['CUDA_Version'] = torch.version.cuda
                
                print(f"üöÄ GPU Detected: {Capabilities['GPU_Name']}")
                print(f"üíæ GPU Memory: {Capabilities['GPU_Memory_GB']:.1f} GB")
                print(f"‚ö° CUDA Version: {Capabilities['CUDA_Version']}")
            else:
                print("‚ö†Ô∏è CUDA not available - using CPU fallback")
                
        except ImportError:
            print("‚ö†Ô∏è PyTorch not available - using CPU fallback")
        except Exception as GPUError:
            print(f"‚ö†Ô∏è GPU detection error: {GPUError}")
        
        return Capabilities
    
    def InitializeOCREngines(self):
        """Initialize available OCR engines"""
        Engines = {
            'TesseractGPU': False,
            'TesseractCPU': False,
            'EasyOCR': False,
            'PaddleOCR': False
        }
        
        # Test Tesseract availability
        try:
            import pytesseract
            Engines['TesseractCPU'] = True
            print("‚úÖ Tesseract CPU engine available")
        except ImportError:
            print("‚ùå Tesseract not available")
        
        # Test EasyOCR availability
        try:
            import easyocr
            if self.GPUCapabilities['CUDA_Available']:
                Engines['EasyOCR'] = True
                print("‚úÖ EasyOCR GPU engine available")
            else:
                print("‚ö†Ô∏è EasyOCR available but no GPU")
        except ImportError:
            print("‚ùå EasyOCR not available")
        
        return Engines
    
    def SelectOptimalEngine(self):
        """Select the best available OCR engine"""
        if self.OCREngines['EasyOCR'] and self.GPUCapabilities['CUDA_Available']:
            return 'EasyOCR-GPU'
        elif self.OCREngines['TesseractCPU']:
            return 'Tesseract-CPU'
        else:
            return 'CPU-Fallback'
    
    def LogHimalayaConfiguration(self):
        """Log the Himalaya hardware configuration"""
        print("\nüìã HIMALAYA CONFIGURATION:")
        print(f"   üéØ Active Engine: {self.ActiveEngine}")
        print(f"   üîß GPU Acceleration: {'‚úÖ' if 'GPU' in self.ActiveEngine else '‚ùå'}")
        print(f"   üíæ Available Memory: {self.GPUCapabilities['GPU_Memory_GB']:.1f} GB")
        print(f"   ‚ö° Hardware Ready: {'‚úÖ' if self.ActiveEngine != 'CPU-Fallback' else '‚ö†Ô∏è'}")
    
    def ProcessImageWithOptimalEngine(self, Image, Context=""):
        """Process image with the optimal available engine"""
        StartTime = time.time()
        
        try:
            if self.ActiveEngine == 'EasyOCR-GPU':
                import easyocr
                Reader = easyocr.Reader(['en'], gpu=True)
                Results = Reader.readtext(np.array(Image))
                Text = ' '.join([Result[1] for Result in Results])
                
                self.PerformanceMetrics['GPU_Operations'] += 1
                self.PerformanceMetrics['GPU_Time'] += time.time() - StartTime
                
                return Text
                
            elif self.ActiveEngine == 'Tesseract-CPU':
                import pytesseract
                Text = pytesseract.image_to_string(Image, lang='eng')
                
                self.PerformanceMetrics['CPU_Operations'] += 1
                self.PerformanceMetrics['CPU_Time'] += time.time() - StartTime
                
                return Text
            else:
                return ""
                
        except Exception as OCRError:
            self.PerformanceMetrics['GPU_Errors'] += 1
            print(f"   ‚ùå OCR error ({Context}): {str(OCRError)[:50]}")
            return ""
    
    def GetPerformanceReport(self):
        """Generate performance report"""
        TotalOps = self.PerformanceMetrics['GPU_Operations'] + self.PerformanceMetrics['CPU_Operations']
        
        Report = {
            'GPU_Usage_Percent': (self.PerformanceMetrics['GPU_Operations'] / TotalOps * 100) if TotalOps > 0 else 0,
            'CPU_Usage_Percent': (self.PerformanceMetrics['CPU_Operations'] / TotalOps * 100) if TotalOps > 0 else 0,
            'GPU_Speedup': 0,
            'Average_GPU_Time': 0,
            'Average_CPU_Time': 0,
            'Timeout_Rate': (self.PerformanceMetrics['Timeout_Failures'] / TotalOps * 100) if TotalOps > 0 else 0
        }
        
        if self.PerformanceMetrics['GPU_Operations'] > 0:
            Report['Average_GPU_Time'] = self.PerformanceMetrics['GPU_Time'] / self.PerformanceMetrics['GPU_Operations']
        
        if self.PerformanceMetrics['CPU_Operations'] > 0:
            Report['Average_CPU_Time'] = self.PerformanceMetrics['CPU_Time'] / self.PerformanceMetrics['CPU_Operations']
        
        if Report['Average_GPU_Time'] > 0 and Report['Average_CPU_Time'] > 0:
            Report['GPU_Speedup'] = Report['Average_CPU_Time'] / Report['Average_GPU_Time']
        
        return Report

# ===== MAIN HIMALAYA PDF EXTRACTOR =====

class HimalayaPDFExtractor:
    """TIMEOUT-PROTECTED Himalaya-standard GPU-accelerated PDF extractor with enhanced bibliographic extraction"""
    
    def __init__(self):
        print("üèîÔ∏è INITIALIZING HIMALAYA PDF EXTRACTOR (ENHANCED BIBLIOGRAPHIC)")
        print("Standard: AIDEV-PascalCase-1.8 (Hardware-Accelerated + Timeout Protection + Enhanced Bibliographic)")
        print("=" * 80)
        
        self.PDFDirectory = Path(PDF_DIRECTORY)
        self.DatabasePath = DATABASE_PATH
        self.OutputFile = OUTPUT_CSV
        
        # Initialize Himalaya hardware manager
        self.HardwareManager = HimalayaHardwareManager()
        
        # Processing statistics
        self.ProcessedCount = 0
        self.ErrorCount = 0
        self.OCRCount = 0
        self.EnhancedExtractionCount = 0
        self.TotalProcessingTime = 0.0
        self.TimeoutCount = 0
        self.CorruptedPDFCount = 0
        self.BibliographicHitCount = {
            'ISBN': 0,
            'LCCN': 0,
            'ISSN': 0,
            'OCLC': 0,
            'DOI': 0,
            'Publisher': 0
        }
        
        # Load existing data and database info
        self.LoadExistingData()
        self.LoadDatabaseInfo()
    
    def LoadExistingData(self):
        """Load previously processed PDFs"""
        self.ProcessedFiles = set()
        
        if os.path.exists(self.OutputFile):
            try:
                ExistingDF = pd.read_csv(self.OutputFile)
                self.ProcessedFiles = set(ExistingDF['filename'].str.replace('.pdf', '', regex=False))
                print(f"‚úÖ Resuming: {len(self.ProcessedFiles)} PDFs already processed")
            except Exception as E:
                print(f"‚ö†Ô∏è Could not load existing CSV: {E}")
                self.ProcessedFiles = set()
        else:
            print("üìÑ Starting fresh Himalaya extraction...")
    
    def LoadDatabaseInfo(self):
        """Load existing book data from SQLite database"""
        self.DatabaseBooks = {}
        
        if os.path.exists(self.DatabasePath):
            try:
                Conn = sqlite3.connect(self.DatabasePath)
                Cursor = Conn.cursor()
                
                Query = '''
                    SELECT b.title, c.category, s.subject 
                    FROM books b
                    LEFT JOIN subjects s ON b.subject_id = s.id
                    LEFT JOIN categories c ON s.category_id = c.id
                '''
                
                Books = Cursor.execute(Query).fetchall()
                
                for Title, Category, Subject in Books:
                    self.DatabaseBooks[Title] = {
                        'category': Category or 'Unknown',
                        'subject': Subject or 'Unknown'
                    }
                
                Conn.close()
                print(f"‚úÖ Loaded {len(self.DatabaseBooks)} books from existing database")
                
            except Exception as DbError:
                print(f"‚ö†Ô∏è Database error: {DbError}")
                self.DatabaseBooks = {}
        else:
            print(f"‚ö†Ô∏è Database not found at {self.DatabasePath}")
            self.DatabaseBooks = {}
    
    @TimeoutProtected(TOTAL_PDF_TIMEOUT)
    def ExtractPDFMetadata(self, PDFPath):
        """TIMEOUT-PROTECTED PDF metadata extraction with enhanced bibliographic data"""
        StartTime = time.time()
        
        Metadata = {
            'filename': PDFPath.name,
            'file_size_mb': round(PDFPath.stat().st_size / (1024*1024), 2),
            'pdf_title': '',
            'pdf_author': '',
            'pdf_subject': '',
            'pdf_creator': '',
            'pdf_producer': '',
            'pdf_creation_date': '',
            'page_count': 0,
            'extracted_isbn': '',
            'extracted_lccn': '',      # NEW
            'extracted_issn': '',      # NEW
            'extracted_oclc': '',      # NEW
            'extracted_year': '',
            'extracted_publisher': '',
            'extracted_edition': '',
            'extracted_doi': '',
            'first_page_text': '',
            'title_page_text': '',
            'copyright_page_text': '',
            'table_of_contents': '',
            'full_text_sample': '',
            'abstract_text': '',
            'tables_content': '',
            'database_category': 'Not Found',
            'database_subject': 'Not Found',
            'extraction_method': 'None',
            'ocr_used': False,
            'enhanced_extraction': False,
            'hardware_acceleration': self.HardwareManager.ActiveEngine,
            'extraction_quality_score': 0,
            'processing_time_seconds': 0,
            'gpu_accelerated': 'GPU' in (self.HardwareManager.ActiveEngine or ''),
            'timeout_protection': True,
            'errors': ''
        }
        
        # Get database info
        BookTitle = PDFPath.stem
        if BookTitle in self.DatabaseBooks:
            Metadata['database_category'] = self.DatabaseBooks[BookTitle]['category']
            Metadata['database_subject'] = self.DatabaseBooks[BookTitle]['subject']
        
        ExtractionMethods = []
        ErrorMessages = []
        AllExtractedText = []
        
        # TIMEOUT-PROTECTED Method 1: PyMuPDF primary extraction
        try:
            print(f"   üìÑ PyMuPDF extraction ({PDF_OPEN_TIMEOUT}s timeout)...")
            
            with PDFTimeout(PDF_OPEN_TIMEOUT, "PyMuPDF PDF opening"):
                Doc = fitz.open(str(PDFPath))
                Metadata['page_count'] = len(Doc)
                
                # Extract basic PDF metadata
                PDFMetadata = Doc.metadata
                if PDFMetadata:
                    Metadata['pdf_title'] = (PDFMetadata.get('title') or '').strip()[:500]
                    Metadata['pdf_author'] = (PDFMetadata.get('author') or '').strip()[:200]
                    Metadata['pdf_subject'] = (PDFMetadata.get('subject') or '').strip()[:200]
                    Metadata['pdf_creator'] = (PDFMetadata.get('creator') or '').strip()[:200]
                    Metadata['pdf_producer'] = (PDFMetadata.get('producer') or '').strip()[:200]
                    Metadata['pdf_creation_date'] = (PDFMetadata.get('creationDate') or '').strip()[:50]
                
                # Enhanced text extraction with timeout protection
                TextToProcess = min(MAX_PAGES_TO_PROCESS, len(Doc))
                
                for PageNum in range(TextToProcess):
                    with PDFTimeout(PAGE_PROCESS_TIMEOUT, f"page {PageNum + 1} processing"):
                        Page = Doc[PageNum]
                        PageText = Page.get_text()
                        
                        # Classify and store text by page type and content
                        PageTextLower = PageText.lower()
                        
                        if PageNum == 0:
                            Metadata['first_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        elif PageNum == 1 or 'title' in PageTextLower:
                            if not Metadata['title_page_text']:
                                Metadata['title_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        
                        # Copyright page detection
                        if 'copyright' in PageTextLower or '¬©' in PageText:
                            Metadata['copyright_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        
                        # Table of contents detection
                        if any(keyword in PageTextLower for keyword in ['contents', 'chapter', 'index']):
                            if len(PageText) > len(Metadata['table_of_contents']):
                                Metadata['table_of_contents'] = PageText[:MAX_TEXT_LENGTH]
                        
                        # Abstract detection
                        if 'abstract' in PageTextLower and PageNum < 5:
                            Metadata['abstract_text'] = PageText[:MAX_TEXT_LENGTH//2]
                        
                        AllExtractedText.append(PageText)
                
                # Create full text sample
                if AllExtractedText:
                    Metadata['full_text_sample'] = ' '.join(AllExtractedText)[:MAX_TEXT_LENGTH]
                
                ExtractionMethods.append('PyMuPDF')
                Doc.close()
                print(f"   ‚úÖ PyMuPDF completed: {TextToProcess} pages extracted")
            
        except TimeoutError:
            ErrorMessages.append("PyMuPDF: Timeout")
            print(f"   ‚è∞ PyMuPDF timed out")
        except Exception as PyMuPDFError:
            ErrorMessages.append(f"PyMuPDF: {str(PyMuPDFError)[:100]}")
            print(f"   ‚ùå PyMuPDF failed: {str(PyMuPDFError)[:50]}")
        
        # TIMEOUT-PROTECTED Method 2: PDFPlumber enhanced extraction
        TextQuality = len(' '.join(filter(None, [
            Metadata.get('first_page_text', ''),
            Metadata.get('title_page_text', ''),
            Metadata.get('copyright_page_text', '')
        ])).strip())
        
        if TextQuality < 500:
            try:
                print(f"   üîß PDFPlumber extraction (20s timeout)...")
                
                @TimeoutProtected(20)
                def ExtractWithPlumber():
                    with pdfplumber.open(PDFPath) as PDF:
                        # Enhanced metadata extraction
                        if PDF.metadata:
                            for Key, Value in PDF.metadata.items():
                                if Key == 'Title' and not Metadata['pdf_title']:
                                    Metadata['pdf_title'] = str(Value).strip()[:500]
                                elif Key == 'Author' and not Metadata['pdf_author']:
                                    Metadata['pdf_author'] = str(Value).strip()[:200]
                        
                        # Extract tables with timeout protection
                        TablesContent = []
                        PagesToCheck = min(4, len(PDF.pages))
                        
                        for PageNum in range(PagesToCheck):
                            Page = PDF.pages[PageNum]
                            Tables = Page.extract_tables()
                            if Tables:
                                for TableNum, Table in enumerate(Tables[:2]):
                                    TableText = f"Table {TableNum + 1} (Page {PageNum + 1}):\n"
                                    for Row in Table[:10]:
                                        if Row:
                                            TableText += " | ".join(str(Cell)[:50] if Cell else "" for Cell in Row) + "\n"
                                    TablesContent.append(TableText)
                        
                        return TablesContent
                
                TablesContent = ExtractWithPlumber()
                
                if TablesContent:
                    ExtractionMethods.append('PDFPlumber')
                    Metadata['enhanced_extraction'] = True
                    Metadata['tables_content'] = '\n'.join(TablesContent)[:MAX_TEXT_LENGTH]
                    self.EnhancedExtractionCount += 1
                    print(f"   ‚úÖ PDFPlumber completed: {len(TablesContent)} tables extracted")
            
            except TimeoutError:
                ErrorMessages.append("PDFPlumber: Timeout after 20 seconds")
                print(f"   ‚è∞ PDFPlumber timed out")
            except Exception as PlumberError:
                ErrorMessages.append(f"PDFPlumber: {str(PlumberError)[:100]}")
                print(f"   ‚ùå PDFPlumber failed: {str(PlumberError)[:50]}")
        
        # TIMEOUT-PROTECTED Method 3: Himalaya GPU-accelerated OCR
        if TextQuality < 200:
            try:
                print(f"   üîç OCR processing ({OCR_TIMEOUT}s timeout)...")
                OCRData = self.ExtractTextWithHimalayaOCR(PDFPath)
                ExtractionMethods.append('HimalayaOCR')
                Metadata['ocr_used'] = True
                
                # Use OCR text if better than existing extraction
                for Field in OCRData:
                    if len(OCRData[Field]) > len(Metadata.get(Field, '')):
                        Metadata[Field] = OCRData[Field]
                
                AllExtractedText.extend(OCRData.values())
                print(f"   ‚úÖ OCR completed: {len([V for V in OCRData.values() if V])} fields populated")
            
            except TimeoutError:
                ErrorMessages.append("HimalayaOCR: Timeout")
                print(f"   ‚è∞ OCR timed out - continuing without OCR")
            except Exception as OCRError:
                ErrorMessages.append(f"HimalayaOCR: {str(OCRError)[:100]}")
                print(f"   ‚ùå OCR failed: {str(OCRError)[:50]}")
        
        # ===== ENHANCED BIBLIOGRAPHIC INFORMATION EXTRACTION =====
        # Combine all text with priority weighting
        AllText = ' '.join(filter(None, AllExtractedText))[:100000]
        
        # Prioritize copyright and title page text for bibliographic extraction
        CopyrightText = Metadata.get('copyright_page_text', '')
        TitleText = Metadata.get('title_page_text', '')
        
        # Create priority text search order
        SearchTexts = [
            (CopyrightText, 3),  # Highest priority - copyright pages have most metadata
            (TitleText, 2),      # Medium priority - title pages  
            (AllText[:25000], 1) # Lower priority, limited text to avoid noise
        ]
        
        # Extract ISBNs with enhanced validation
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_isbn']:
                for Pattern in ISBN_PATTERNS:
                    Matches = Pattern.findall(Text)
                    for Match in Matches:
                        ISBN = ValidateISBN(Match)
                        if ISBN:
                            Metadata['extracted_isbn'] = ISBN
                            self.BibliographicHitCount['ISBN'] += 1
                            break
                    if Metadata['extracted_isbn']:
                        break
        
        # Extract LCCNs (NEW) - Library of Congress Control Numbers
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_lccn']:
                for Pattern in LCCN_PATTERNS:
                    Matches = Pattern.findall(Text)
                    for Match in Matches:
                        LCCN = ValidateLCCN(Match)
                        if LCCN:
                            Metadata['extracted_lccn'] = LCCN
                            self.BibliographicHitCount['LCCN'] += 1
                            break
                    if Metadata['extracted_lccn']:
                        break
        
        # Extract ISSNs (NEW) - International Standard Serial Numbers
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_issn']:
                ISSNMatch = ExtractWithPatterns(Text, ISSN_PATTERNS)
                if ISSNMatch:
                    CleanISSN = re.sub(r'[\s]', '', ISSNMatch)
                    if len(CleanISSN) == 8:
                        CleanISSN = CleanISSN[:4] + '-' + CleanISSN[4:]
                    if re.match(r'^\d{4}-\d{4}$', CleanISSN):
                        Metadata['extracted_issn'] = CleanISSN
                        self.BibliographicHitCount['ISSN'] += 1
                        break
        
        # Extract OCLC numbers (NEW) - WorldCat catalog numbers
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_oclc']:
                OCLCMatch = ExtractWithPatterns(Text, OCLC_PATTERNS)
                if OCLCMatch and re.match(r'^\d{8,12}$', OCLCMatch):
                    Metadata['extracted_oclc'] = OCLCMatch
                    self.BibliographicHitCount['OCLC'] += 1
                    break
        
        # Enhanced DOI extraction
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_doi']:
                DOIMatch = ExtractWithPatterns(Text, DOI_PATTERNS)
                if DOIMatch:
                    Metadata['extracted_doi'] = DOIMatch
                    self.BibliographicHitCount['DOI'] += 1
                    break
        
        # Enhanced year extraction with priority
        YearCandidates = []
        for Text, Priority in SearchTexts:
            if Text:
                for Pattern in YEAR_PATTERNS:
                    Years = Pattern.findall(Text)
                    for Year in Years:
                        try:
                            YearInt = int(Year)
                            if 1900 <= YearInt <= 2030:
                                YearCandidates.append((YearInt, Priority))
                        except:
                            continue
        
        if YearCandidates:
            # Sort by priority then by most recent year
            YearCandidates.sort(key=lambda x: (x[1], x[0]), reverse=True)
            Metadata['extracted_year'] = str(YearCandidates[0][0])
        
        # Enhanced publisher extraction with priority
        PublisherCandidates = []
        for Text, Priority in SearchTexts:
            if Text:
                for Pattern in PUBLISHER_PATTERNS:
                    Publishers = Pattern.findall(Text)
                    for Pub in Publishers:
                        if len(Pub.strip()) >= 5:
                            PublisherCandidates.append((Pub.strip()[:200], Priority))
        
        if PublisherCandidates:
            PublisherCandidates.sort(key=lambda x: x[1], reverse=True)
            Metadata['extracted_publisher'] = PublisherCandidates[0][0]
            self.BibliographicHitCount['Publisher'] += 1
        
        # Enhanced edition extraction
        for Text, Priority in SearchTexts:
            if Text and not Metadata['extracted_edition']:
                EditionMatch = ExtractWithPatterns(Text, EDITION_PATTERNS)
                if EditionMatch:
                    Metadata['extracted_edition'] = EditionMatch.strip()
                    break
        
        # Enhanced Himalaya quality scoring with bibliographic weighting
        QualityFactors = [
            bool(Metadata['pdf_title']) * 10,
            bool(Metadata['pdf_author']) * 10,
            bool(Metadata['extracted_isbn']) * 20,     # Increased weight for ISBN
            bool(Metadata['extracted_lccn']) * 15,     # NEW: LCCN highly valued
            bool(Metadata['extracted_issn']) * 10,     # NEW: ISSN for periodicals
            bool(Metadata['extracted_oclc']) * 5,      # NEW: OCLC catalog numbers
            bool(Metadata['extracted_year']) * 10,
            bool(Metadata['extracted_publisher']) * 10,
            bool(Metadata['first_page_text']) * 15,
            bool(Metadata['title_page_text']) * 10,
            bool(Metadata['copyright_page_text']) * 10,
            bool(Metadata['full_text_sample']) * 5,
            bool(Metadata['abstract_text']) * 5,
            bool(Metadata['tables_content']) * 5,
            bool(Metadata['ocr_used']) * 10,
            bool(Metadata['enhanced_extraction']) * 5,
            min(len(AllText) / 150, 15)
        ]
        
        Metadata['extraction_quality_score'] = min(100, sum(QualityFactors))
        
        # Processing metadata
        ProcessingTime = time.time() - StartTime
        Metadata['processing_time_seconds'] = round(ProcessingTime, 2)
        Metadata['extraction_method'] = '+'.join(ExtractionMethods) if ExtractionMethods else 'Failed'
        Metadata['errors'] = '; '.join(ErrorMessages) if ErrorMessages else ''
        
        self.TotalProcessingTime += ProcessingTime
        
        return Metadata
    
    @TimeoutProtected(OCR_TIMEOUT)
    def ExtractTextWithHimalayaOCR(self, PDFPath):
        """TIMEOUT-PROTECTED Himalaya OCR extraction"""
        OCRText = {
            'first_page_text': '',
            'title_page_text': '',
            'copyright_page_text': '',
            'table_of_contents': '',
            'full_text_sample': '',
            'abstract_text': ''
        }
        
        if not self.HardwareManager.ActiveEngine:
            return OCRText
        
        try:
            with tempfile.TemporaryDirectory() as TempDir:
                # Reduced settings for reliability
                Pages = convert_from_path(
                    PDFPath, 
                    dpi=200,  # Reduced from 350
                    first_page=1,
                    last_page=min(6, 10),  # Max 6 pages
                    output_folder=TempDir
                )
                
                PagesToProcess = min(4, len(Pages))  # Process max 4 pages
                
                for PageNum in range(PagesToProcess):
                    try:
                        PageImage = Pages[PageNum]
                        PageText = self.HardwareManager.ProcessImageWithOptimalEngine(
                            PageImage, 
                            f"page {PageNum + 1} of {PDFPath.name}"
                        )
                        
                        # Enhanced content classification
                        PageTextLower = PageText.lower()
                        
                        # Store by page position
                        if PageNum == 0:
                            OCRText['first_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        elif PageNum == 1:
                            OCRText['title_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        
                        # Store by content type
                        if 'copyright' in PageTextLower or '¬©' in PageText:
                            OCRText['copyright_page_text'] = PageText[:MAX_TEXT_LENGTH]
                        
                        if any(Keyword in PageTextLower for Keyword in ['contents', 'chapter', 'index']):
                            if len(PageText) > len(OCRText['table_of_contents']):
                                OCRText['table_of_contents'] = PageText[:MAX_TEXT_LENGTH]
                        
                        if 'abstract' in PageTextLower and PageNum < 3:
                            OCRText['abstract_text'] = PageText[:MAX_TEXT_LENGTH//2]
                        
                        # Collect for full text sample
                        if not OCRText['full_text_sample']:
                            OCRText['full_text_sample'] = PageText[:MAX_TEXT_LENGTH]
                        
                    except Exception as PageError:
                        print(f"   ‚ö†Ô∏è OCR page {PageNum + 1} error: {str(PageError)[:50]}")
                        continue
                
                self.OCRCount += 1
                return OCRText
                
        except Exception as OCRError:
            print(f"   ‚ùå OCR processing failed: {str(OCRError)[:50]}")
            return OCRText
    
    def ProcessAllPDFs(self):
        """Process all PDFs in the directory with enhanced progress reporting"""
        if not self.PDFDirectory.exists():
            print(f"‚ùå PDF directory not found: {self.PDFDirectory}")
            return False
        
        PDFFiles = list(self.PDFDirectory.glob("*.pdf"))
        TotalFiles = len(PDFFiles)
        
        if TotalFiles == 0:
            print(f"‚ùå No PDF files found in {self.PDFDirectory}")
            return False
        
        # Filter out already processed files
        UnprocessedFiles = [F for F in PDFFiles if F.stem not in self.ProcessedFiles]
        RemainingCount = len(UnprocessedFiles)
        
        print(f"\nüìä HIMALAYA EXTRACTION SUMMARY:")
        print(f"   üìÅ Total PDFs found: {TotalFiles}")
        print(f"   ‚úÖ Previously processed: {len(self.ProcessedFiles)}")
        print(f"   üîÑ Remaining to process: {RemainingCount}")
        
        if RemainingCount == 0:
            print(f"\nüéâ All PDFs already processed!")
            print(f"üìä Enhanced database migration ready with maximum content extraction!")
            print(f"üõ°Ô∏è Zero infinite hangs - timeout protection working perfectly!")
            print(f"üîÑ Output: {self.OutputFile}")
        else:
            Missing = TotalFiles - len(self.ProcessedFiles) - self.ProcessedCount
            print(f"\n‚ö†Ô∏è {Missing} PDFs still need processing")
            print(f"üîÑ Run the script again to continue")
        
        if RemainingCount == 0:
            return True
        
        print(f"üîÑ Starting timeout-protected Himalaya extraction of {RemainingCount} files...\n")
        
        # Process PDFs with timeout protection
        for FileIndex, PDFFile in enumerate(UnprocessedFiles, 1):
            try:
                print(f"[{FileIndex:4d}/{RemainingCount}] Processing: {PDFFile.name}")
                
                # TIMEOUT-PROTECTED EXTRACTION
                try:
                    ExtractedMetadata = self.ExtractPDFMetadata(PDFFile)
                    self.AppendToCSV(ExtractedMetadata)
                    self.ProcessedCount += 1
                    
                    # Display results with bibliographic info
                    Quality = ExtractedMetadata['extraction_quality_score']
                    ProcessingTime = ExtractedMetadata['processing_time_seconds']
                    
                    StatusFlags = []
                    if ExtractedMetadata['ocr_used']:
                        StatusFlags.append("üîç OCR")
                    if ExtractedMetadata['enhanced_extraction']:
                        StatusFlags.append("‚ö° Enhanced")
                    if ExtractedMetadata['gpu_accelerated']:
                        StatusFlags.append("üöÄ GPU")
                    if ExtractedMetadata.get('timeout_protection'):
                        StatusFlags.append("‚è∞ Protected")
                    
                    # Add bibliographic flags
                    BibFlags = []
                    if ExtractedMetadata['extracted_isbn']:
                        BibFlags.append("üìö ISBN")
                    if ExtractedMetadata['extracted_lccn']:
                        BibFlags.append("üèõÔ∏è LCCN")
                    if ExtractedMetadata['extracted_issn']:
                        BibFlags.append("üì∞ ISSN")
                    if ExtractedMetadata['extracted_oclc']:
                        BibFlags.append("üåê OCLC")
                    
                    AllFlags = StatusFlags + BibFlags
                    Status = " ".join(AllFlags) if AllFlags else "üìÑ Text"
                    print(f"   ‚úÖ Quality: {Quality:.0f}% | Time: {ProcessingTime:.1f}s | {Status}")
                
                except TimeoutError:
                    # Handle timeout gracefully
                    print(f"   ‚è∞ TIMEOUT after {TOTAL_PDF_TIMEOUT}s - marking as corrupted PDF")
                    
                    CorruptedMetadata = {
                        'filename': PDFFile.name,
                        'file_size_mb': round(PDFFile.stat().st_size / (1024*1024), 2),
                        'page_count': 0,
                        'database_category': 'Corrupted',
                        'database_subject': 'Corrupted',
                        'pdf_title': 'CORRUPTED PDF - TIMEOUT',
                        'extraction_method': 'Timeout Protection',
                        'errors': f'Timeout after {TOTAL_PDF_TIMEOUT}s - likely corrupted PDF structure',
                        'extraction_quality_score': 0,
                        'processing_time_seconds': TOTAL_PDF_TIMEOUT,
                        'timeout_protection': True
                    }
                    
                    # Fill in missing fields with empty values
                    CSVColumns = [
                        'pdf_author', 'pdf_subject', 'pdf_creator', 'pdf_producer',
                        'pdf_creation_date', 'extracted_isbn', 'extracted_lccn', 'extracted_issn',
                        'extracted_oclc', 'extracted_year', 'extracted_publisher', 'extracted_edition', 
                        'extracted_doi', 'first_page_text', 'title_page_text', 'copyright_page_text',
                        'table_of_contents', 'full_text_sample', 'abstract_text', 'tables_content',
                        'ocr_used', 'enhanced_extraction', 'hardware_acceleration', 'gpu_accelerated'
                    ]
                    
                    for Col in CSVColumns:
                        if Col not in CorruptedMetadata:
                            if Col in ['ocr_used', 'enhanced_extraction', 'gpu_accelerated']:
                                CorruptedMetadata[Col] = False
                            else:
                                CorruptedMetadata[Col] = ''
                    
                    self.AppendToCSV(CorruptedMetadata)
                    self.TimeoutCount += 1
                    self.CorruptedPDFCount += 1
                    
                    print(f"   üõ°Ô∏è Timeout protection prevented infinite hang - continuing...")
                
                # Progress reporting
                if FileIndex % PROGRESS_INTERVAL == 0:
                    self.ShowHimalayaProgress(FileIndex, RemainingCount)
                
            except Exception as ProcessingError:
                print(f"   ‚ùå Critical error processing {PDFFile.name}: {ProcessingError}")
                self.ErrorCount += 1
                continue
        
        # Final reporting
        self.ShowHimalayaProgress(RemainingCount, RemainingCount)
        self.GenerateHimalayaReport(TotalFiles, len(self.ProcessedFiles) + self.ProcessedCount)
        
        return True
    
    def AppendToCSV(self, BookData):
        """Append record to Himalaya CSV with enhanced bibliographic fields"""
        FileExists = os.path.exists(self.OutputFile)
        
        # Himalaya enhanced CSV columns with new bibliographic fields
        Columns = [
            'filename', 'file_size_mb', 'page_count',
            'database_category', 'database_subject',
            'pdf_title', 'pdf_author', 'pdf_subject', 'pdf_creator', 'pdf_producer',
            'pdf_creation_date', 'extracted_isbn', 'extracted_lccn', 'extracted_issn',
            'extracted_oclc', 'extracted_year', 'extracted_publisher', 'extracted_edition', 
            'extracted_doi', 'first_page_text', 'title_page_text', 'copyright_page_text',
            'table_of_contents', 'full_text_sample', 'abstract_text', 'tables_content',
            'extraction_method', 'ocr_used', 'enhanced_extraction',
            'hardware_acceleration', 'gpu_accelerated', 'timeout_protection',
            'extraction_quality_score', 'processing_time_seconds', 'errors'
        ]
        
        try:
            with open(self.OutputFile, 'a', newline='', encoding='utf-8') as CSVFile:
                Writer = csv.DictWriter(CSVFile, fieldnames=Columns)
                
                if not FileExists:
                    Writer.writeheader()
                
                Writer.writerow(BookData)
                
        except Exception as SaveError:
            print(f"‚ùå Error appending to CSV: {SaveError}")
    
    def ShowHimalayaProgress(self, Current, Total):
        """Enhanced progress reporting with bibliographic metrics"""
        ProcessedPct = (Current / Total) * 100
        
        # Get hardware performance report
        Performance = self.HardwareManager.GetPerformanceReport()
        
        AvgProcessingTime = self.TotalProcessingTime / Current if Current > 0 else 0
        EstimatedRemaining = (Total - Current) * AvgProcessingTime / 60  # minutes
        
        print(f"\nüèîÔ∏è HIMALAYA PROGRESS REPORT (ENHANCED BIBLIOGRAPHIC): {Current}/{Total} ({ProcessedPct:.1f}%)")
        print(f"   ‚úÖ Successfully processed: {self.ProcessedCount}")
        print(f"   üîç OCR extractions: {self.OCRCount}")
        print(f"   ‚ö° Enhanced extractions: {self.EnhancedExtractionCount}")
        print(f"   üöÄ GPU utilization: {Performance['GPU_Usage_Percent']:.1f}%")
        print(f"   ‚è∞ Timeout protections: {self.TimeoutCount}")
        print(f"   üõ°Ô∏è Corrupted PDFs handled: {self.CorruptedPDFCount}")
        
        # Enhanced bibliographic reporting
        print(f"   üìö BIBLIOGRAPHIC EXTRACTION:")
        print(f"      üìñ ISBNs extracted: {self.BibliographicHitCount['ISBN']}")
        print(f"      üèõÔ∏è LCCNs extracted: {self.BibliographicHitCount['LCCN']} (NEW!)")
        print(f"      üì∞ ISSNs extracted: {self.BibliographicHitCount['ISSN']} (NEW!)")
        print(f"      üåê OCLC numbers: {self.BibliographicHitCount['OCLC']} (NEW!)")
        print(f"      üîó DOIs extracted: {self.BibliographicHitCount['DOI']}")
        print(f"      üè¢ Publishers found: {self.BibliographicHitCount['Publisher']}")
        
        if Performance['GPU_Speedup'] > 0:
            print(f"   ‚ö° GPU speedup: {Performance['GPU_Speedup']:.1f}x")
        
        print(f"   ‚è±Ô∏è Avg time per PDF: {AvgProcessingTime:.1f}s")
        print(f"   üïí Est. remaining: {EstimatedRemaining:.0f} minutes")
        print(f"   ‚ùå Errors: {self.ErrorCount}")
        print()
    
    def GenerateHimalayaReport(self, TotalInDirectory, TotalProcessed):
        """Generate comprehensive Himalaya performance report with enhanced bibliographic metrics"""
        print("\n" + "=" * 80)
        print("üèîÔ∏è HIMALAYA ENHANCED BIBLIOGRAPHIC EXTRACTION COMPLETE!")
        print("=" * 80)
        
        # Basic statistics
        print(f"üìÅ Total PDFs in directory: {TotalInDirectory}")
        print(f"‚úÖ Total processed: {TotalProcessed}")
        print(f"üîç OCR extractions performed: {self.OCRCount}")
        print(f"‚ö° Enhanced extractions: {self.EnhancedExtractionCount}")
        print(f"‚è∞ Timeout protections triggered: {self.TimeoutCount}")
        print(f"üõ°Ô∏è Corrupted PDFs handled gracefully: {self.CorruptedPDFCount}")
        print(f"‚ùå Total errors: {self.ErrorCount}")
        
        # Enhanced bibliographic reporting
        print(f"\nüìö BIBLIOGRAPHIC IDENTIFIER EXTRACTION RESULTS:")
        TotalBiblio = sum(self.BibliographicHitCount.values())
        if TotalProcessed > 0:
            print(f"   üìñ ISBNs: {self.BibliographicHitCount['ISBN']} ({self.BibliographicHitCount['ISBN']/TotalProcessed*100:.1f}%)")
            print(f"   üèõÔ∏è LCCNs: {self.BibliographicHitCount['LCCN']} ({self.BibliographicHitCount['LCCN']/TotalProcessed*100:.1f}%) ‚ú® NEW!")
            print(f"   üì∞ ISSNs: {self.BibliographicHitCount['ISSN']} ({self.BibliographicHitCount['ISSN']/TotalProcessed*100:.1f}%) ‚ú® NEW!")
            print(f"   üåê OCLC: {self.BibliographicHitCount['OCLC']} ({self.BibliographicHitCount['OCLC']/TotalProcessed*100:.1f}%) ‚ú® NEW!")
            print(f"   üîó DOIs: {self.BibliographicHitCount['DOI']} ({self.BibliographicHitCount['DOI']/TotalProcessed*100:.1f}%)")
            print(f"   üè¢ Publishers: {self.BibliographicHitCount['Publisher']} ({self.BibliographicHitCount['Publisher']/TotalProcessed*100:.1f}%)")
            print(f"   üìä Total bibliographic identifiers: {TotalBiblio}")
        
        SuccessRate = ((TotalProcessed - self.ErrorCount) / TotalInDirectory * 100) if TotalInDirectory > 0 else 0
        print(f"\nüìà Success rate: {SuccessRate:.1f}%")
        
        if TotalProcessed == TotalInDirectory:
            print(f"\nüéâ ALL PDFs PROCESSED WITH ENHANCED BIBLIOGRAPHIC EXTRACTION!")
            print(f"üìä Enhanced database migration ready with maximum content extraction!")
            print(f"üõ°Ô∏è Zero infinite hangs - timeout protection working perfectly!")
            print(f"üìö Comprehensive bibliographic identifiers extracted!")
            print(f"üîÑ Output: {self.OutputFile}")
        else:
            Missing = TotalInDirectory - TotalProcessed
            print(f"\n‚ö†Ô∏è {Missing} PDFs still need processing")
            print(f"üîÑ Run the script again to continue")
        
        print("=" * 80)
        print("üèîÔ∏è Himalaya enhanced bibliographic extraction complete!")

if __name__ == "__main__":
    print("üèîÔ∏è HIMALAYA ENHANCED BIBLIOGRAPHIC GPU PDF EXTRACTOR")
    print("Standard: AIDEV-PascalCase-1.8 (Hardware-Accelerated + Timeout Protection + Enhanced Bibliographic)")
    print("Enhanced Features: ISBN, LCCN, ISSN, OCLC, DOI extraction with validation")
    print("Expected Improvements: ISBN 45.7%‚Üí75%+, New LCCN 40-60%, Publisher 28.4%‚Üí65%+")
    print("=" * 80)
    
    # Run enhanced Himalaya extraction
    Extractor = HimalayaPDFExtractor()
    Success = Extractor.ProcessAllPDFs()
    
    if Success:
        print(f"\nüéâ Enhanced bibliographic Himalaya extraction complete!")
        print(f"üìä Results saved to: {OUTPUT_CSV}")
        print(f"üõ°Ô∏è Zero infinite hangs - corruption handled gracefully!")
        print(f"üìö Enhanced bibliographic identifiers extracted successfully!")
    else:
        print(f"\n‚ùå Himalaya extraction failed!")
        exit(1)
================
File: MigrateToEnhancedSchema.py
================
#!/usr/bin/env python3
"""
File: MigrateToEnhancedSchema.py
Path: BowersWorld-com/Scripts/Migration/MigrateToEnhancedSchema.py
Standard: AIDEV-PascalCase-1.8
Created: 2025-06-30
Modified: 2025-06-30
Author: Herb Bowers - Project Himalaya
Description: Migrate existing library data to enhanced MyLibrary.db schema

Purpose: Takes your CSV metadata and existing SQLite database and migrates
to the new enhanced schema with full AI classification support.
"""

import sqlite3
import pandas as pd
import json
import hashlib
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple

class LibraryDataMigrator:
    """Migrates Anderson's Library data to enhanced schema"""
    
    def __init__(self, 
                 OldDatabasePath: str,
                 CSVPath: str,
                 NewDatabasePath: str,
                 BooksDirectory: str,
                 CoversDirectory: str,
                 ThumbnailsDirectory: str):
        """Initialize migrator with file paths"""
        self.OldDatabasePath = "Data/Databases/my_library.db"
        self.CSVPath = "Data/Spreadsheets/AndersonLibrary_PDFMetadata.csv"
        self.NewDatabasePath = "Data/Databases/MyLibrary.db"
        self.BooksDirectory = Path("Data/Books")
        self.CoversDirectory = Path("Data/Covers")
        self.ThumbnailsDirectory = Path("Data/Thumbs")
        
        # Load CSV data
        self.CSVData = pd.read_csv(CSVPath).fillna('')
        print(f"‚úÖ Loaded {len(self.CSVData)} records from CSV")
        
        # Statistics
        self.StatsCounters = {
            'CategoriesMigrated': 0,
            'SubjectsMigrated': 0,
            'BooksMigrated': 0,
            'ContentProcessed': 0,
            'ErrorsEncountered': 0
        }

    def ExecuteMigration(self) -> bool:
        """Execute complete migration process"""
        try:
            print("üöÄ Starting Anderson's Library data migration...")
            
            # Create new database with enhanced schema
            self.CreateEnhancedDatabase()
            
            # Migrate categories and subjects
            self.MigrateCategories()
            self.MigrateSubjects()
            
            # Migrate books with enhanced metadata
            self.MigrateBooks()
            
            # Process content for full-text search
            self.ProcessBookContent()
            
            # Generate initial analytics
            self.GenerateInitialAnalytics()
            
            # Generate migration report
            self.GenerateReport()
            
            # Export MySQL conversion instructions
            self.ExportForMySQL()
            
            print("‚úÖ Migration completed successfully!")
            return True
            
        except Exception as Error:
            print(f"‚ùå Migration failed: {Error}")
            return False

    def CreateEnhancedDatabase(self):
        """Create new database with enhanced schema"""
        print("üìÑ Creating enhanced database schema...")
        
        # Delete old database if it exists
        if os.path.exists(self.NewDatabasePath):
            os.remove(self.NewDatabasePath)
            print("üóëÔ∏è Removed old database")
            
        # Read schema from file or create inline
        SchemaSQL = self.GetEnhancedSchema()
        
        # Create database
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        # Execute schema
        Cursor.executescript(SchemaSQL)
        Connection.commit()
        Connection.close()
        
        print("‚úÖ Enhanced schema created")

    def MigrateCategories(self):
        """Migrate categories from old database and CSV data"""
        print("üìÇ Migrating categories...")
        
        # Get unique categories from CSV
        UniqueCategories = self.CSVData['database_category'].dropna().unique()
        
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        for CategoryName in UniqueCategories:
            if CategoryName and CategoryName != 'Not Found':
                try:
                    Cursor.execute("""
                        INSERT OR IGNORE INTO Categories (CategoryName, Description, CreatedDate)
                        VALUES (?, ?, ?)
                    """, (CategoryName, f"Migrated category: {CategoryName}", datetime.now().isoformat()))
                    
                    if Cursor.rowcount > 0:
                        self.StatsCounters['CategoriesMigrated'] += 1
                        
                except Exception as Error:
                    print(f"‚ö†Ô∏è Error inserting category {CategoryName}: {Error}")
                    self.StatsCounters['ErrorsEncountered'] += 1
        
        Connection.commit()
        Connection.close()
        
        print(f"‚úÖ Migrated {self.StatsCounters['CategoriesMigrated']} categories")

    def MigrateSubjects(self):
        """Migrate subjects with category relationships"""
        print("üìö Migrating subjects...")
        
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        # Get category ID mapping
        CategoryMapping = {}
        Cursor.execute("SELECT CategoryID, CategoryName FROM Categories")
        for CategoryID, CategoryName in Cursor.fetchall():
            CategoryMapping[CategoryName] = CategoryID
        
        # Process unique category/subject combinations
        SubjectData = self.CSVData[['database_category', 'database_subject']].dropna()
        UniqueSubjects = SubjectData.drop_duplicates()
        
        for _, Row in UniqueSubjects.iterrows():
            Category = Row['database_category']
            Subject = Row['database_subject']
            
            if Category in CategoryMapping and Subject and Subject != 'Not Found':
                try:
                    CategoryID = CategoryMapping[Category]
                    
                    Cursor.execute("""
                        INSERT OR IGNORE INTO Subjects (SubjectName, CategoryID, Description, CreatedDate)
                        VALUES (?, ?, ?, ?)
                    """, (Subject, CategoryID, f"Migrated subject: {Subject}", datetime.now().isoformat()))
                    
                    if Cursor.rowcount > 0:
                        self.StatsCounters['SubjectsMigrated'] += 1
                        
                except Exception as Error:
                    print(f"‚ö†Ô∏è Error inserting subject {Subject}: {Error}")
                    self.StatsCounters['ErrorsEncountered'] += 1
        
        Connection.commit()
        Connection.close()
        
        print(f"‚úÖ Migrated {self.StatsCounters['SubjectsMigrated']} subjects")

    def MigrateBooks(self):
        """Migrate books with all metadata"""
        print("üìñ Migrating books with enhanced metadata...")
        
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        # Get category and subject ID mappings
        CategoryMapping = {}
        SubjectMapping = {}
        
        Cursor.execute("SELECT CategoryID, CategoryName FROM Categories")
        for CategoryID, CategoryName in Cursor.fetchall():
            CategoryMapping[CategoryName] = CategoryID
            
        Cursor.execute("SELECT SubjectID, SubjectName, CategoryID FROM Subjects")
        SubjectMappingRaw = Cursor.fetchall()
        for SubjectID, SubjectName, CategoryID in SubjectMappingRaw:
            SubjectMapping[(SubjectName, CategoryID)] = SubjectID
        
        # Process each book
        for Index, Row in self.CSVData.iterrows():
            try:
                BookData = self.PrepareBookData(Row, CategoryMapping, SubjectMapping)
                
                # Calculate file hash if file exists
                BookPath = self.BooksDirectory / Row['filename']
                if BookPath.exists():
                    BookData['FileHash'] = self.CalculateFileHash(BookPath)
                    BookData['FilePath'] = str(BookPath)
                
                # Set cover and thumbnail paths
                CoverPath = self.CoversDirectory / (Path(Row['filename']).stem + '.png')
                ThumbnailPath = self.ThumbnailsDirectory / (Path(Row['filename']).stem + '.png')
                
                if CoverPath.exists():
                    BookData['CoverPath'] = str(CoverPath)
                if ThumbnailPath.exists():
                    BookData['ThumbnailPath'] = str(ThumbnailPath)
                
                # Insert book record
                InsertSQL = """
                    INSERT INTO Books (
                        FileName, FilePath, FileSize, FileSizeMB, PageCount, FileHash,
                        Title, Author, Publisher, PublicationYear, ISBN,
                        PDFTitle, PDFAuthor, PDFSubject, PDFCreator, PDFProducer, PDFCreationDate,
                        CategoryID, SubjectID, CategoryConfidence, SubjectConfidence, OverallConfidence,
                        ExtractedISBN, ExtractedYear, ExtractedPublisher, ExtractedEdition,
                        ExtractionMethod, ProcessingDate, ProcessingErrors, ProcessingFlags,
                        CoverPath, ThumbnailPath, DateAdded
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """
                
                Cursor.execute(InsertSQL, [
                    BookData['FileName'], BookData['FilePath'], BookData['FileSize'], 
                    BookData['FileSizeMB'], BookData['PageCount'], BookData['FileHash'],
                    BookData['Title'], BookData['Author'], BookData['Publisher'], 
                    BookData['PublicationYear'], BookData['ISBN'],
                    BookData['PDFTitle'], BookData['PDFAuthor'], BookData['PDFSubject'],
                    BookData['PDFCreator'], BookData['PDFProducer'], BookData['PDFCreationDate'],
                    BookData['CategoryID'], BookData['SubjectID'], BookData['CategoryConfidence'],
                    BookData['SubjectConfidence'], BookData['OverallConfidence'],
                    BookData['ExtractedISBN'], BookData['ExtractedYear'], BookData['ExtractedPublisher'],
                    BookData['ExtractedEdition'], BookData['ExtractionMethod'], BookData['ProcessingDate'],
                    BookData['ProcessingErrors'], BookData['ProcessingFlags'],
                    BookData['CoverPath'], BookData['ThumbnailPath'], BookData['DateAdded']
                ])
                
                BookID = Cursor.lastrowid
                
                # Insert content for full-text search
                if any(Row.get(field) for field in ['first_page_text', 'title_page_text', 'copyright_page_text']):
                    self.InsertBookContent(Cursor, BookID, Row)
                
                self.StatsCounters['BooksMigrated'] += 1
                
                if (Index + 1) % 100 == 0:
                    print(f"   üìà Processed {Index + 1}/{len(self.CSVData)} books...")
                    Connection.commit()
                
            except Exception as Error:
                print(f"‚ö†Ô∏è Error migrating book {Row.get('filename', 'unknown')}: {Error}")
                self.StatsCounters['ErrorsEncountered'] += 1
        
        Connection.commit()
        Connection.close()
        
        print(f"‚úÖ Migrated {self.StatsCounters['BooksMigrated']} books")

    def PrepareBookData(self, Row: pd.Series, CategoryMapping: Dict, SubjectMapping: Dict) -> Dict:
        """Prepare book data dictionary from CSV row"""
        
        # Map category and subject IDs
        CategoryID = None
        SubjectID = None
        
        Category = Row.get('database_category')
        if pd.isna(Category):
            Category = None
        else:
            Category = str(Category)
            
        Subject = Row.get('database_subject')
        if pd.isna(Subject):
            Subject = None
        else:
            Subject = str(Subject)
        
        if Category and Category in CategoryMapping:
            CategoryID = CategoryMapping[Category]
            
            if Subject and (Subject, CategoryID) in SubjectMapping:
                SubjectID = SubjectMapping[(Subject, CategoryID)]
        
        # Calculate file size in bytes
        FileSizeMB = float(Row.get('file_size_mb', 0) or 0)
        FileSize = int(FileSizeMB * 1024 * 1024) if FileSizeMB > 0 else None
        
        # Process confidence scores
        CategoryConfidence = self.ParseFloat(Row.get('category_confidence'))
        SubjectConfidence = self.ParseFloat(Row.get('subject_confidence'))
        OverallConfidence = self.ParseFloat(Row.get('overall_confidence'))
        
        # Handle processing flags
        ProcessingFlags = []
        if Row.get('errors'):
            ProcessingFlags.append('extraction_errors')
        if CategoryConfidence and CategoryConfidence < 0.7:
            ProcessingFlags.append('low_category_confidence')
        if SubjectConfidence and SubjectConfidence < 0.7:
            ProcessingFlags.append('low_subject_confidence')
        
        return {
            'FileName': Row['filename'],
            'FilePath': None,
            'FileSize': FileSize,
            'FileSizeMB': FileSizeMB,
            'PageCount': int(Row.get('page_count', 0) or 0),
            'FileHash': None,
            'Title': Row.get('pdf_title') or Row.get('title') or Path(Row['filename']).stem,
            'Author': Row.get('pdf_author') or Row.get('author'),
            'Publisher': Row.get('extracted_publisher') or Row.get('publisher'),
            'PublicationYear': self.ParseInt(Row.get('extracted_year')),
            'ISBN': Row.get('extracted_isbn') or Row.get('isbn'),
            'PDFTitle': Row.get('pdf_title'),
            'PDFAuthor': Row.get('pdf_author'),
            'PDFSubject': Row.get('pdf_subject'),
            'PDFCreator': Row.get('pdf_creator'),
            'PDFProducer': Row.get('pdf_producer'),
            'PDFCreationDate': Row.get('pdf_creation_date'),
            'CategoryID': CategoryID,
            'SubjectID': SubjectID,
            'CategoryConfidence': CategoryConfidence,
            'SubjectConfidence': SubjectConfidence,
            'OverallConfidence': OverallConfidence,
            'ExtractedISBN': Row.get('extracted_isbn'),
            'ExtractedYear': self.ParseInt(Row.get('extracted_year')),
            'ExtractedPublisher': Row.get('extracted_publisher'),
            'ExtractedEdition': Row.get('extracted_edition'),
            'ExtractionMethod': Row.get('extraction_method', 'legacy'),
            'ProcessingDate': datetime.now().isoformat(),
            'ProcessingErrors': Row.get('errors'),
            'ProcessingFlags': json.dumps(ProcessingFlags) if ProcessingFlags else None,
            'CoverPath': None,
            'ThumbnailPath': None,
            'DateAdded': datetime.now().isoformat()
        }

    def InsertBookContent(self, Cursor: sqlite3.Cursor, BookID: int, Row: pd.Series):
        """Insert book content for full-text search"""
        
        Cursor.execute("""
            INSERT INTO BookContent (
                BookID, FirstPageText, TitlePageText, CopyrightPageText, ExtractionDate
            ) VALUES (?, ?, ?, ?, ?)
        """, [
            BookID,
            Row.get('first_page_text', '')[:5000],  # Limit text length
            Row.get('title_page_text', '')[:5000],
            Row.get('copyright_page_text', '')[:5000],
            datetime.now().isoformat()
        ])
        
        self.StatsCounters['ContentProcessed'] += 1

    def ProcessBookContent(self):
        """Process book content for full-text search indexing"""
        print("üîç Processing content for full-text search...")
        
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        # Populate FTS table
        Cursor.execute("""
            INSERT INTO BooksFullText (rowid, Title, Author, Publisher, PDFTitle, PDFAuthor, PDFSubject)
            SELECT BookID, Title, Author, Publisher, PDFTitle, PDFAuthor, PDFSubject
            FROM Books WHERE IsActive = 1
        """)
        
        Connection.commit()
        Connection.close()
        
        print("‚úÖ Full-text search indexing completed")

    def GenerateInitialAnalytics(self):
        """Generate initial analytics for the migrated data"""
        print("üìä Generating initial analytics...")
        
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        # Add initial view events for existing books
        Cursor.execute("""
            INSERT INTO BookAnalytics (BookID, EventType, EventDate)
            SELECT BookID, 'migration', DateAdded
            FROM Books WHERE IsActive = 1
        """)
        
        Connection.commit()
        Connection.close()
        
        print("‚úÖ Initial analytics generated")

    def GenerateReport(self):
        """Generate migration completion report"""
        print("\n" + "="*60)
        print("üìã MIGRATION COMPLETION REPORT")
        print("="*60)
        
        for StatName, Count in self.StatsCounters.items():
            print(f"{StatName}: {Count}")
        
        # Database statistics
        Connection = sqlite3.connect(self.NewDatabasePath)
        Cursor = Connection.cursor()
        
        Cursor.execute("SELECT COUNT(*) FROM Categories WHERE IsActive = 1")
        ActiveCategories = Cursor.fetchone()[0]
        
        Cursor.execute("SELECT COUNT(*) FROM Subjects WHERE IsActive = 1")
        ActiveSubjects = Cursor.fetchone()[0]
        
        Cursor.execute("SELECT COUNT(*) FROM Books WHERE IsActive = 1")
        ActiveBooks = Cursor.fetchone()[0]
        
        Cursor.execute("SELECT COUNT(*) FROM Books WHERE OverallConfidence >= 0.8")
        HighConfidenceBooks = Cursor.fetchone()[0]
        
        Cursor.execute("SELECT COUNT(*) FROM Books WHERE CoverPath IS NOT NULL")
        BooksWithCovers = Cursor.fetchone()[0]
        
        Connection.close()
        
        print(f"\nüìä DATABASE SUMMARY:")
        print(f"   Active Categories: {ActiveCategories}")
        print(f"   Active Subjects: {ActiveSubjects}")
        print(f"   Active Books: {ActiveBooks}")
        print(f"   High Confidence Books: {HighConfidenceBooks} ({HighConfidenceBooks/ActiveBooks*100:.1f}%)")
        print(f"   Books with Covers: {BooksWithCovers} ({BooksWithCovers/ActiveBooks*100:.1f}%)")
        
        print(f"\n‚úÖ Migration completed successfully!")
        print(f"üìÅ Enhanced SQLite database: {self.NewDatabasePath}")
        
        # MySQL conversion instructions
        print(f"\nüîÑ MYSQL CONVERSION READY!")
        print("="*60)
        print("Your database is now ready for MySQL conversion:")
        print()
        print("STEP 1: Generate MySQL dump")
        print("   Use your SQLite-to-MySQL converter on:")
        print(f"   {self.NewDatabasePath}")
        print()
        print("STEP 2: Import to MySQL")
        print("   mysql -u username -p database_name < converted_dump.sql")
        print()
        print("STEP 3: Run MySQL optimizations")
        print("   Execute the MySQL enhancement script to add:")
        print("   - AUTO_INCREMENT to primary keys")
        print("   - FULLTEXT search indexes")
        print("   - MySQL-specific stored procedures")
        print("   - Performance optimizations")
        print()
        print("STEP 4: MySQL Workbench benefits")
        print("   - Visual ER diagrams")
        print("   - Query optimization tools")
        print("   - Data modeling validation")
        print("   - Export capabilities")
        print()
        print("üéØ MYSQL FEATURES ENABLED:")
        print("   ‚úÖ FULLTEXT search on Books and BookContent")
        print("   ‚úÖ Stored procedures for complex queries")
        print("   ‚úÖ Custom functions for popularity scoring")
        print("   ‚úÖ Optimized indexes for performance")
        print("   ‚úÖ UTF8MB4 charset for full Unicode support")
        print("   ‚úÖ InnoDB engine for ACID compliance")
        print("="*60)

    def ExportForMySQL(self) -> str:
        """Export additional MySQL-specific setup instructions"""
        MySQLSetupPath = self.NewDatabasePath.replace('.db', '_mysql_setup.sql')
        
        MySQLInstructions = f"""
-- MySQL Conversion Instructions
-- Generated: {datetime.now().isoformat()}
-- Source: {self.NewDatabasePath}

-- ===============================================
-- MYSQL CONVERSION WORKFLOW
-- ===============================================

-- 1. CONVERT SQLITE TO MYSQL
-- Use your SQLite-to-MySQL converter tool:
-- Input: {self.NewDatabasePath}
-- Output: mylibrary_mysql.sql

-- 2. CREATE MYSQL DATABASE
CREATE DATABASE anderson_library 
CHARACTER SET utf8mb4 
COLLATE utf8mb4_unicode_ci;

USE anderson_library;

-- 3. IMPORT CONVERTED DATA
-- mysql -u username -p anderson_library < mylibrary_mysql.sql

-- 4. RUN ENHANCEMENTS
-- Execute the MySQL conversion enhancement script

-- ===============================================
-- POST-CONVERSION VERIFICATION QUERIES
-- ===============================================

-- Verify data integrity
SELECT 
    'Categories' as table_name, COUNT(*) as record_count 
FROM Categories WHERE IsActive = 1
UNION ALL
SELECT 
    'Subjects' as table_name, COUNT(*) as record_count 
FROM Subjects WHERE IsActive = 1
UNION ALL
SELECT 
    'Books' as table_name, COUNT(*) as record_count 
FROM Books WHERE IsActive = 1;

-- Test FULLTEXT search (after enhancement script)
-- SELECT Title, Author, 
--        MATCH(Title, Author, Publisher) AGAINST ('python') as relevance
-- FROM Books 
-- WHERE MATCH(Title, Author, Publisher) AGAINST ('python' IN NATURAL LANGUAGE MODE)
-- ORDER BY relevance DESC;

-- Verify foreign key relationships
SELECT 
    COUNT(DISTINCT b.CategoryID) as categories_used,
    COUNT(DISTINCT b.SubjectID) as subjects_used
FROM Books b 
WHERE b.IsActive = 1;

-- ===============================================
-- MYSQL WORKBENCH SETUP
-- ===============================================

-- 1. Connect to MySQL database
-- 2. Use "Database > Reverse Engineer" to create ER diagram
-- 3. Explore relationships visually
-- 4. Use Query tab for analysis
-- 5. Export documentation and diagrams

-- ===============================================
-- PERFORMANCE MONITORING
-- ===============================================

-- Monitor query performance
-- EXPLAIN SELECT * FROM Books WHERE Title LIKE '%python%';
-- EXPLAIN SELECT * FROM Books WHERE MATCH(Title) AGAINST ('python');

-- Check index usage
-- SHOW INDEX FROM Books;
-- SHOW INDEX FROM BookContent;

"""
        
        with open(MySQLSetupPath, 'w', encoding='utf-8') as File:
            File.write(MySQLInstructions)
        
        print(f"üìÑ MySQL setup instructions: {MySQLSetupPath}")
        return MySQLSetupPath

    def CalculateFileHash(self, FilePath: Path) -> str:
        """Calculate SHA256 hash of file"""
        Hash = hashlib.sha256()
        with open(FilePath, 'rb') as File:
            for Chunk in iter(lambda: File.read(4096), b""):
                Hash.update(Chunk)
        return Hash.hexdigest()

    def ParseFloat(self, Value) -> Optional[float]:
        """Safely parse float value"""
        try:
            if pd.isna(Value):
                return None
            return float(Value)
        except (ValueError, TypeError):
            return None

    def ParseInt(self, Value) -> Optional[int]:
        """Safely parse integer value"""
        try:
            if pd.isna(Value):
                return None
            return int(float(Value))
        except (ValueError, TypeError):
            return None

    def GetEnhancedSchema(self) -> str:
        """Return the enhanced schema SQL - optimized for MySQL compatibility"""
        return """
        -- MyLibrary Database Schema - Dual SQLite/MySQL Compatible
        -- Use the complete schema from the dual-compatible artifact
        
        PRAGMA foreign_keys = ON;
        PRAGMA journal_mode = WAL;
        
        -- Core tables with MySQL-compatible sizing
        CREATE TABLE Categories (
            CategoryID INTEGER NOT NULL,
            CategoryName VARCHAR(100) NOT NULL,
            Description TEXT(1000),
            ParentCategoryID INTEGER DEFAULT NULL,
            Color VARCHAR(7) DEFAULT '#4285f4',
            SortOrder INTEGER DEFAULT 0,
            CreatedDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            ModifiedDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            IsActive TINYINT(1) DEFAULT 1,
            PRIMARY KEY (CategoryID),
            CONSTRAINT UK_Categories_Name UNIQUE (CategoryName)
        );
        
        CREATE TABLE Subjects (
            SubjectID INTEGER NOT NULL,
            SubjectName VARCHAR(150) NOT NULL,
            CategoryID INTEGER NOT NULL,
            Description TEXT(2000),
            KeywordTags TEXT(1000),
            SortOrder INTEGER DEFAULT 0,
            CreatedDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            ModifiedDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            IsActive TINYINT(1) DEFAULT 1,
            PRIMARY KEY (SubjectID),
            FOREIGN KEY (CategoryID) REFERENCES Categories(CategoryID),
            CONSTRAINT UK_Subjects_CategoryName UNIQUE (SubjectName, CategoryID)
        );
        
        CREATE TABLE Books (
            BookID INTEGER NOT NULL,
            FileName VARCHAR(255) NOT NULL,
            FilePath VARCHAR(500),
            FileSize BIGINT,
            FileSizeMB DECIMAL(10,2),
            PageCount INTEGER,
            FileHash VARCHAR(64),
            Title VARCHAR(500),
            Author VARCHAR(300),
            Publisher VARCHAR(200),
            PublicationYear INTEGER,
            ISBN VARCHAR(20),
            Language VARCHAR(50) DEFAULT 'English',
            Edition VARCHAR(100),
            PDFTitle VARCHAR(500),
            PDFAuthor VARCHAR(300),
            PDFSubject VARCHAR(300),
            PDFCreator VARCHAR(100),
            PDFProducer VARCHAR(100),
            PDFCreationDate VARCHAR(50),
            CategoryID INTEGER,
            SubjectID INTEGER,
            CategoryConfidence DECIMAL(5,4),
            SubjectConfidence DECIMAL(5,4),
            OverallConfidence DECIMAL(5,4),
            ExtractedISBN VARCHAR(20),
            ExtractedYear INTEGER,
            ExtractedPublisher VARCHAR(200),
            ExtractedEdition VARCHAR(100),
            ReadingLevel DECIMAL(4,2),
            ComplexityScore DECIMAL(4,2),
            QualityScore DECIMAL(4,2),
            ContentTags TEXT(2000),
            ExtractionMethod VARCHAR(50),
            ProcessingDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            ProcessingVersion VARCHAR(20),
            ProcessingErrors TEXT(1000),
            ProcessingFlags TEXT(500),
            ViewCount INTEGER DEFAULT 0,
            DownloadCount INTEGER DEFAULT 0,
            Rating DECIMAL(3,2) DEFAULT 0.00,
            RatingCount INTEGER DEFAULT 0,
            CoverPath VARCHAR(500),
            ThumbnailPath VARCHAR(500),
            DateAdded TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            DateModified TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            LastAccessed TIMESTAMP,
            IsActive TINYINT(1) DEFAULT 1,
            PRIMARY KEY (BookID),
            FOREIGN KEY (CategoryID) REFERENCES Categories(CategoryID),
            FOREIGN KEY (SubjectID) REFERENCES Subjects(SubjectID),
            CONSTRAINT UK_Books_FileName UNIQUE (FileName)
        );
        
        CREATE TABLE BookContent (
            BookID INTEGER NOT NULL,
            FirstPageText TEXT(16000),
            TitlePageText TEXT(16000),
            CopyrightPageText TEXT(16000),
            ExtractedKeywords TEXT(2000),
            ExtractedEntities TEXT(2000),
            ExtractedTopics TEXT(2000),
            ContentLanguage VARCHAR(20),
            ContentEncoding VARCHAR(20),
            ExtractionDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (BookID),
            FOREIGN KEY (BookID) REFERENCES Books(BookID) ON DELETE CASCADE
        );
        
        CREATE TABLE BookSearchIndex (
            BookID INTEGER NOT NULL,
            SearchableContent TEXT(20000),
            IndexedDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (BookID),
            FOREIGN KEY (BookID) REFERENCES Books(BookID) ON DELETE CASCADE
        );
        
        CREATE TABLE LLMClassifications (
            ClassificationID INTEGER NOT NULL,
            BookID INTEGER NOT NULL,
            ModelName VARCHAR(100) NOT NULL,
            ModelVersion VARCHAR(50),
            InputPrompt TEXT(5000),
            RawResponse TEXT(10000),
            ParsedResults TEXT(2000),
            CategorySuggested VARCHAR(100),
            SubjectSuggested VARCHAR(150),
            ConfidenceScore DECIMAL(5,4),
            ProcessingTime DECIMAL(8,3),
            TokensUsed INTEGER,
            ClassificationDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            IsAccepted TINYINT(1) DEFAULT 0,
            UserOverride TEXT(1000),
            PRIMARY KEY (ClassificationID),
            FOREIGN KEY (BookID) REFERENCES Books(BookID)
        );
        
        -- Essential indexes
        CREATE INDEX idx_books_title ON Books(Title);
        CREATE INDEX idx_books_author ON Books(Author);
        CREATE INDEX idx_books_category ON Books(CategoryID);
        CREATE INDEX idx_books_confidence ON Books(OverallConfidence);
        CREATE INDEX idx_categories_active ON Categories(IsActive);
        CREATE INDEX idx_subjects_category ON Subjects(CategoryID);
        
        -- Essential views
        CREATE VIEW BookDetails AS
        SELECT 
            b.BookID, b.FileName, b.Title, b.Author, b.Publisher, b.PublicationYear,
            c.CategoryName, s.SubjectName, b.CategoryConfidence, b.SubjectConfidence,
            b.OverallConfidence, b.FileSize, b.PageCount, b.Rating, b.ViewCount,
            b.DateAdded, b.CoverPath, b.ThumbnailPath, b.IsActive
        FROM Books b
        LEFT JOIN Categories c ON b.CategoryID = c.CategoryID
        LEFT JOIN Subjects s ON b.SubjectID = s.SubjectID;

        CREATE VIRTUAL TABLE BooksFullText USING fts5(
            Title, Author, Publisher, PDFTitle, PDFAuthor, PDFSubject,
            content='Books', content_rowid='BookID'
        );

        CREATE TABLE BookAnalytics (
            AnalyticsID INTEGER NOT NULL,
            BookID INTEGER NOT NULL,
            EventType VARCHAR(50) NOT NULL,
            EventDate TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            PRIMARY KEY (AnalyticsID),
            FOREIGN KEY (BookID) REFERENCES Books(BookID) ON DELETE CASCADE
        );
        """

if __name__ == "__main__":
    # Configuration
    OLD_DATABASE = "Assets/my_library.db"
    CSV_FILE = os.path.join(os.path.dirname(__file__), "Data/Spreadsheets/AndersonLibrary_PDFMetadata.csv")
    NEW_DATABASE = "MyLibrary_Enhanced.db"
    BOOKS_DIR = "Anderson eBooks"
    COVERS_DIR = "Covers"
    THUMBS_DIR = "Thumbs"
    
    # Execute migration
    Migrator = LibraryDataMigrator(
        OldDatabasePath=OLD_DATABASE,
        CSVPath=CSV_FILE,
        NewDatabasePath=NEW_DATABASE,
        BooksDirectory=BOOKS_DIR,
        CoversDirectory=COVERS_DIR,
        ThumbnailsDirectory=THUMBS_DIR
    )
    
    Success = Migrator.ExecuteMigration()
    
    if Success:
        print("\nüéâ Your Anderson's Library database has been successfully upgraded!")
        print("üîç Full-text search enabled")
        print("ü§ñ AI classification tracking ready")
        print("üìä Analytics and relationship mapping prepared")
        print("üê¨ MySQL conversion ready - see generated setup instructions")
        print("üìà Use MySQL Workbench for visual ER diagrams and analysis")
    else:
        print("\n‚ùå Migration failed - check logs for details")

================
File: README.md
================
# BowersWorld-com Digital Alexandria\n\nRun: python DigitalAlexandria.py
================
File: Scripts/Development/BowersWorldSetup.py
================
#!/usr/bin/env python3
"""
File: BowersWorldSetup.py
Path: BowersWorld-com/BowersWorldSetup.py
Standard: AIDEV-PascalCase-1.7
Created: 2025-06-27  11:30
Modified: 2025-06-27  11:30
Author: Herb Bowers - Project Himalaya
Contact: HimalayaProject1@gmail.com
Description: BowersWorld-com Project Foundation Setup Script (Digital Alexandria Architecture)

Purpose: Creates the complete BowersWorld-com project structure from scratch,
following AIDEV-PascalCase-1.7 standards and implementing the Digital Alexandria
blueprint architecture. Migrates existing Andy.py desktop functionality to modern
web-based library system with AI-powered features.

Dependencies: Python 3.9+, required packages installed automatically
Output: Complete BowersWorld-com project structure ready for development
"""

import os
import sys
import json
import shutil
import sqlite3
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

class BowersWorldSetup:
    """
    BowersWorld-com Project Foundation Builder (Digital Alexandria Architecture)
    
    Creates complete project structure following AIDEV-PascalCase-1.7 standards
    and Digital Alexandria blueprint architecture specifications.
    """
    
    def __init__(self, ProjectPath: str = "BowersWorld-com"):
        """Initialize setup with project configuration"""
        self.ProjectPath = Path(ProjectPath).resolve()
        self.Timestamp = datetime.now()
        self.TimestampStr = self.Timestamp.strftime("%Y-%m-%d  %H:%M")
        self.LogMessages: List[str] = []
        
        # Digital Alexandria Architecture Components
        self.CoreComponents = {
            "Foundation": ["Database", "Search", "API", "Auth"],
            "Intelligence": ["AI", "Classification", "Discovery", "Analytics"], 
            "Interface": ["Web", "Mobile", "Desktop", "Plugins"],
            "Collaboration": ["Users", "Annotations", "Collections", "Social"],
            "Innovation": ["Research", "Assistant", "Extensions", "Future"]
        }
        
        print("üèõÔ∏è BowersWorld-com Foundation Builder (Digital Alexandria Architecture)")
        print("=" * 60)
        print(f"üìÅ Project Path: {self.ProjectPath}")
        print(f"‚è∞ Timestamp: {self.TimestampStr}")
        print()

    def CreateProjectStructure(self) -> bool:
        """Create complete Digital Alexandria project directory structure"""
        try:
            print("üìÅ Creating BowersWorld-com Project Structure (Digital Alexandria Architecture)...")
            
            # Main project directories following blueprint architecture
            MainDirectories = [
                # Core Foundation Layer
                "Source/Core/Database",
                "Source/Core/Search", 
                "Source/Core/API",
                "Source/Core/Authentication",
                
                # AI Intelligence Layer
                "Source/AI/Classification",
                "Source/AI/Discovery", 
                "Source/AI/Analytics",
                "Source/AI/Models",
                "Source/AI/Training",
                
                # User Interface Layer
                "Source/Interface/Web/Components",
                "Source/Interface/Web/Pages", 
                "Source/Interface/Web/Assets",
                "Source/Interface/Desktop",
                "Source/Interface/Mobile",
                "Source/Interface/API",
                
                # Collaboration Features
                "Source/Collaboration/Users",
                "Source/Collaboration/Annotations",
                "Source/Collaboration/Collections", 
                "Source/Collaboration/Social",
                
                # Plugin & Extension System
                "Source/Plugins/Classification",
                "Source/Plugins/Search",
                "Source/Plugins/Analysis",
                "Source/Plugins/Export",
                "Source/Plugins/Import",
                
                # Data & Configuration
                "Data/Database",
                "Data/Books", 
                "Data/Covers",
                "Data/Thumbnails",
                "Data/Cache",
                "Data/Backups",
                
                # Configuration & Settings
                "Config/Development",
                "Config/Production", 
                "Config/Testing",
                "Config/Deployment",
                
                # Documentation & Standards
                "Documentation/API",
                "Documentation/Architecture",
                "Documentation/Standards", 
                "Documentation/Guides",
                "Documentation/Research",
                
                # Testing Infrastructure
                "Tests/Unit",
                "Tests/Integration",
                "Tests/Performance",
                "Tests/Data",
                
                # Scripts & Utilities
                "Scripts/Migration",
                "Scripts/Development",
                "Scripts/Deployment",
                "Scripts/Maintenance",
                
                # Legacy Integration
                "Legacy/Andy",
                "Legacy/Migration",
                "Legacy/Archive"
            ]
            
            # Create all directories
            for Directory in MainDirectories:
                DirectoryPath = self.ProjectPath / Directory
                DirectoryPath.mkdir(parents=True, exist_ok=True)
                self.LogMessages.append(f"‚úÖ Created: {Directory}")
            
            print(f"   ‚úÖ Created {len(MainDirectories)} directories")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error creating directories: {Error}")
            return False

    def CreateConfigurationFiles(self) -> bool:
        """Create all Digital Alexandria configuration files"""
        try:
            print("‚öôÔ∏è Creating Configuration Files...")
            
            # Main project configuration
            ProjectConfig = {
                "project": {
                    "name": "BowersWorld-com",
                    "codename": "Digital Alexandria",
                    "version": "1.0.0", 
                    "description": "Complete Digital Library System",
                    "author": "Herb Bowers - Project Himalaya",
                    "contact": "HimalayaProject1@gmail.com",
                    "standard": "AIDEV-PascalCase-1.7",
                    "created": self.TimestampStr,
                    "modified": self.TimestampStr
                },
                "architecture": {
                    "pattern": "Layered Architecture",
                    "database": "SQLite + Full-Text Search",
                    "ai_engine": "Multi-Model Ensemble", 
                    "web_framework": "FastAPI + React",
                    "desktop_legacy": "PySide6 (Andy.py)",
                    "plugin_system": "Hook-based Extensions"
                },
                "features": {
                    "ai_classification": True,
                    "semantic_search": True, 
                    "knowledge_graphs": True,
                    "collaboration": True,
                    "multi_user": True,
                    "mobile_support": True,
                    "plugin_system": True,
                    "api_access": True
                }
            }
            
            # Development environment configuration
            DevelopmentConfig = {
                "environment": "development",
                "debug": True,
                "database": {
                    "url": "sqlite:///Data/Database/BowersWorld_dev.db",
                    "backup_interval": 3600,
                    "migration_auto": True
                },
                "ai": {
                    "models_path": "Source/AI/Models",
                    "training_data": "Data/Training", 
                    "cache_size": "1GB",
                    "gpu_enabled": True
                },
                "web": {
                    "host": "localhost",
                    "port": 8000,
                    "hot_reload": True,
                    "cors_enabled": True
                },
                "logging": {
                    "level": "DEBUG",
                    "file": "Logs/alexandria_dev.log",
                    "console": True
                }
            }
            
            # Production configuration template
            ProductionConfig = {
                "environment": "production", 
                "debug": False,
                "database": {
                    "url": "sqlite:///Data/Database/BowersWorld.db",
                    "backup_interval": 1800,
                    "migration_auto": False
                },
                "security": {
                    "secret_key": "CHANGE_THIS_IN_PRODUCTION",
                    "session_timeout": 3600,
                    "rate_limiting": True,
                    "https_only": True
                },
                "performance": {
                    "cache_size": "2GB", 
                    "workers": 4,
                    "connection_pool": 20
                }
            }
            
            # Python requirements
            RequirementsList = [
                "# BowersWorld-com Core Dependencies (Digital Alexandria Architecture)",
                "fastapi>=0.104.1",
                "uvicorn[standard]>=0.24.0",
                "sqlalchemy>=2.0.0",
                
                "# AI & Machine Learning",
                "transformers>=4.35.0", 
                "torch>=2.1.0",
                "scikit-learn>=1.3.0",
                "nltk>=3.8.1",
                "spacy>=3.7.0",
                
                "# Web & API",
                "jinja2>=3.1.2",
                "python-multipart>=0.0.6",
                "python-jose[cryptography]>=3.3.0",
                
                "# Data Processing", 
                "pandas>=2.1.0",
                "numpy>=1.25.0",
                "pillow>=10.0.0",
                "PyPDF2>=3.0.1",
                
                "# Legacy Desktop Integration",
                "PySide6>=6.6.0",
                
                "# Development Tools",
                "pytest>=7.4.0",
                "pytest-asyncio>=0.21.0", 
                "black>=23.0.0",
                "isort>=5.12.0",
                
                "# Optional Enhancements",
                "redis>=5.0.0  # For caching",
                "celery>=5.3.0  # For background tasks"
            ]
            
            # Write configuration files
            ConfigFiles = [
                ("alexandria_config.json", ProjectConfig),
                ("Config/Development/config.json", DevelopmentConfig), 
                ("Config/Production/config.json", ProductionConfig),
                ("requirements.txt", "\n".join(RequirementsList))
            ]
            
            for FileName, Content in ConfigFiles:
                FilePath = self.ProjectPath / FileName
                FilePath.parent.mkdir(parents=True, exist_ok=True)
                
                if FileName.endswith('.json'):
                    with open(FilePath, 'w', encoding='utf-8') as File:
                        json.dump(Content, File, indent=2)
                else:
                    with open(FilePath, 'w', encoding='utf-8') as File:
                        File.write(Content)
                        
                self.LogMessages.append(f"‚úÖ Created: {FileName}")
            
            print(f"   ‚úÖ Created {len(ConfigFiles)} configuration files")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error creating configuration: {Error}")
            return False

    def CreateFoundationDatabase(self) -> bool:
        """Create Digital Alexandria v2.0 database schema"""
        try:
            print("üóÑÔ∏è Creating BowersWorld-com Database v2.0 (Digital Alexandria Architecture)...")
            
            DatabasePath = self.ProjectPath / "Data/Database/BowersWorld.db"
            DatabasePath.parent.mkdir(parents=True, exist_ok=True)
            
            # Connect and create schema
            Connection = sqlite3.connect(DatabasePath)
            Cursor = Connection.cursor()
            
            # Enable foreign keys and full-text search
            Cursor.execute("PRAGMA foreign_keys = ON")
            Cursor.execute("PRAGMA journal_mode = WAL")
            
            # Core Books table with enhanced metadata
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS Books (
                    BookID INTEGER PRIMARY KEY AUTOINCREMENT,
                    Title TEXT NOT NULL,
                    Author TEXT,
                    ISBN TEXT,
                    Publisher TEXT,
                    PublishDate TEXT,
                    Language TEXT DEFAULT 'English',
                    PageCount INTEGER,
                    FileSize INTEGER,
                    FilePath TEXT UNIQUE NOT NULL,
                    CoverPath TEXT,
                    ThumbnailPath TEXT,
                    
                    -- Metadata Enhancement
                    Description TEXT,
                    Keywords TEXT,
                    Subjects TEXT,
                    DeweyDecimal TEXT,
                    LibraryOfCongress TEXT,
                    
                    -- AI Analysis Results
                    ReadingLevel REAL,
                    ComplexityScore REAL,
                    TopicVector TEXT, -- JSON array for similarity
                    Categories TEXT,  -- JSON array of classifications
                    
                    -- Quality & Processing
                    QualityScore REAL DEFAULT 0.0,
                    ProcessingStatus TEXT DEFAULT 'pending',
                    LastAnalyzed TEXT,
                    
                    -- System Fields
                    DateAdded TEXT DEFAULT CURRENT_TIMESTAMP,
                    DateModified TEXT DEFAULT CURRENT_TIMESTAMP,
                    Version INTEGER DEFAULT 1,
                    
                    -- User Interaction
                    ViewCount INTEGER DEFAULT 0,
                    Rating REAL DEFAULT 0.0,
                    Notes TEXT
                )
            """)
            
            # Full-Text Search Virtual Table
            Cursor.execute("""
                CREATE VIRTUAL TABLE IF NOT EXISTS BooksFullText USING fts5(
                    Title, Author, Description, Keywords, Subjects, Content,
                    content='Books', content_rowid='BookID'
                )
            """)
            
            # Knowledge Graph - Relationships between books
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS BookRelationships (
                    RelationshipID INTEGER PRIMARY KEY AUTOINCREMENT,
                    BookID1 INTEGER NOT NULL,
                    BookID2 INTEGER NOT NULL,
                    RelationshipType TEXT NOT NULL, -- 'similar', 'prerequisite', 'follows', 'cites'
                    Strength REAL DEFAULT 0.0, -- 0.0 to 1.0 confidence
                    Source TEXT, -- 'ai', 'user', 'metadata'
                    DateCreated TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (BookID1) REFERENCES Books(BookID),
                    FOREIGN KEY (BookID2) REFERENCES Books(BookID),
                    UNIQUE(BookID1, BookID2, RelationshipType)
                )
            """)
            
            # User Management
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS Users (
                    UserID INTEGER PRIMARY KEY AUTOINCREMENT,
                    Username TEXT UNIQUE NOT NULL,
                    Email TEXT UNIQUE NOT NULL,
                    PasswordHash TEXT NOT NULL,
                    Role TEXT DEFAULT 'user', -- 'admin', 'user', 'guest'
                    Preferences TEXT, -- JSON for user settings
                    DateCreated TEXT DEFAULT CURRENT_TIMESTAMP,
                    LastLogin TEXT,
                    IsActive BOOLEAN DEFAULT 1
                )
            """)
            
            # User Annotations and Notes
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS Annotations (
                    AnnotationID INTEGER PRIMARY KEY AUTOINCREMENT,
                    BookID INTEGER NOT NULL,
                    UserID INTEGER NOT NULL,
                    PageNumber INTEGER,
                    PositionX REAL,
                    PositionY REAL,
                    AnnotationType TEXT, -- 'highlight', 'note', 'bookmark'
                    Content TEXT,
                    Color TEXT DEFAULT '#ffff00',
                    DateCreated TEXT DEFAULT CURRENT_TIMESTAMP,
                    DateModified TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (BookID) REFERENCES Books(BookID),
                    FOREIGN KEY (UserID) REFERENCES Users(UserID)
                )
            """)
            
            # Collections and Reading Lists
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS Collections (
                    CollectionID INTEGER PRIMARY KEY AUTOINCREMENT,
                    Name TEXT NOT NULL,
                    Description TEXT,
                    UserID INTEGER NOT NULL,
                    IsPublic BOOLEAN DEFAULT 0,
                    DateCreated TEXT DEFAULT CURRENT_TIMESTAMP,
                    DateModified TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (UserID) REFERENCES Users(UserID)
                )
            """)
            
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS CollectionBooks (
                    CollectionID INTEGER,
                    BookID INTEGER,
                    OrderIndex INTEGER DEFAULT 0,
                    DateAdded TEXT DEFAULT CURRENT_TIMESTAMP,
                    PRIMARY KEY (CollectionID, BookID),
                    FOREIGN KEY (CollectionID) REFERENCES Collections(CollectionID),
                    FOREIGN KEY (BookID) REFERENCES Books(BookID)
                )
            """)
            
            # Analytics and Usage Tracking
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS BookAnalytics (
                    AnalyticsID INTEGER PRIMARY KEY AUTOINCREMENT,
                    BookID INTEGER NOT NULL,
                    UserID INTEGER,
                    Action TEXT NOT NULL, -- 'view', 'download', 'search', 'rate'
                    Details TEXT, -- JSON for additional data
                    Timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                    SessionID TEXT,
                    FOREIGN KEY (BookID) REFERENCES Books(BookID),
                    FOREIGN KEY (UserID) REFERENCES Users(UserID)
                )
            """)
            
            # System Configuration
            Cursor.execute("""
                CREATE TABLE IF NOT EXISTS SystemConfig (
                    ConfigKey TEXT PRIMARY KEY,
                    ConfigValue TEXT,
                    Description TEXT,
                    LastModified TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # Insert initial system configuration
            InitialConfig = [
                ('version', '2.0.0', 'Database schema version'),
                ('created', self.TimestampStr, 'Database creation timestamp'),
                ('ai_enabled', 'true', 'AI features enabled'),
                ('search_engine', 'fts5', 'Full-text search engine'),
                ('backup_interval', '3600', 'Backup interval in seconds')
            ]
            
            Cursor.executemany(
                "INSERT OR REPLACE INTO SystemConfig (ConfigKey, ConfigValue, Description) VALUES (?, ?, ?)",
                InitialConfig
            )
            
            # Create indexes for performance
            Indexes = [
                "CREATE INDEX IF NOT EXISTS idx_books_author ON Books(Author)",
                "CREATE INDEX IF NOT EXISTS idx_books_title ON Books(Title)",
                "CREATE INDEX IF NOT EXISTS idx_books_date_added ON Books(DateAdded)",
                "CREATE INDEX IF NOT EXISTS idx_books_quality ON Books(QualityScore)",
                "CREATE INDEX IF NOT EXISTS idx_relationships_books ON BookRelationships(BookID1, BookID2)",
                "CREATE INDEX IF NOT EXISTS idx_annotations_book_user ON Annotations(BookID, UserID)",
                "CREATE INDEX IF NOT EXISTS idx_analytics_book ON BookAnalytics(BookID)",
                "CREATE INDEX IF NOT EXISTS idx_analytics_timestamp ON BookAnalytics(Timestamp)"
            ]
            
            for IndexSQL in Indexes:
                Cursor.execute(IndexSQL)
            
            Connection.commit()
            Connection.close()
            
            print(f"   ‚úÖ Created Digital Alexandria Database v2.0")
            print(f"   üìä Location: {DatabasePath}")
            self.LogMessages.append(f"‚úÖ Created: Digital Alexandria Database v2.0")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error creating database: {Error}")
            return False

    def CreateCoreFoundationFiles(self) -> bool:
        """Create core foundation Python modules"""
        try:
            print("üèóÔ∏è Creating Core Foundation Files...")
            
            # Main Application Entry Point
            MainApp = f'''#!/usr/bin/env python3
"""
File: DigitalAlexandria.py
Path: BowersWorld-com/DigitalAlexandria.py
Standard: AIDEV-PascalCase-1.7
Created: {self.TimestampStr}
Modified: {self.TimestampStr}
Author: Herb Bowers - Project Himalaya
Contact: HimalayaProject1@gmail.com
Description: Digital Alexandria - Complete Library System Main Application

Purpose: Main entry point for Digital Alexandria library system. Provides unified
access to all system components including web interface, API, desktop integration,
and administrative functions following the Digital Alexandria blueprint architecture.

Usage: python DigitalAlexandria.py [command] [options]
Commands: web, api, desktop, admin, migrate, setup
"""

import sys
import argparse
from pathlib import Path

# Add source directory to Python path
sys.path.insert(0, str(Path(__file__).parent / "Source"))

from Core.Application import AlexandriaApplication
from Core.Configuration import ConfigurationManager
from Core.Logger import AlexandriaLogger

def CreateArgumentParser():
    """Create command line argument parser"""
    Parser = argparse.ArgumentParser(
        prog='Digital Alexandria',
        description='Complete Digital Library System',
        epilog='For more information, visit the Documentation folder'
    )
    
    Subparsers = Parser.add_subparsers(dest='command', help='Available commands')
    
    # Web Interface Command
    WebParser = Subparsers.add_parser('web', help='Start web interface')
    WebParser.add_argument('--host', default='localhost', help='Host address')
    WebParser.add_argument('--port', type=int, default=8000, help='Port number')
    WebParser.add_argument('--dev', action='store_true', help='Development mode')
    
    # API Server Command  
    APIParser = Subparsers.add_parser('api', help='Start API server')
    APIParser.add_argument('--port', type=int, default=8001, help='API port')
    APIParser.add_argument('--docs', action='store_true', help='Enable API docs')
    
    # Desktop Integration Command
    DesktopParser = Subparsers.add_parser('desktop', help='Launch desktop interface')
    DesktopParser.add_argument('--legacy', action='store_true', help='Use Andy.py legacy mode')
    
    # Admin Commands
    AdminParser = Subparsers.add_parser('admin', help='Administrative functions')
    AdminParser.add_argument('--backup', action='store_true', help='Create backup')
    AdminParser.add_argument('--optimize', action='store_true', help='Optimize database')
    AdminParser.add_argument('--stats', action='store_true', help='Show statistics')
    
    # Migration Command
    MigrateParser = Subparsers.add_parser('migrate', help='Data migration utilities')
    MigrateParser.add_argument('--from-legacy', action='store_true', help='Migrate from Andy.py')
    MigrateParser.add_argument('--backup-first', action='store_true', help='Create backup before migration')
    
    # Setup Command
    SetupParser = Subparsers.add_parser('setup', help='Initial system setup')
    SetupParser.add_argument('--reset', action='store_true', help='Reset all data')
    SetupParser.add_argument('--sample-data', action='store_true', help='Load sample data')
    
    return Parser

def Main():
    """Main application entry point"""
    try:
        # Parse command line arguments
        Parser = CreateArgumentParser()
        Arguments = Parser.parse_args()
        
        # Initialize configuration and logging
        Config = ConfigurationManager()
        Logger = AlexandriaLogger(Config)
        
        # Create main application
        App = AlexandriaApplication(Config, Logger)
        
        # Route to appropriate command
        if Arguments.command == 'web':
            App.StartWebInterface(
                Host=Arguments.host,
                Port=Arguments.port, 
                Development=Arguments.dev
            )
        elif Arguments.command == 'api':
            App.StartAPIServer(
                Port=Arguments.port,
                EnableDocs=Arguments.docs
            )
        elif Arguments.command == 'desktop':
            App.StartDesktopInterface(Legacy=Arguments.legacy)
        elif Arguments.command == 'admin':
            App.RunAdminCommand(Arguments)
        elif Arguments.command == 'migrate':
            App.RunMigration(Arguments)
        elif Arguments.command == 'setup':
            App.RunSetup(Arguments)
        else:
            # No command specified - show help and start web interface
            Parser.print_help()
            print("\\nüèõÔ∏è Starting Digital Alexandria Web Interface...")
            App.StartWebInterface()
            
    except KeyboardInterrupt:
        print("\\n‚ö†Ô∏è Digital Alexandria shutdown requested")
        sys.exit(0)
    except Exception as Error:
        print(f"\\n‚ùå Fatal error: {{Error}}")
        sys.exit(1)

if __name__ == "__main__":
    Main()
'''
            
            # Core Application Class
            CoreApp = f'''#!/usr/bin/env python3
"""
File: Application.py
Path: BowersWorld-com/Source/Core/Application.py
Standard: AIDEV-PascalCase-1.7
Created: {self.TimestampStr}
Modified: {self.TimestampStr}
Author: Herb Bowers - Project Himalaya
Contact: HimalayaProject1@gmail.com
Description: Digital Alexandria Core Application Manager

Purpose: Central application orchestration for Digital Alexandria. Manages all
system components, coordinates between web/desktop/API interfaces, and provides
unified application lifecycle management following layered architecture patterns.
"""

import sys
import asyncio
from pathlib import Path
from typing import Optional, Dict, Any

from .Configuration import ConfigurationManager
from .Logger import AlexandriaLogger
from .Database import DatabaseManager
from ..AI.AIEngine import AIEngineManager
from ..Interface.Web.WebApplication import WebApplication
from ..Interface.Desktop.DesktopLauncher import DesktopLauncher

class AlexandriaApplication:
    """
    Digital Alexandria Main Application Orchestrator
    
    Coordinates all system components and provides unified interface
    for web, desktop, and API access modes.
    """
    
    def __init__(self, Config: ConfigurationManager, Logger: AlexandriaLogger):
        """Initialize Digital Alexandria application"""
        self.Config = Config
        self.Logger = Logger
        self.Database = DatabaseManager(Config, Logger)
        self.AIEngine = AIEngineManager(Config, Logger) 
        self.IsRunning = False
        
        self.Logger.Info("Digital Alexandria Application initialized")
    
    async def StartWebInterface(self, Host: str = "localhost", Port: int = 8000, Development: bool = False):
        """Start the web interface server"""
        try:
            self.Logger.Info(f"Starting web interface on {{Host}}:{{Port}}")
            
            WebApp = WebApplication(self.Config, self.Logger, self.Database, self.AIEngine)
            await WebApp.Start(Host, Port, Development)
            
            self.IsRunning = True
            self.Logger.Info("Web interface started successfully")
            
        except Exception as Error:
            self.Logger.Error(f"Failed to start web interface: {{Error}}")
            raise
    
    async def StartAPIServer(self, Port: int = 8001, EnableDocs: bool = True):
        """Start the API server"""
        try:
            self.Logger.Info(f"Starting API server on port {{Port}}")
            
            # API server implementation
            from ..Interface.API.APIApplication import APIApplication
            APIApp = APIApplication(self.Config, self.Logger, self.Database, self.AIEngine)
            await APIApp.Start(Port, EnableDocs)
            
            self.Logger.Info("API server started successfully")
            
        except Exception as Error:
            self.Logger.Error(f"Failed to start API server: {{Error}}")
            raise
    
    def StartDesktopInterface(self, Legacy: bool = False):
        """Start the desktop interface"""
        try:
            self.Logger.Info(f"Starting desktop interface (Legacy: {{Legacy}})")
            
            if Legacy:
                # Launch Andy.py compatibility mode
                from ...Legacy.Andy.AndyLauncher import LaunchAndyCompatibilityMode
                LaunchAndyCompatibilityMode(self.Config, self.Database)
            else:
                # Modern desktop interface
                DesktopApp = DesktopLauncher(self.Config, self.Logger, self.Database, self.AIEngine)
                DesktopApp.Launch()
                
            self.Logger.Info("Desktop interface started successfully")
            
        except Exception as Error:
            self.Logger.Error(f"Failed to start desktop interface: {{Error}}")
            raise
    
    def RunAdminCommand(self, Arguments):
        """Execute administrative commands"""
        try:
            if Arguments.backup:
                self.Database.CreateBackup()
                print("‚úÖ Backup completed")
                
            if Arguments.optimize:
                self.Database.OptimizePerformance()
                print("‚úÖ Database optimized")
                
            if Arguments.stats:
                Stats = self.Database.GetStatistics()
                print("üìä Digital Alexandria Statistics:")
                for Key, Value in Stats.items():
                    print(f"   {{Key}}: {{Value}}")
                    
        except Exception as Error:
            self.Logger.Error(f"Admin command failed: {{Error}}")
            raise
    
    def RunMigration(self, Arguments):
        """Execute data migration operations"""
        try:
            if Arguments.from_legacy:
                if Arguments.backup_first:
                    self.Database.CreateBackup()
                    
                from ...Legacy.Migration.LegacyMigrator import LegacyMigrator
                Migrator = LegacyMigrator(self.Config, self.Logger, self.Database)
                Migrator.MigrateFromAndyPy()
                print("‚úÖ Legacy migration completed")
                
        except Exception as Error:
            self.Logger.Error(f"Migration failed: {{Error}}")
            raise
    
    def RunSetup(self, Arguments):
        """Execute initial setup operations"""
        try:
            if Arguments.reset:
                print("‚ö†Ô∏è Resetting all data...")
                self.Database.ResetDatabase()
                
            if Arguments.sample_data:
                print("üìö Loading sample data...")
                self.Database.LoadSampleData()
                
            print("‚úÖ Setup completed")
            
        except Exception as Error:
            self.Logger.Error(f"Setup failed: {{Error}}")
            raise
    
    def Shutdown(self):
        """Graceful application shutdown"""
        try:
            self.Logger.Info("Shutting down Digital Alexandria...")
            self.IsRunning = False
            
            # Close database connections
            self.Database.Close()
            
            # Cleanup AI engine
            self.AIEngine.Cleanup()
            
            self.Logger.Info("Digital Alexandria shutdown complete")
            
        except Exception as Error:
            self.Logger.Error(f"Error during shutdown: {{Error}}")
'''
            
            # Write foundation files
            FoundationFiles = [
                ("DigitalAlexandria.py", MainApp),
                ("Source/Core/Application.py", CoreApp),
                ("Source/Core/__init__.py", "# Digital Alexandria Core Foundation"),
                ("Source/AI/__init__.py", "# Digital Alexandria AI Engine"),
                ("Source/Interface/__init__.py", "# Digital Alexandria Interface Layer"),
                ("Source/Plugins/__init__.py", "# Digital Alexandria Plugin System")
            ]
            
            for FileName, Content in FoundationFiles:
                FilePath = self.ProjectPath / FileName
                FilePath.parent.mkdir(parents=True, exist_ok=True)
                
                with open(FilePath, 'w', encoding='utf-8') as File:
                    File.write(Content)
                    
                self.LogMessages.append(f"‚úÖ Created: {FileName}")
            
            print(f"   ‚úÖ Created {len(FoundationFiles)} foundation files")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error creating foundation files: {Error}")
            return False

    def CreateDocumentation(self) -> bool:
        """Create comprehensive project documentation"""
        try:
            print("üìö Creating Digital Alexandria Documentation...")
            
            # Main README with Digital Alexandria vision
            ReadmeContent = f'''# BowersWorld-com - Complete Library System
## Digital Alexandria Architecture - Herb's Legacy Project

**Created:** {self.TimestampStr}  
**Standard:** AIDEV-PascalCase-1.7  
**Author:** Herb Bowers - Project Himalaya  

---

## üèõÔ∏è The Grand Vision

> *"A library is not a luxury but one of the necessities of life."* - Henry Ward Beecher

BowersWorld-com implements the Digital Alexandria architecture - more than software, it's a **living repository of human knowledge** with every possible tool for discovery, analysis, and preservation built in from the ground up.

## üéØ Core Principles

### 1. Future-Proof Foundation
- **Modular Architecture**: Every component can be upgraded independently
- **Open Standards**: JSON, SQLite, REST APIs - never locked into proprietary formats
- **Extensible Design**: Hooks and interfaces everywhere for future features
- **Documentation**: Every decision explained for future maintainers

### 2. Knowledge Preservation  
- **Full-Text Indexing**: Every word searchable
- **Metadata Preservation**: Original + enhanced + user annotations
- **Version Control**: Track every change to every book record
- **Backup Strategy**: Multiple redundant storage options

### 3. Intelligence Everywhere
- **AI-Powered Discovery**: "Find books like this but more advanced"
- **Relationship Mapping**: Visual networks of related knowledge
- **Automatic Curation**: AI suggests collections and reading paths
- **Content Analysis**: Detect plagiarism, find citations, map influences

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 USER INTERFACES                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Web App ‚îÇ Desktop App ‚îÇ API ‚îÇ Mobile ‚îÇ Future Interfaces ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   AI LAYER                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Classification ‚îÇ Discovery ‚îÇ Analysis ‚îÇ Recommendations ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                 KNOWLEDGE ENGINE                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Full-Text Search ‚îÇ Semantic Search ‚îÇ Graph Database    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                   DATA LAYER                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   Books   ‚îÇ Metadata ‚îÇ Annotations ‚îÇ Analytics ‚îÇ Logs  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ Quick Start

### Prerequisites
- Python 3.9 or higher
- 4GB RAM minimum (8GB recommended)
- 10GB free disk space

### Installation
```bash
# Clean start setup
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Run foundation builder
python BowersWorldSetup.py

# Enter created project
cd BowersWorld-com

# Install dependencies
pip install -r requirements.txt

# Initialize system
python DigitalAlexandria.py setup --sample-data

# Start web interface
python DigitalAlexandria.py web
```

### Access Points
- **Web Interface**: http://localhost:8000
- **API Documentation**: http://localhost:8001/docs
- **Desktop Mode**: `python DigitalAlexandria.py desktop`

## üìñ Features

### Core Library Functions
- ‚úÖ **Intelligent Classification** (Multi-category, confidence scoring)
- ‚úÖ **Advanced Similarity** (Semantic, structural, conceptual)
- ‚úÖ **Duplicate Detection** (Sophisticated version/edition handling)
- ‚úÖ **Title Intelligence** (OCR, metadata fusion, confidence scoring)

### Discovery & Navigation
- üîç **Full-Text Search** (Every word in every book)
- üß† **Semantic Search** (Concept-based, not just keywords)
- üó∫Ô∏è **Knowledge Maps** (Visual relationship networks)
- üìä **Topic Clustering** (Auto-generated subject areas)
- üéØ **Smart Recommendations** (ML-powered suggestions)
- üìà **Reading Paths** (Guided learning sequences)

### AI-Powered Intelligence
- üìö **Multi-Modal Analysis** (Text, structure, metadata)
- üîó **Knowledge Graph Construction** (Relationship mapping)
- üéØ **Advanced Search** ("Books about X that don't require Y")
- üè∑Ô∏è **Auto-Classification** (Subject, difficulty, audience)
- üìä **Content Analysis** (Reading level, complexity, quality)

## üõ†Ô∏è Development

### Project Structure
```
BowersWorld-com/
‚îú‚îÄ‚îÄ Source/                    # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ Core/                 # Foundation layer
‚îÇ   ‚îú‚îÄ‚îÄ AI/                   # Intelligence engine
‚îÇ   ‚îú‚îÄ‚îÄ Interface/            # User interfaces
‚îÇ   ‚îú‚îÄ‚îÄ Collaboration/        # Multi-user features
‚îÇ   ‚îî‚îÄ‚îÄ Plugins/             # Extension system
‚îú‚îÄ‚îÄ Data/                     # Database and files
‚îú‚îÄ‚îÄ Config/                   # Configuration files
‚îú‚îÄ‚îÄ Documentation/            # Comprehensive docs
‚îú‚îÄ‚îÄ Tests/                    # Test suites
‚îú‚îÄ‚îÄ Scripts/                  # Utility scripts
‚îî‚îÄ‚îÄ Legacy/                   # Andy.py integration
```

### Development Commands
```bash
# Start development server
python DigitalAlexandria.py web --dev

# Run tests
pytest Tests/

# Database operations
python DigitalAlexandria.py admin --backup
python DigitalAlexandria.py admin --optimize

# Migration from legacy
python DigitalAlexandria.py migrate --from-legacy --backup-first
```

## üìä Success Metrics

### Technical Excellence
- ‚ö° Sub-second search across entire collection
- üéØ 95%+ classification accuracy
- üîç Semantic search that "understands" queries
- üìä 99.9% uptime and data integrity

### User Experience
- üòä Intuitive for 8-year-olds, powerful for PhD researchers
- üì± Works perfectly on any device
- ‚ôø Fully accessible (WCAG 2.1 AA compliant)
- üåç Internationalization ready

## üîß Configuration

### Environment Variables
- `ALEXANDRIA_ENV`: development|production|testing
- `ALEXANDRIA_DB_PATH`: Database file location
- `ALEXANDRIA_AI_CACHE`: AI model cache directory
- `ALEXANDRIA_LOG_LEVEL`: DEBUG|INFO|WARNING|ERROR

### Configuration Files
- `alexandria_config.json`: Main configuration
- `Config/Development/config.json`: Development settings
- `Config/Production/config.json`: Production settings

## ü§ù Contributing

1. Follow AIDEV-PascalCase-1.7 standards
2. All functions must have docstrings and type hints
3. Tests required for new features
4. Update documentation for changes

## üìÑ License

This project embodies 50+ years of development wisdom and is designed to preserve human knowledge for future generations. 

## üèÜ The Alexandria Principle

> *"Build not just for today's users, but for the scholars of 2050 who will discover knowledge we can't yet imagine."*

Every decision guided by:
- **Permanence**: Will this work in 20 years?
- **Extensibility**: Can future maintainers build on this?
- **Excellence**: Is this worthy of the world's knowledge?
- **Legacy**: Would the scholars of Alexandria be proud?

---

**This isn't just Herb's library - it's humanity's library, one scroll at a time.** üèõÔ∏è
'''
            
            # Development Guide
            DevGuideContent = f'''# BowersWorld-com Development Guide
## Digital Alexandria Architecture - AIDEV-PascalCase-1.7 Standards Implementation

**Created:** {self.TimestampStr}  
**Standard:** AIDEV-PascalCase-1.7  
**Author:** Herb Bowers - Project Himalaya  

---

## üéØ Development Philosophy

> *"My code, my way‚Äîclarity, maintainability, and personality matter."*

Every line of code follows the AIDEV-PascalCase-1.7 standard, ensuring consistency, readability, and long-term maintainability.

## üìã File Header Template

```python
#!/usr/bin/env python3
"""
File: FileName.py
Path: BowersWorld-com/Path/To/FileName.py
Standard: AIDEV-PascalCase-1.7
Created: YYYY-MM-DD  HH:MM
Modified: YYYY-MM-DD  HH:MM
Author: Herb Bowers - Project Himalaya
Contact: HimalayaProject1@gmail.com
Description: Brief description of file purpose

Purpose: Detailed explanation of what this file does and how it fits
into the Digital Alexandria architecture.

Dependencies: List of major dependencies
Usage: How to use this module
"""
```

## üèóÔ∏è Architecture Patterns

### Layered Architecture
```
User Interface Layer ‚Üí Business Logic Layer ‚Üí Data Access Layer
```

### Dependency Injection
```python
class ComponentClass:
    def __init__(self, Config: ConfigurationManager, Logger: AlexandriaLogger):
        self.Config = Config
        self.Logger = Logger
```

### Plugin Architecture
```python
class PluginInterface:
    def Initialize(self, Context: PluginContext) -> bool:
        pass
    
    def Execute(self, Parameters: Dict[str, Any]) -> PluginResult:
        pass
    
    def Cleanup(self) -> None:
        pass
```

## üîß Coding Standards

### Naming Conventions
- **Files & Modules**: PascalCase.py
- **Classes**: PascalCase
- **Functions & Methods**: PascalCase  
- **Variables**: PascalCase
- **Constants**: ALLCAPSWITHUNDERSCORES
- **Private**: _PrefixWithUnderscore

### Type Hints
```python
def ProcessBook(BookPath: str, Options: Dict[str, Any]) -> BookProcessingResult:
    """Process a book file with specified options"""
    pass
```

### Error Handling
```python
try:
    Result = ProcessSomething()
    return Result
except SpecificException as Error:
    self.Logger.Error(f"Specific error occurred: {{Error}}")
    raise
except Exception as Error:
    self.Logger.Error(f"Unexpected error: {{Error}}")
    raise
```

## üìä Testing Standards

### Unit Test Template
```python
#!/usr/bin/env python3
"""
File: TestSomething.py
Path: BowersWorld-com/Tests/Unit/TestSomething.py
Standard: AIDEV-PascalCase-1.7
Created: {self.TimestampStr}
Modified: {self.TimestampStr}
Author: Herb Bowers - Project Himalaya
Description: Unit tests for Something module
"""

import pytest
from unittest.mock import Mock, patch
from Source.Something import SomethingClass

class TestSomethingClass:
    def TestInitialization(self):
        # Test proper initialization
        pass
    
    def TestMainFunctionality(self):
        # Test core functionality
        pass
    
    def TestErrorHandling(self):
        # Test error conditions
        pass
```

## üìà Performance Guidelines

### Database Operations
- Use parameterized queries
- Implement connection pooling
- Add appropriate indexes
- Monitor query performance

### AI Processing
- Cache model results
- Batch process when possible
- Use GPU when available
- Implement fallback mechanisms

### Web Interface
- Implement lazy loading
- Use CDN for static assets
- Compress responses
- Cache API results

## üîå Plugin Development

### Plugin Structure
```
Plugins/
‚îî‚îÄ‚îÄ PluginName/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ PluginName.py
    ‚îú‚îÄ‚îÄ config.json
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ README.md
```

### Plugin Template
```python
from Source.Plugins.PluginInterface import PluginInterface

class MyPlugin(PluginInterface):
    def __init__(self):
        self.Name = "MyPlugin"
        self.Version = "1.0.0"
        self.Description = "Plugin description"
    
    def Initialize(self, Context: PluginContext) -> bool:
        # Plugin initialization logic
        return True
    
    def Execute(self, Parameters: Dict[str, Any]) -> PluginResult:
        # Main plugin functionality
        pass
    
    def Cleanup(self) -> None:
        # Cleanup resources
        pass
```

## üöÄ Deployment

### Development Environment
```bash
export ALEXANDRIA_ENV=development
export ALEXANDRIA_DEBUG=true
export ALEXANDRIA_LOG_LEVEL=DEBUG
python DigitalAlexandria.py web --dev
```

### Production Environment
```bash
export ALEXANDRIA_ENV=production
export ALEXANDRIA_DEBUG=false
export ALEXANDRIA_LOG_LEVEL=INFO
python DigitalAlexandria.py web --port 80
```

## üìã Checklist

### Before Committing
- [ ] All files have proper AIDEV headers
- [ ] Code follows PascalCase conventions
- [ ] Functions have docstrings and type hints
- [ ] Tests written and passing
- [ ] Documentation updated
- [ ] No hardcoded values
- [ ] Error handling implemented
- [ ] Logging added where appropriate

### Before Release
- [ ] Performance testing completed
- [ ] Security review passed
- [ ] Documentation complete
- [ ] Migration scripts tested
- [ ] Backup procedures verified
- [ ] Monitoring configured

---

*Remember: Every line of code is a brick in the foundation of BowersWorld-com's Digital Alexandria architecture. Build with pride, precision, and permanence.* üèõÔ∏è
'''
            
            # Write documentation files
            DocumentationFiles = [
                ("README.md", ReadmeContent),
                ("Documentation/DevelopmentGuide.md", DevGuideContent),
                ("Documentation/STANDARDS.md", "# AIDEV-PascalCase-1.7 Standards Reference\\n\\nSee DevelopmentGuide.md for complete standards documentation."),
                ("Documentation/API/README.md", "# Digital Alexandria API Documentation\\n\\nAPI documentation will be auto-generated."),
                ("Documentation/Architecture/SystemDesign.md", "# Digital Alexandria System Architecture\\n\\nDetailed architecture documentation."),
                (".gitignore", self.CreateGitIgnore()),
                ("CHANGELOG.md", f"# BowersWorld-com Changelog\\n\\n## Version 1.0.0 - {self.TimestampStr}\\n- Digital Alexandria architecture foundation created\\n- Complete BowersWorld-com structure implemented\\n- AIDEV-PascalCase-1.7 standards applied")
            ]
            
            for FileName, Content in DocumentationFiles:
                FilePath = self.ProjectPath / FileName
                FilePath.parent.mkdir(parents=True, exist_ok=True)
                
                with open(FilePath, 'w', encoding='utf-8') as File:
                    File.write(Content)
                    
                self.LogMessages.append(f"‚úÖ Created: {FileName}")
            
            print(f"   ‚úÖ Created {len(DocumentationFiles)} documentation files")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error creating documentation: {Error}")
            return False

    def CreateGitIgnore(self) -> str:
        """Generate appropriate .gitignore file"""
        return '''# BowersWorld-com - .gitignore
# Generated by BowersWorld-com Setup (Digital Alexandria Architecture)

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environments
venv/
env/
ENV/
.venv/
.env/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# BowersWorld-com Specific (Digital Alexandria Architecture)
Data/Database/*.db
Data/Database/*.db-*
Data/Cache/
Data/Backups/
Logs/
*.log

# Sensitive Configuration
Config/Production/secrets.json
Config/Production/api_keys.json
.env
.env.local
.env.production

# AI Models (large files)
Source/AI/Models/*.bin
Source/AI/Models/*.pt
Source/AI/Models/*.h5
Source/AI/Training/

# Temporary Files
tmp/
temp/
*.tmp
*.temp

# OS Generated
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Coverage Reports
htmlcov/
.coverage
.coverage.*
coverage.xml
*.cover

# Testing
.pytest_cache/
.tox/
'''

    def GenerateSetupReport(self) -> bool:
        """Generate comprehensive setup report"""
        try:
            print("üìÑ Generating Setup Report...")
            
            ReportPath = self.ProjectPath / f"Setup_Report_{self.Timestamp.strftime('%Y%m%d_%H%M%S')}.txt"
            
            ReportContent = f"""
BowersWorld-com - Complete Project Setup Report
(Digital Alexandria Architecture Implementation)
Generated: {self.TimestampStr}
Standard: AIDEV-PascalCase-1.7
Author: Herb Bowers - Project Himalaya

================================================================
SETUP SUMMARY
================================================================

Project Location: {self.ProjectPath}
Setup Completed: {self.TimestampStr}
Total Operations: {len(self.LogMessages)}

Architecture: Digital Alexandria Blueprint Implementation
- Layered Architecture Pattern
- Plugin-Based Extension System  
- AI-Powered Intelligence Layer
- Multi-Interface Support (Web/Desktop/Mobile/API)
- Full AIDEV-PascalCase-1.7 Standards Compliance

================================================================
OPERATIONS COMPLETED
================================================================

{chr(10).join(self.LogMessages)}

================================================================
NEXT STEPS
================================================================

1. ENTER PROJECT DIRECTORY
   cd BowersWorld-com

2. INSTALL DEPENDENCIES
   pip install -r requirements.txt

3. INITIALIZE SYSTEM
   python DigitalAlexandria.py setup --sample-data

4. START WEB INTERFACE
   python DigitalAlexandria.py web --dev
   Access: http://localhost:8000

5. START API SERVER
   python DigitalAlexandria.py api --docs
   Access: http://localhost:8001/docs

6. LEGACY MIGRATION (if needed)
   python DigitalAlexandria.py migrate --from-legacy --backup-first

7. DEVELOPMENT WORKFLOW
   - Follow AIDEV-PascalCase-1.7 standards
   - Run tests: pytest Tests/
   - Generate docs: Update Documentation/
   - Plugin development: See Documentation/DevelopmentGuide.md

8. GITHUB REPOSITORY
   - Initialize: git init
   - Add remote: git remote add origin [your-repo-url]
   - Initial commit: git add . && git commit -m "Initial Digital Alexandria foundation"
   - Push: git push -u origin main

================================================================
PROJECT STRUCTURE CREATED - CLEAN START
================================================================

Current Directory/
‚îú‚îÄ‚îÄ venv/                      # Virtual environment
‚îú‚îÄ‚îÄ BowersWorldSetup.py        # Setup script (can be removed after setup)
‚îî‚îÄ‚îÄ BowersWorld-com/           # Complete Digital Alexandria project
    ‚îú‚îÄ‚îÄ Source/                # Main source code (Layered Architecture)
‚îÇ   ‚îú‚îÄ‚îÄ Core/                 # Foundation Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Application.py    # Main application orchestrator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Configuration.py  # Configuration management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Database.py       # Database abstraction layer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Logger.py         # Logging system
‚îÇ   ‚îú‚îÄ‚îÄ AI/                   # Intelligence Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AIEngine.py       # AI orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Classification/   # Book classification
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Discovery/        # Knowledge discovery
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Analytics/        # Content analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Models/           # AI model storage
‚îÇ   ‚îú‚îÄ‚îÄ Interface/            # User Interface Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Web/             # Modern web interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Desktop/         # Desktop application
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Mobile/          # Mobile interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ API/             # RESTful API
‚îÇ   ‚îú‚îÄ‚îÄ Collaboration/        # Multi-User Features
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Users/           # User management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Annotations/     # Note/highlight system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Collections/     # Shared collections
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Social/          # Social features
‚îÇ   ‚îî‚îÄ‚îÄ Plugins/             # Extension System
‚îÇ       ‚îú‚îÄ‚îÄ Classification/   # Classification plugins
‚îÇ       ‚îú‚îÄ‚îÄ Search/          # Search plugins
‚îÇ       ‚îú‚îÄ‚îÄ Analysis/        # Analysis plugins
‚îÇ       ‚îî‚îÄ‚îÄ Export/          # Export plugins
‚îú‚îÄ‚îÄ Data/                     # Data Storage
‚îÇ   ‚îú‚îÄ‚îÄ Database/            # SQLite databases
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Alexandria.db    # Main database (v2.0 schema)
‚îÇ   ‚îú‚îÄ‚îÄ Books/               # PDF library files
‚îÇ   ‚îú‚îÄ‚îÄ Covers/              # Book cover images
‚îÇ   ‚îú‚îÄ‚îÄ Thumbnails/          # Web-optimized thumbnails
‚îÇ   ‚îú‚îÄ‚îÄ Cache/               # Temporary cache
‚îÇ   ‚îî‚îÄ‚îÄ Backups/             # Database backups
‚îú‚îÄ‚îÄ Config/                   # Configuration Management
‚îÇ   ‚îú‚îÄ‚îÄ Development/         # Development settings
‚îÇ   ‚îú‚îÄ‚îÄ Production/          # Production settings
‚îÇ   ‚îú‚îÄ‚îÄ Testing/             # Test settings
‚îÇ   ‚îî‚îÄ‚îÄ Deployment/          # Deployment configs
‚îú‚îÄ‚îÄ Documentation/            # Comprehensive Documentation
‚îÇ   ‚îú‚îÄ‚îÄ API/                 # API documentation
‚îÇ   ‚îú‚îÄ‚îÄ Architecture/        # System architecture docs
‚îÇ   ‚îú‚îÄ‚îÄ Standards/           # AIDEV-PascalCase-1.7 standards
‚îÇ   ‚îú‚îÄ‚îÄ Guides/              # User/developer guides
‚îÇ   ‚îî‚îÄ‚îÄ Research/            # Research notes
‚îú‚îÄ‚îÄ Tests/                    # Testing Infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ Unit/                # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ Integration/         # Integration tests
‚îÇ   ‚îú‚îÄ‚îÄ Performance/         # Performance tests
‚îÇ   ‚îî‚îÄ‚îÄ Data/                # Test data
‚îú‚îÄ‚îÄ Scripts/                  # Utility Scripts
‚îÇ   ‚îú‚îÄ‚îÄ Migration/           # Data migration scripts
‚îÇ   ‚îú‚îÄ‚îÄ Development/         # Development utilities
‚îÇ   ‚îú‚îÄ‚îÄ Deployment/          # Deployment scripts
‚îÇ   ‚îî‚îÄ‚îÄ Maintenance/         # Maintenance scripts
‚îú‚îÄ‚îÄ Legacy/                   # Legacy Integration
‚îÇ   ‚îú‚îÄ‚îÄ Andy/                # Andy.py desktop app integration
‚îÇ   ‚îú‚îÄ‚îÄ Migration/           # Legacy migration tools
‚îÇ   ‚îî‚îÄ‚îÄ Archive/             # Archived legacy code
‚îú‚îÄ‚îÄ alexandria_config.json    # Main configuration
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ DigitalAlexandria.py     # Main application entry point
‚îî‚îÄ‚îÄ README.md                # Project documentation

================================================================
DATABASE SCHEMA (v2.0)
================================================================

Core Tables:
- Books: Enhanced metadata with AI analysis fields
- BookRelationships: Knowledge graph connections
- BooksFullText: Full-text search virtual table
- Users: Multi-user support
- Annotations: User notes and highlights
- Collections: Shared reading lists
- BookAnalytics: Usage tracking
- SystemConfig: Configuration storage

Key Features:
- Full-text search with FTS5
- Knowledge graph relationships
- AI analysis result storage
- Multi-user collaboration
- Comprehensive analytics
- Version control support

================================================================
CONFIGURATION FILES
================================================================

alexandria_config.json: Main project configuration
Config/Development/config.json: Development environment
Config/Production/config.json: Production environment  
requirements.txt: Python dependencies

Key Settings:
- Database: SQLite with FTS5 full-text search
- AI Engine: Multi-model ensemble architecture
- Web Framework: FastAPI + React (future)
- Desktop Legacy: PySide6 (Andy.py integration)
- Plugin System: Hook-based extensions

================================================================
DIGITAL ALEXANDRIA FEATURES
================================================================

üèõÔ∏è FOUNDATION LAYER
- Future-proof modular architecture
- SQLite + FTS5 full-text search
- Comprehensive logging and monitoring
- Configuration management
- Multi-environment support

üß† AI INTELLIGENCE LAYER  
- Multi-model book classification
- Semantic similarity analysis
- Knowledge graph construction
- Content analysis and scoring
- Recommendation engine

üñ•Ô∏è INTERFACE LAYER
- Modern web interface (responsive)
- Legacy desktop integration (Andy.py)
- RESTful API with documentation
- Mobile-friendly design
- Plugin-extensible views

ü§ù COLLABORATION LAYER
- Multi-user support
- Annotation and note sharing
- Collaborative collections
- Social features
- Access control

üîå PLUGIN SYSTEM
- Classification plugins
- Search algorithm plugins
- Analysis tool plugins
- Export/import plugins
- Future-ready extension points

================================================================
SUCCESS METRICS
================================================================

Technical Excellence:
‚úÖ Sub-second search across entire collection
‚úÖ 95%+ classification accuracy target
‚úÖ Semantic search understanding
‚úÖ 99.9% uptime and data integrity

User Experience:
‚úÖ Intuitive for beginners, powerful for experts
‚úÖ Cross-device compatibility
‚úÖ Full accessibility (WCAG 2.1 AA)
‚úÖ Internationalization ready

Legacy Impact:
‚úÖ Architecture others can replicate
‚úÖ Educational value for developers
‚úÖ Research contributions to digital libraries
‚úÖ Model for knowledge preservation

================================================================
THE ALEXANDRIA PRINCIPLE
================================================================

"Build not just for today's users, but for the scholars of 2050 
who will discover knowledge we can't yet imagine."

Every decision guided by:
- Permanence: Will this work in 20 years?
- Extensibility: Can future maintainers build on this?
- Excellence: Is this worthy of the world's knowledge?
- Legacy: Would the scholars of Alexandria be proud?

================================================================
STATUS: BOWERSWORLD-COM FOUNDATION COMPLETE ‚úÖ
================================================================

The foundation is laid. The architecture is sound. The standards 
are enforced. BowersWorld-com with Digital Alexandria architecture 
is ready for a fresh GitHub push and development!

üîÑ Clean Start Complete:
- Old project safely moved/archived
- Fresh Digital Alexandria architecture implemented  
- GitHub repository ready for population
- AIDEV-PascalCase-1.7 standards throughout
- Legacy migration tools included for future reference

Ready to build the future of human knowledge preservation! üèõÔ∏è

"""
            
            with open(ReportPath, 'w', encoding='utf-8') as File:
                File.write(ReportContent)
            
            print(f"   ‚úÖ Setup report: {ReportPath}")
            return True
            
        except Exception as Error:
            print(f"   ‚ùå Error generating report: {Error}")
            return False

    def Execute(self) -> bool:
        """Execute complete BowersWorld-com setup with Digital Alexandria architecture"""
        print("üöÄ Starting BowersWorld-com Complete Setup (Digital Alexandria Architecture)...")
        print()
        
        SetupSteps = [
            ("Project Structure", self.CreateProjectStructure),
            ("Configuration Files", self.CreateConfigurationFiles), 
            ("Foundation Database", self.CreateFoundationDatabase),
            ("Core Foundation Files", self.CreateCoreFoundationFiles),
            ("Documentation", self.CreateDocumentation),
            ("Setup Report", self.GenerateSetupReport)
        ]
        
        SuccessCount = 0
        for StepName, StepFunction in SetupSteps:
            if StepFunction():
                SuccessCount += 1
            else:
                print(f"‚ö†Ô∏è {StepName} encountered issues but setup continues...")
        
        print()
        print("=" * 60)
        if SuccessCount == len(SetupSteps):
            print("üéâ BowersWorld-com Foundation Setup COMPLETE!")
            print("   (Digital Alexandria Architecture Implemented)")
            print()
            print("üèõÔ∏è BowersWorld-com is ready for development!")
            print()
            print("üìã Next Steps:")
            print("   1. cd BowersWorld-com")
            print("   2. pip install -r requirements.txt")  
            print("   3. python DigitalAlexandria.py setup --sample-data")
            print("   4. python DigitalAlexandria.py web --dev")
            print("   5. Access: http://localhost:8000")
            print()
            print("üêô GitHub Repository Setup:")
            print("   1. git init")
            print("   2. git remote add origin [your-repo-url]")
            print("   3. git add . && git commit -m 'Initial Digital Alexandria foundation'")
            print("   4. git push -u origin main")
            print()
            print("üìö Documentation: See Documentation/ folder")
            print("üîß Standards: Follow AIDEV-PascalCase-1.7")
            print("üéØ Vision: Digital Alexandria architecture!")
            print()
            print(f"‚úÖ Setup completed: {SuccessCount}/{len(SetupSteps)} operations successful")
            return True
        else:
            print(f"‚ö†Ô∏è Setup completed with warnings: {SuccessCount}/{len(SetupSteps)} operations successful")
            print("   Check individual step messages above for details")
            return False

def Main():
    """Main setup script entry point"""
    try:
        print("üèõÔ∏è BowersWorld-com Foundation Builder")
        print("   Digital Alexandria Architecture Implementation")
        print("   AIDEV-PascalCase-1.7 Standards")
        print("   Project Himalaya - Herb Bowers")
        print()
        
        # Setup location guidance
        CurrentDir = Path.cwd()
        print(f"üìÅ Current Directory: {CurrentDir}")
        print()
        print("üéØ CLEAN START SETUP:")
        print("   1. Create project directory: mkdir BowersWorld-com")
        print("   2. Enter directory: cd BowersWorld-com")
        print("   3. Create virtual environment: python -m venv venv")
        print("   4. Activate venv: source venv/bin/activate (or venv\\Scripts\\activate)")
        print("   5. Run setup: python BowersWorldSetup.py")
        print("   6. This creates complete BowersWorld-com/ structure")
        print("   7. GitHub repo ready for fresh push")
        print()
        
        # Check if we're in the right location
        if os.path.exists("BowersWorld-com"):
            print("‚ö†Ô∏è  BowersWorld-com directory already exists!")
            print("   This will REPLACE/REBUILD the entire project structure")
            print("   Old project has been moved - this is a clean foundation build")
            print()
            Response = input("   Continue with clean rebuild? (y/N): ").strip().lower()
            if Response != 'y':
                print("   Setup cancelled.")
                print()
                print("üöÄ For clean setup, remove existing BowersWorld-com first:")
                print("   rm -rf BowersWorld-com  # or move to backup location")
                print("   python BowersWorldSetup.py")
                return False
        else:
            print("‚úÖ Clean directory - perfect for fresh BowersWorld-com foundation!")
            print()
        
        # Create setup instance and execute
        Setup = BowersWorldSetup()
        return Setup.Execute()
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Setup interrupted by user")
        return False
    except Exception as Error:
        print(f"\n‚ùå Setup failed: {Error}")
        return False

if __name__ == "__main__":
    Success = Main()
    sys.exit(0 if Success else 1)

================
File: Scripts/System/CodebaseSum.py
================
#!/usr/bin/env python3
"""
File: CodebaseSum.py
Path: BowersWorld-com/Scripts/CodebaseSum.py
Created: 2025-06-25
Description: Generate a comprehensive codebase snapshot in a structured format
"""

import os
import subprocess
import tempfile
from datetime import datetime
from pathlib import Path
import shutil
import fnmatch
import PyPDF2
from PyPDF2 import PdfReader

def get_gitignore_patterns(gitignore_path=".gitignore"):
    patterns = set()
    if os.path.exists(gitignore_path):
        with open(gitignore_path, 'r') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    # Normalize patterns: remove leading / and trailing / if not needed
                    if line.startswith('/'):
                        line = line[1:]
                    patterns.add(line)
    return patterns

def is_ignored(path, gitignore_patterns):
    """
    Checks if a given path should be ignored based on .gitignore patterns.
    This is a simplified implementation and may not cover all gitignore complexities.
    """
    path_str = str(path)
    # Check if the path directly matches any pattern
    for pattern in gitignore_patterns:
        # Handle directory patterns (ending with /)
        if pattern.endswith('/'):
            if path.is_dir() and fnmatch.fnmatch(path_str + '/', pattern):
                return True
            elif path.is_file() and fnmatch.fnmatch(path_str, pattern[:-1]): # Match files within ignored dirs
                return True
        elif fnmatch.fnmatch(path_str, pattern):
            return True
        # Handle patterns that are just directory names without leading/trailing slashes
        if path.is_dir() and fnmatch.fnmatch(path.name, pattern):
            return True
    return False

def main():
    # Create timestamp for the output filename
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"CodebaseSummary_{timestamp}.txt"
    
    # Check if the tree command is available
    if not shutil.which('tree'):
        print("Error: The 'tree' command is required but not found. Please install it first.")
        return 1
    
    print(f"Generating codebase summary to {output_file}...")
    
    # Create temp directory for building the summary
    with tempfile.TemporaryDirectory() as temp_dir:
        header_file = os.path.join(temp_dir, "header.txt")
        structure_file = os.path.join(temp_dir, "structure.txt")
        files_list = os.path.join(temp_dir, "files_list.txt")
        files_content = os.path.join(temp_dir, "files_content.txt")
        
        # Create the header
        header_content = """This file is a comprehensive codebase snapshot for the BowersWorld-com project, generated to facilitate analysis and development.

================================================================
File Summary
================================================================

Purpose:
--------
This document provides a consolidated view of the project's source code, scripts,
HTML, and text files, excluding any files specified in the .gitignore file. 
It serves as a reference for developers, making it easier to understand the 
codebase structure and functionality in a single document.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
5. List of Program files
6. List of Documents

"""
        
        with open(header_file, 'w') as f:
            f.write(header_content)
        
        # Generate directory structure using tree
        print("Generating directory structure...")
        # Get exclusion patterns from .gitignore for tree command
        gitignore_patterns_for_tree = get_gitignore_patterns()
        # Convert patterns to a format suitable for tree's -I option
        # Tree's -I uses fnmatch, so we can directly use the patterns.
        # We need to explicitly include some common system-level ignores for tree
        common_tree_excludes = [
            '.git', '__pycache__', '.venv', 'venv', 'ENV', '.idea', '.vscode',
            'Temp', 'Logs', 'build', 'dist', 'env', 'lib', 'lib64', 'parts', 
            'sdist', 'var', 'downloads', 'eggs', '.eggs', 'develop-eggs',
            'Covers', 'Thumbs', 'Html', 'Docs', 'node_modules'
        ]
        tree_ignore_patterns = list(set(common_tree_excludes).union(gitignore_patterns_for_tree))
        
        tree_cmd = ['tree', '-f', '-I', '|'.join(tree_ignore_patterns), '.']
        with open(structure_file, 'w') as f:
            subprocess.run(tree_cmd, stdout=f)
        
        # Create the files section header
        with open(files_content, 'w') as f:
            f.write("================================================================\n")
            f.write("Files\n")
            f.write("================================================================\n")
            f.write("\n")
        
        # Get exclusion patterns from .gitignore for os.walk
        gitignore_patterns_for_walk = get_gitignore_patterns()

        # Define common directories to exclude for os.walk based on gitignore and common patterns
        # These are explicit directories that should always be skipped by os.walk,
        # in addition to those matched by gitignore patterns.
        explicit_exclude_dirs_walk = {
            '.git', '__pycache__', '.venv', 'venv', 'ENV', '.idea', '.vscode',
            'Temp', 'Logs', 'build', 'dist', 'env', 'lib', 'lib64', 'parts',
            'sdist', 'var', 'downloads', 'eggs', '.eggs', 'develop-eggs',
            'Covers', 'Thumbs', 'Html', 'Docs', 'node_modules'
        }

        # Find relevant project files
        print("Finding relevant project files (.py, .sh, .md, .html, .txt, .pdf)...")
        file_extensions = {'.py', '.sh', '.md', '.html', '.txt', '.pdf'}
        relevant_files = []

        for root, dirs, files in os.walk('.'):
            # Filter directories in-place to avoid walking into excluded ones
            dirs_to_keep = []
            for d in list(dirs): # Iterate over a copy because we modify 'dirs'
                current_dir_path = Path(root) / d
                rel_dir_path = current_dir_path.relative_to('.')
                
                # Check explicit excludes first
                if d in explicit_exclude_dirs_walk:
                    dirs.remove(d)
                    continue
                
                # Check against gitignore patterns
                if is_ignored(rel_dir_path, gitignore_patterns_for_walk):
                    dirs.remove(d)
                else:
                    dirs_to_keep.append(d)
            dirs[:] = dirs_to_keep # Update dirs for the current walk iteration

            for file in files:
                file_path = Path(root) / file
                rel_file_path = file_path.relative_to('.')
                
                # Skip .gitignore file itself
                if file == '.gitignore':
                    continue

                # Check if file has relevant extension
                if file_path.suffix in file_extensions:
                    # Check if the file path should be ignored by gitignore patterns
                    if is_ignored(rel_file_path, gitignore_patterns_for_walk):
                        continue
                    
                    relevant_files.append(rel_file_path)
        
        # Sort files for consistent output
        relevant_files.sort(key=str) # Sort Path objects by their string representation
        
        # Write files list
        with open(files_list, 'w') as f:
            for file_path in relevant_files:
                f.write(f"{file_path}\n")
        
        # Process each file found
        print("Processing files...")
        with open(files_content, 'a') as fc:
            for p_obj in relevant_files: # Iterate over Path objects
                file_path_str = str(p_obj) # Get string representation for os.path.isfile
                if os.path.isfile(file_path_str):
                    current_file_path = Path(file_path_str) # Convert back to Path object for .suffix
                    fc.write("================\n")
                    fc.write(f"File: {current_file_path}\n")
                    fc.write("================\n")
                    try:
                        if current_file_path.suffix == '.pdf':
                            pdf_content = ""
                            with open(current_file_path, 'rb') as pdf_file:
                                pdf_reader = PdfReader(pdf_file)
                                for page_num in range(len(pdf_reader.pages)):
                                    page = pdf_reader.pages[page_num]
                                    text = page.extract_text()
                                    if text: # Only add if text is extracted
                                        pdf_content += text + "\n"
                            if pdf_content:
                                fc.write(pdf_content)
                            else:
                                fc.write("[PDF file: No extractable text content]\n")
                        else:
                            with open(current_file_path, 'r', encoding='utf-8') as f:
                                fc.write(f.read())
                    except Exception as e: # Catch all exceptions for reading files, including PDFs
                        fc.write(f"[Error reading content: {e} - content not displayed]\n")
                    fc.write("\n")
        
        # Combine all parts into the final file
        with open(output_file, 'w') as output:
            # Write header
            with open(header_file, 'r') as f:
                output.write(f.read())
            
            # Write directory structure
            output.write("================================================================\n")
            output.write("Directory Structure\n")
            output.write("================================================================\n")
            with open(structure_file, 'r') as f:
                output.write(f.read())
            output.write("\n")
            
            # Write files content
            with open(files_content, 'r') as f:
                output.write(f.read())
            
            # Write file list
            output.write("\n")
            output.write("================================================================\n")
            output.write("List of Included Files\n")
            output.write("================================================================\n")
            output.write("\n")
            output.write("Files included:\n")
            with open(files_list, 'r') as f:
                output.write(f.read())
            
            num_files = len(relevant_files)
            output.write(f"\nThere are {num_files} files included in the Files section of the CodebaseSummary document.\n")
    
    print(f"Codebase summary generated: {output_file}")
    print(f"It contains {len(relevant_files)} files.")
    
    return 0

if __name__ == "__main__":
    exit(main())

================
File: Scripts/System/GPU OCR Speed Test.py
================
#!/usr/bin/env python3
"""
GPU OCR Speed Test - Compare CPU vs GPU OCR performance
"""

import time
import torch
from pathlib import Path
import fitz  # PyMuPDF
from pdf2image import convert_from_path
import tempfile

def test_gpu_availability():
    """Test if CUDA GPU is available"""
    print("üîç GPU AVAILABILITY CHECK")
    print("=" * 40)
    
    # Check CUDA
    cuda_available = torch.cuda.is_available()
    print(f"CUDA Available: {cuda_available}")
    
    if cuda_available:
        gpu_count = torch.cuda.device_count()
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"GPU Count: {gpu_count}")
        print(f"GPU Name: {gpu_name}")
        print(f"GPU Memory: {gpu_memory:.1f} GB")
        
        return True
    else:
        print("‚ùå CUDA not available")
        return False

def test_easyocr_speed(pdf_path):
    """Test EasyOCR speed with GPU"""
    try:
        import easyocr
        
        print("\nüöÄ TESTING EASYOCR (GPU)")
        print("=" * 40)
        
        # Initialize EasyOCR with GPU
        reader = easyocr.Reader(['en'], gpu=True)
        
        # Convert first page to image
        with tempfile.TemporaryDirectory() as temp_dir:
            pages = convert_from_path(pdf_path, first_page=1, last_page=1, dpi=300)
            
            if pages:
                start_time = time.time()
                
                # Perform OCR
                results = reader.readtext(pages[0])
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                # Extract text
                extracted_text = ' '.join([result[1] for result in results])
                
                print(f"‚è±Ô∏è Processing time: {processing_time:.2f} seconds")
                print(f"üìÑ Text extracted: {len(extracted_text)} characters")
                print(f"üìù Sample: {extracted_text[:200]}...")
                
                return processing_time, len(extracted_text)
                
    except ImportError:
        print("‚ùå EasyOCR not installed. Install with: pip install easyocr")
        return None, None
    except Exception as e:
        print(f"‚ùå EasyOCR test failed: {e}")
        return None, None

def test_tesseract_speed(pdf_path):
    """Test current Tesseract speed for comparison"""
    try:
        import pytesseract
        
        print("\nüêå TESTING TESSERACT (CPU)")
        print("=" * 40)
        
        # Convert first page to image
        with tempfile.TemporaryDirectory() as temp_dir:
            pages = convert_from_path(pdf_path, first_page=1, last_page=1, dpi=300)
            
            if pages:
                start_time = time.time()
                
                # Perform OCR
                extracted_text = pytesseract.image_to_string(pages[0])
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                print(f"‚è±Ô∏è Processing time: {processing_time:.2f} seconds")
                print(f"üìÑ Text extracted: {len(extracted_text)} characters")
                print(f"üìù Sample: {extracted_text[:200]}...")
                
                return processing_time, len(extracted_text)
                
    except Exception as e:
        print(f"‚ùå Tesseract test failed: {e}")
        return None, None

def test_paddleocr_speed(pdf_path):
    """Test PaddleOCR speed with GPU"""
    try:
        from paddleocr import PaddleOCR
        
        print("\n‚ö° TESTING PADDLEOCR (GPU)")
        print("=" * 40)
        
        # Initialize PaddleOCR with GPU
        ocr = PaddleOCR(use_angle_cls=True, lang='en', use_gpu=True)
        
        # Convert first page to image
        with tempfile.TemporaryDirectory() as temp_dir:
            pages = convert_from_path(pdf_path, first_page=1, last_page=1, dpi=300)
            
            if pages:
                # Save image temporarily
                img_path = f"{temp_dir}/test_page.png"
                pages[0].save(img_path)
                
                start_time = time.time()
                
                # Perform OCR
                results = ocr.ocr(img_path, cls=True)
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                # Extract text
                extracted_text = ''
                if results and results[0]:
                    extracted_text = ' '.join([line[1][0] for line in results[0]])
                
                print(f"‚è±Ô∏è Processing time: {processing_time:.2f} seconds")
                print(f"üìÑ Text extracted: {len(extracted_text)} characters")
                print(f"üìù Sample: {extracted_text[:200]}...")
                
                return processing_time, len(extracted_text)
                
    except ImportError:
        print("‚ùå PaddleOCR not installed. Install with: pip install paddlepaddle-gpu paddleocr")
        return None, None
    except Exception as e:
        print(f"‚ùå PaddleOCR test failed: {e}")
        return None, None

def main():
    """Main speed test function"""
    print("üöÄ GPU OCR SPEED TEST FOR RTX 4070")
    print("=" * 50)
    
    # Test GPU availability
    gpu_available = test_gpu_availability()
    
    if not gpu_available:
        print("\n‚ùå No GPU acceleration available")
        return
    
    # Find a test PDF
    pdf_dir = Path("/home/herb/Desktop/Not Backed Up/Anderson's Library/Andy/Anderson eBooks")
    test_pdfs = list(pdf_dir.glob("*.pdf"))[:3]  # Test first 3 PDFs
    
    if not test_pdfs:
        print("‚ùå No test PDFs found")
        return
    
    print(f"\nüìö Testing with: {test_pdfs[0].name}")
    
    # Test each OCR method
    results = {}
    
    # Test Tesseract (current method)
    tesseract_time, tesseract_chars = test_tesseract_speed(test_pdfs[0])
    if tesseract_time:
        results['Tesseract (CPU)'] = tesseract_time
    
    # Test EasyOCR
    easyocr_time, easyocr_chars = test_easyocr_speed(test_pdfs[0])
    if easyocr_time:
        results['EasyOCR (GPU)'] = easyocr_time
    
    # Test PaddleOCR
    paddleocr_time, paddleocr_chars = test_paddleocr_speed(test_pdfs[0])
    if paddleocr_time:
        results['PaddleOCR (GPU)'] = paddleocr_time
    
    # Show comparison
    print("\nüìä SPEED COMPARISON RESULTS")
    print("=" * 50)
    
    if results:
        fastest_method = min(results.items(), key=lambda x: x[1])
        
        for method, time_taken in results.items():
            speedup = tesseract_time / time_taken if tesseract_time and method != 'Tesseract (CPU)' else 1.0
            status = "üèÜ" if method == fastest_method[0] else "‚ö°" if speedup > 1 else "üêå"
            
            print(f"{status} {method}: {time_taken:.2f}s (√ó{speedup:.1f} speedup)")
        
        print(f"\nüéØ RECOMMENDATION:")
        print(f"   Fastest method: {fastest_method[0]} ({fastest_method[1]:.2f}s)")
        
        if fastest_method[1] < tesseract_time:
            total_speedup = tesseract_time / fastest_method[1]
            new_total_time = 6 * 60 / total_speedup  # 6 hours in minutes
            print(f"   Total processing speedup: √ó{total_speedup:.1f}")
            print(f"   Estimated new total time: {new_total_time:.0f} minutes ({new_total_time/60:.1f} hours)")
    
    print("\n" + "=" * 50)

if __name__ == "__main__":
    main()

================
File: Scripts/System/GitHubAutoUpdate.py
================
# GitHub Auto-Update Script for BowersWorld.com
# Author: Herb Bowers - Project Himalaya
# Created: 2025-06-22  17:15
# Path: /scripts/AutoUpdateGitHub.py

import os
import sys
import subprocess
import json
import time
from datetime import datetime
from pathlib import Path
import argparse


class GitHubAutoUpdater:
    def __init__(self, repo_path=None, remote_name="origin", branch="main"):
        """
        Initialize the GitHub auto-updater
        
        Args:
            repo_path: Path to your local repository (if None, uses current directory)
            remote_name: Git remote name (usually "origin")
            branch: Branch to push to (usually "main")
        """
        self.repo_path = Path(repo_path) if repo_path else Path.cwd()
        self.remote_name = remote_name
        self.branch = branch
        
        # Ensure we're in a git repository
        if not (self.repo_path / '.git').exists():
            raise Exception(f"Not a git repository: {self.repo_path}")
    
    def RunGitCommand(self, command):
        """Execute git command and return result"""
        try:
            result = subprocess.run(
                command,
                cwd=self.repo_path,
                shell=True,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            print(f"Git command failed: {command}")
            print(f"Error: {e.stderr}")
            raise
    
    def CheckGitStatus(self):
        """Check if there are any changes to commit"""
        try:
            # Check for unstaged changes
            unstaged = self.RunGitCommand("git diff --name-only")
            
            # Check for staged changes
            staged = self.RunGitCommand("git diff --cached --name-only")
            
            # Check for untracked files
            untracked = self.RunGitCommand("git ls-files --others --exclude-standard")
            
            changes = {
                'unstaged': unstaged.split('\n') if unstaged else [],
                'staged': staged.split('\n') if staged else [],
                'untracked': untracked.split('\n') if untracked else []
            }
            
            return changes
        except Exception as e:
            print(f"Error checking git status: {e}")
            return None
    
    def AddFiles(self, files=None):
        """Add files to staging area"""
        if files:
            for file in files:
                self.RunGitCommand(f"git add {file}")
        else:
            # Add all changes
            self.RunGitCommand("git add .")
    
    def CreateCommit(self, message=None, auto_message=True):
        """Create a commit with given message"""
        if not message and auto_message:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            message = f"Auto-update: {timestamp}"
        elif not message:
            raise ValueError("Commit message required when auto_message=False")
        
        self.RunGitCommand(f'git commit -m "{message}"')
        return message
    
    def PushToGitHub(self):
        """Push changes to GitHub"""
        push_command = f"git push {self.remote_name} {self.branch}"
        self.RunGitCommand(push_command)
    
    def AutoUpdate(self, commit_message=None, files=None, verbose=True):
        """
        Complete auto-update workflow: add, commit, push
        
        Args:
            commit_message: Custom commit message (auto-generated if None)
            files: Specific files to add (all changes if None)
            verbose: Print status messages
        """
        if verbose:
            print("üîÑ Starting GitHub auto-update...")
        
        try:
            # Check for changes
            changes = self.CheckGitStatus()
            if not changes:
                if verbose:
                    print("‚ùå Error checking repository status")
                return False
            
            total_changes = len(changes['unstaged']) + len(changes['staged']) + len(changes['untracked'])
            
            if total_changes == 0:
                if verbose:
                    print("‚úÖ No changes detected. Repository is up to date.")
                return True
            
            if verbose:
                print(f"üìÅ Found {total_changes} changed/new files:")
                for file in changes['unstaged'] + changes['untracked']:
                    if file:  # Skip empty strings
                        print(f"   - {file}")
            
            # Add files
            if verbose:
                print("üì§ Adding files to staging area...")
            self.AddFiles(files)
            
            # Create commit
            if verbose:
                print("üíæ Creating commit...")
            commit_msg = self.CreateCommit(commit_message)
            
            # Push to GitHub
            if verbose:
                print("üöÄ Pushing to GitHub...")
            self.PushToGitHub()
            
            if verbose:
                print(f"‚úÖ Successfully updated GitHub!")
                print(f"   Commit: {commit_msg}")
                print(f"   Branch: {self.branch}")
                print("üåê GitHub Pages will update in 5-10 minutes")
            
            return True
            
        except Exception as e:
            if verbose:
                print(f"‚ùå Error during auto-update: {e}")
            return False
    
    def SetupWatchMode(self, watch_directory=None, interval=30):
        """
        Watch for file changes and auto-update
        
        Args:
            watch_directory: Directory to watch (repo root if None)
            interval: Check interval in seconds
        """
        watch_dir = Path(watch_directory) if watch_directory else self.repo_path
        
        print(f"üëÄ Watching {watch_dir} for changes...")
        print(f"‚è∞ Check interval: {interval} seconds")
        print("Press Ctrl+C to stop")
        
        last_check = {}
        
        try:
            while True:
                current_check = {}
                changes_detected = False
                
                # Check modification times of files
                for file_path in watch_dir.rglob('*'):
                    if file_path.is_file() and not str(file_path).startswith('.git'):
                        try:
                            mtime = file_path.stat().st_mtime
                            current_check[str(file_path)] = mtime
                            
                            if str(file_path) in last_check:
                                if last_check[str(file_path)] != mtime:
                                    changes_detected = True
                            else:
                                changes_detected = True
                        except:
                            continue
                
                if changes_detected and last_check:  # Skip first run
                    print(f"\nüîî Changes detected at {datetime.now().strftime('%H:%M:%S')}")
                    if self.AutoUpdate(verbose=True):
                        print("‚úÖ Auto-update completed successfully\n")
                    else:
                        print("‚ùå Auto-update failed\n")
                
                last_check = current_check
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nüëã Watch mode stopped")


def CreateConfigFile(repo_path="."):
    """Create a configuration file for the auto-updater"""
    config = {
        "repository": {
            "path": str(Path(repo_path).absolute()),
            "remote": "origin",
            "branch": "main"
        },
        "auto_update": {
            "default_message_prefix": "Auto-update",
            "include_timestamp": True,
            "watch_interval": 30
        },
        "excluded_files": [
            ".git/*",
            "*.log",
            "*.tmp",
            "__pycache__/*",
            "node_modules/*"
        ]
    }
    
    config_path = Path(repo_path) / "auto_update_config.json"
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=2)
    
    print(f"‚úÖ Configuration file created: {config_path}")
    return config_path


def main():
    """Main function for command line usage"""
    parser = argparse.ArgumentParser(description="GitHub Auto-Update Script")
    parser.add_argument("--path", default=".", help="Repository path (default: current directory)")
    parser.add_argument("--message", "-m", help="Commit message")
    parser.add_argument("--watch", "-w", action="store_true", help="Watch mode for continuous updates")
    parser.add_argument("--interval", "-i", type=int, default=30, help="Watch interval in seconds")
    parser.add_argument("--setup", action="store_true", help="Create configuration file")
    parser.add_argument("--quiet", "-q", action="store_true", help="Quiet mode (less output)")
    
    args = parser.parse_args()
    
    try:
        if args.setup:
            CreateConfigFile(args.path)
            return
        
        # Initialize updater
        updater = GitHubAutoUpdater(repo_path=args.path)
        
        if args.watch:
            # Watch mode
            updater.SetupWatchMode(interval=args.interval)
        else:
            # Single update
            success = updater.AutoUpdate(
                commit_message=args.message,
                verbose=not args.quiet
            )
            sys.exit(0 if success else 1)
            
    except KeyboardInterrupt:
        print("\nüëã Goodbye!")
        sys.exit(0)
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)


# Usage examples and helper functions
class LibraryUpdater:
    """Specialized updater for Anderson's Library files"""
    
    def __init__(self, repo_path="."):
        self.updater = GitHubAutoUpdater(repo_path)
    
    def UpdateLibraryDatabase(self, db_path):
        """Update when library database changes"""
        return self.updater.AutoUpdate(
            commit_message=f"Update library database: {Path(db_path).name}",
            files=[db_path]
        )
    
    def UpdateLibraryPages(self):
        """Update library-specific pages"""
        library_files = [
            "library/index.html",
            "library/app/index.html", 
            "library/auth/*.html",
            "library/js/*.js",
            "library/css/*.css"
        ]
        
        return self.updater.AutoUpdate(
            commit_message="Update Anderson's Library interface",
            files=library_files
        )
    
    def QuickUpdate(self, message="Quick library update"):
        """Quick update of all changes"""
        return self.updater.AutoUpdate(commit_message=message)


if __name__ == "__main__":
    main()

================
File: Scripts/System/GitHubUpdateSite.py
================
# Simple Auto-Update Script for BowersWorld.com
# Author: Herb Bowers - Project Himalaya  
# Created: 2025-06-22  17:30
# Path: /UpdateSite.py

import os
import subprocess
import sys
from datetime import datetime

def RunCommand(command, show_output=True):
    """Run a command and return result"""
    try:
        if show_output:
            print(f"üîÑ Running: {command}")
        
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        
        if result.returncode == 0:
            if show_output and result.stdout:
                print(result.stdout)
            return True
        else:
            print(f"‚ùå Error: {result.stderr}")
            return False
    except Exception as e:
        print(f"‚ùå Command failed: {e}")
        return False

def UpdateSite(message=None):
    """Simple function to update GitHub Pages site"""
    
    print("üöÄ BowersWorld.com Auto-Update Starting...")
    print("=" * 50)
    
    # Check if we're in a git repository
    if not os.path.exists('.git'):
        print("‚ùå Error: Not in a git repository")
        print("   Make sure you're in the BowersWorld-com directory")
        return False
    
    # Check for changes
    print("üìã Checking for changes...")
    result = subprocess.run("git status --porcelain", shell=True, capture_output=True, text=True)
    
    if not result.stdout.strip():
        print("‚úÖ No changes detected. Site is up to date!")
        return True
    
    print("üìÅ Changes found:")
    changes = result.stdout.strip().split('\n')
    for change in changes:
        print(f"   {change}")
    
    # Create automatic commit message if none provided
    if not message:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        message = f"Site update: {timestamp}"
    
    # Add all changes
    print("\nüì§ Adding changes...")
    if not RunCommand("git add ."):
        return False
    
    # Commit changes
    print("üíæ Creating commit...")
    commit_command = f'git commit -m "{message}"'
    if not RunCommand(commit_command):
        return False
    
    # Push to GitHub
    print("üöÄ Pushing to GitHub...")
    if not RunCommand("git push origin main"):
        return False
    
    print("\n" + "=" * 50)
    print("‚úÖ SUCCESS! Site updated successfully!")
    print("üåê GitHub Pages will update in 5-10 minutes")
    print("üîó View at: https://callmechewy.github.io/BowersWorld-com/")
    print("=" * 50)
    
    return True

def QuickUpdate():
    """Quick update with automatic message"""
    return UpdateSite()

def CustomUpdate():
    """Update with custom commit message"""
    print("üìù Enter a custom commit message:")
    message = input("Message: ").strip()
    
    if not message:
        print("Using automatic message...")
        return UpdateSite()
    
    return UpdateSite(message)

def main():
    """Main menu for the updater"""
    print("üìö BowersWorld.com Site Updater")
    print("=" * 40)
    print("1. Quick update (automatic message)")
    print("2. Custom update (enter your message)")
    print("3. Exit")
    print("=" * 40)
    
    while True:
        try:
            choice = input("Choose option (1-3): ").strip()
            
            if choice == "1":
                QuickUpdate()
                break
            elif choice == "2":
                CustomUpdate()
                break
            elif choice == "3":
                print("üëã Goodbye!")
                break
            else:
                print("‚ùå Invalid choice. Please enter 1, 2, or 3.")
        except KeyboardInterrupt:
            print("\nüëã Goodbye!")
            break
        except Exception as e:
            print(f"‚ùå Error: {e}")
            break

# Direct usage functions
def UpdateLibrary():
    """Update library-specific changes"""
    return UpdateSite("Update Anderson's Library")

def UpdateMainSite():
    """Update main site changes"""
    return UpdateSite("Update Project Himalaya site")

def UpdateDatabase():
    """Update when database changes"""
    return UpdateSite("Update library database")

if __name__ == "__main__":
    # Check for command line arguments
    if len(sys.argv) > 1:
        if sys.argv[1] == "--quick":
            QuickUpdate()
        elif sys.argv[1] == "--library":
            UpdateLibrary()
        elif sys.argv[1] == "--main":
            UpdateMainSite()
        elif sys.argv[1] == "--database":
            UpdateDatabase()
        elif sys.argv[1] == "--message" and len(sys.argv) > 2:
            UpdateSite(" ".join(sys.argv[2:]))
        else:
            print("Usage:")
            print("  python update_site.py               # Interactive menu")
            print("  python update_site.py --quick       # Quick update")
            print("  python update_site.py --library     # Library update")
            print("  python update_site.py --main        # Main site update")
            print("  python update_site.py --database    # Database update")
            print("  python update_site.py --message 'Your message'")
    else:
        # Run interactive menu
        main()

================
File: Scripts/System/ListFilesByDate.py
================



import os
import datetime

def list_files_and_dates():
    """
    Lists all files in the current directory and their last modification dates.
    """
    files_with_dates = []
    for item in os.listdir('.'):
        if os.path.isfile(item):
            try:
                timestamp = os.path.getmtime(item)
                files_with_dates.append((timestamp, item))
            except Exception as e:
                print(f"Warning: Could not retrieve date for {item} ({e})")

    files_with_dates.sort() # Sort by timestamp (oldest first)

    print("Files and their last modification dates in the current directory (oldest first):")
    for timestamp, item in files_with_dates:
        dt_object = datetime.datetime.fromtimestamp(timestamp)
        print(f"- {dt_object.strftime('%Y-%m-%d %H:%M:%S')}: {item}")

if __name__ == "__main__":
    list_files_and_dates()

================
File: Scripts/System/MarkdownToText.py
================
# File: MarkdownToText.py
# Path: MarkdownToText.py
# Standard: AIDEV-PascalCase-1.7
# Created: 2025-06-21
# Last Modified: 2025-06-21  09:30 AM
# Author: Claude Code Assistant
"""
Description: Himalaya Markdown to Text Converter Utility
Converts .md files to plain text format by stripping Markdown syntax while preserving
content structure and readability. Handles headers, lists, code blocks, links, and
other common Markdown elements. Follows AIDEV-PascalCase-1.7 standard with comprehensive
error handling, logging, and audit trail generation.

Core Features:
- PascalCase naming convention enforcement
- Comprehensive Markdown syntax removal
- Batch directory processing capabilities
- Detailed logging and status reporting
- Error handling with graceful degradation
"""

import os
import re
import sys
import logging
from datetime import datetime
from typing import Optional

# --- CONSTANTS ---
DOCS_DIR = 'Docs'
TEXT_OUTPUT_DIR = 'TextOutput'
DATE_FMT = "%Y-%m-%d"
TS_FMT = "%Y-%m-%d_%H-%M-%S"

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='[MarkdownToText] %(levelname)s: %(message)s'
)

def ProcessMarkdownToText(MarkdownContent: str) -> str:
    """
    Processes Markdown content and converts to clean plain text.
    Removes all Markdown syntax while preserving content structure and readability.
    Follows Himalaya text processing standards.
    
    Args:
        MarkdownContent: Raw markdown content as string
        
    Returns:
        Plain text with all Markdown syntax removed
    """
    ProcessedText = MarkdownContent
    
    # Remove code blocks (```code```)
    ProcessedText = re.sub(r'```[\s\S]*?```', '', ProcessedText)
    
    # Remove inline code (`code`)
    ProcessedText = re.sub(r'`([^`]+)`', r'\1', ProcessedText)
    
    # Convert headers (# ## ### etc.) to plain text with spacing
    ProcessedText = re.sub(r'^#{1,6}\s*(.+)$', r'\1', ProcessedText, flags=re.MULTILINE)
    
    # Remove bold/italic markers (**text**, *text*, __text__, _text_)
    ProcessedText = re.sub(r'\*\*([^*]+)\*\*', r'\1', ProcessedText)
    ProcessedText = re.sub(r'\*([^*]+)\*', r'\1', ProcessedText)
    ProcessedText = re.sub(r'__([^_]+)__', r'\1', ProcessedText)
    ProcessedText = re.sub(r'_([^_]+)_', r'\1', ProcessedText)
    
    # Convert links [text](url) to just text
    ProcessedText = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', ProcessedText)
    
    # Remove reference-style links [text]: url
    ProcessedText = re.sub(r'^\s*\[[^\]]+\]:\s*.+$', '', ProcessedText, flags=re.MULTILINE)
    
    # Convert unordered lists (- * +) to plain text with indentation
    ProcessedText = re.sub(r'^(\s*)[-*+]\s+(.+)$', r'\1\2', ProcessedText, flags=re.MULTILINE)
    
    # Convert ordered lists (1. 2. etc.) to plain text with indentation
    ProcessedText = re.sub(r'^(\s*)\d+\.\s+(.+)$', r'\1\2', ProcessedText, flags=re.MULTILINE)
    
    # Remove blockquotes (>)
    ProcessedText = re.sub(r'^>\s*(.*)$', r'\1', ProcessedText, flags=re.MULTILINE)
    
    # Remove horizontal rules (--- or ***)
    ProcessedText = re.sub(r'^[-*]{3,}$', '', ProcessedText, flags=re.MULTILINE)
    
    # Clean up extra whitespace while preserving paragraph breaks
    ProcessedText = re.sub(r'\n{3,}', '\n\n', ProcessedText)
    ProcessedText = re.sub(r'[ \t]+', ' ', ProcessedText)
    
    # Remove leading/trailing whitespace from lines
    CleanedLines = [Line.strip() for Line in ProcessedText.split('\n')]
    ProcessedText = '\n'.join(CleanedLines)
    
    return ProcessedText.strip()

def ConvertSingleMarkdownFile(SourcePath: str, DestinationPath: Optional[str] = None) -> bool:
    """
    Converts a single Markdown file to plain text with full error handling.
    Follows Himalaya file processing standards with comprehensive logging.
    
    Args:
        SourcePath: Path to source .md file
        DestinationPath: Optional output path, defaults to source path with .txt extension
        
    Returns:
        True if conversion successful, False otherwise
    """
    try:
        # Validate source file existence
        if not os.path.exists(SourcePath):
            logging.error(f"Source file not found: {SourcePath}")
            return False
            
        if not SourcePath.lower().endswith('.md'):
            logging.warning(f"Source file is not a Markdown file: {SourcePath}")
        
        # Determine destination path with PascalCase naming
        if DestinationPath is None:
            BaseFileName = os.path.splitext(os.path.basename(SourcePath))[0]
            DestinationPath = f"{BaseFileName}.txt"
        
        # Ensure destination directory exists
        DestinationDir = os.path.dirname(DestinationPath)
        if DestinationDir and not os.path.exists(DestinationDir):
            os.makedirs(DestinationDir, exist_ok=True)
            logging.info(f"Created destination directory: {DestinationDir}")
        
        # Read markdown content with encoding validation
        with open(SourcePath, 'r', encoding='utf-8') as SourceFile:
            MarkdownContent = SourceFile.read()
        
        # Process markdown to plain text
        ConvertedText = ProcessMarkdownToText(MarkdownContent)
        
        # Write output file with UTF-8 encoding
        with open(DestinationPath, 'w', encoding='utf-8') as DestinationFile:
            DestinationFile.write(ConvertedText)
        
        logging.info(f"Successfully converted: {SourcePath} ‚Üí {DestinationPath}")
        return True
        
    except Exception as ProcessingError:
        logging.error(f"Failed to convert {SourcePath}: {ProcessingError}")
        return False

def ProcessMarkdownDirectory(SourceDirectory: str, DestinationDirectory: Optional[str] = None) -> int:
    """
    Processes all .md files in a directory to .txt files with batch processing.
    Generates comprehensive status report and audit trail.
    
    Args:
        SourceDirectory: Path to directory containing .md files
        DestinationDirectory: Optional output directory, defaults to same as source
        
    Returns:
        Number of files successfully converted
    """
    if not os.path.isdir(SourceDirectory):
        logging.error(f"Source directory not found: {SourceDirectory}")
        return 0
    
    SuccessfulConversions = 0
    ProcessingErrors = 0
    MarkdownFileList = [FileName for FileName in os.listdir(SourceDirectory) if FileName.lower().endswith('.md')]
    
    if not MarkdownFileList:
        logging.warning(f"No .md files found in directory: {SourceDirectory}")
        return 0
    
    logging.info(f"Found {len(MarkdownFileList)} Markdown files to process")
    
    for FileName in MarkdownFileList:
        SourceFilePath = os.path.join(SourceDirectory, FileName)
        
        if DestinationDirectory:
            os.makedirs(DestinationDirectory, exist_ok=True)
            BaseFileName = os.path.splitext(FileName)[0]
            DestinationFilePath = os.path.join(DestinationDirectory, f"{BaseFileName}.txt")
        else:
            DestinationFilePath = None
        
        if ConvertSingleMarkdownFile(SourceFilePath, DestinationFilePath):
            SuccessfulConversions += 1
        else:
            ProcessingErrors += 1
    
    logging.info(f"Batch processing completed: {SuccessfulConversions} successful, {ProcessingErrors} errors")
    logging.info(f"Directory processing summary: {SourceDirectory} ‚Üí {DestinationDirectory or 'same directory'}")
    return SuccessfulConversions

def ExecuteMarkdownConversion():
    """
    Main execution function for command-line usage.
    Handles both single file and directory batch processing with comprehensive error handling.
    
    Usage: python MarkdownToText.py <source_file_or_directory> [destination_path]
    
    Examples:
        python MarkdownToText.py Document.md
        python MarkdownToText.py Document.md ConvertedDocument.txt
        python MarkdownToText.py ./MarkdownFiles/
        python MarkdownToText.py ./MarkdownFiles/ ./TextFiles/
    """
    if len(sys.argv) < 2:
        print("Usage: python MarkdownToText.py <source_file_or_directory> [destination_path]")
        print("Examples:")
        print("  python MarkdownToText.py Document.md")
        print("  python MarkdownToText.py Document.md ConvertedDocument.txt")
        print("  python MarkdownToText.py ./SourceDocs/")
        print("  python MarkdownToText.py ./SourceDocs/ ./ConvertedText/")
        print("\nHimalaya Markdown to Text Converter - AIDEV-PascalCase-1.7")
        sys.exit(1)
    
    SourcePath = sys.argv[1]
    DestinationPath = sys.argv[2] if len(sys.argv) > 2 else None
    
    print(f"[MarkdownToText] Himalaya conversion process starting...")
    ExecutionStartTime = datetime.now()
    
    if os.path.isfile(SourcePath):
        ConversionSuccess = ConvertSingleMarkdownFile(SourcePath, DestinationPath)
        if ConversionSuccess:
            print(f"[MarkdownToText] Single file conversion completed successfully")
        else:
            print(f"[MarkdownToText] Single file conversion failed - check logs for details")
            sys.exit(1)
    elif os.path.isdir(SourcePath):
        ProcessedFileCount = ProcessMarkdownDirectory(SourcePath, DestinationPath)
        print(f"[MarkdownToText] Directory batch processing completed: {ProcessedFileCount} files converted")
        if ProcessedFileCount == 0:
            print(f"[MarkdownToText] Warning: No files were successfully converted")
    else:
        print(f"[MarkdownToText] Error: Source path not found: {SourcePath}")
        sys.exit(1)
    
    ExecutionEndTime = datetime.now()
    TotalDuration = (ExecutionEndTime - ExecutionStartTime).total_seconds()
    print(f"[MarkdownToText] Total execution time: {TotalDuration:.2f} seconds")
    print(f"[MarkdownToText] Himalaya conversion process completed successfully")

if __name__ == "__main__":
    ExecuteMarkdownConversion()
================
File: Scripts/System/Project_Backup.py
================
#!/usr/bin/env python3
"""
Project backup script that respects .gitignore files
"""

import os
import shutil
import sys
from datetime import datetime
from pathlib import Path
import fnmatch


def parse_gitignore(gitignore_path):
    """Parse .gitignore file and return patterns to ignore"""
    patterns = []
    if os.path.exists(gitignore_path):
        with open(gitignore_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    patterns.append(line)
    return patterns


def should_ignore(file_path, ignore_patterns, base_path):
    """Check if a file/directory should be ignored based on gitignore patterns"""
    relative_path = os.path.relpath(file_path, base_path)
    
    for pattern in ignore_patterns:
        # Handle directory patterns ending with /
        if pattern.endswith('/'):
            if os.path.isdir(file_path):
                dir_pattern = pattern.rstrip('/')
                if fnmatch.fnmatch(relative_path, dir_pattern) or fnmatch.fnmatch(os.path.basename(file_path), dir_pattern):
                    return True
        else:
            # Handle file patterns
            if fnmatch.fnmatch(relative_path, pattern) or fnmatch.fnmatch(os.path.basename(file_path), pattern):
                return True
            # Check if any parent directory matches the pattern
            path_parts = relative_path.split(os.sep)
            for part in path_parts[:-1]:  # Exclude the file itself
                if fnmatch.fnmatch(part, pattern):
                    return True
    
    return False


def copy_with_gitignore(src, dst, ignore_patterns):
    """Copy directory tree while respecting gitignore patterns"""
    if not os.path.exists(dst):
        os.makedirs(dst)
    
    for item in os.listdir(src):
        src_path = os.path.join(src, item)
        dst_path = os.path.join(dst, item)
        
        if should_ignore(src_path, ignore_patterns, src):
            print(f"Ignoring: {src_path}")
            continue
        
        if os.path.isdir(src_path):
            copy_with_gitignore(src_path, dst_path, ignore_patterns)
        else:
            shutil.copy2(src_path, dst_path)


def backup_project(project_name=None):
    """Backup the current project, respecting .gitignore if present"""
    # Get project name
    if not project_name:
        project_name = os.path.basename(os.getcwd())
    
    # Setup backup directory
    backup_dir = os.path.join(os.path.expanduser("~"), "Desktop", "Projects_Backup")
    date_stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"{project_name}_{date_stamp}"
    backup_path = os.path.join(backup_dir, backup_name)
    
    # Create backup directory
    os.makedirs(backup_dir, exist_ok=True)
    
    # Get source directory (current directory)
    src_dir = os.getcwd()
    
    # Parse .gitignore if it exists
    gitignore_path = os.path.join(src_dir, '.gitignore')
    ignore_patterns = parse_gitignore(gitignore_path)
    
    # Always ignore .git directory
    ignore_patterns.append('.git/')
    
    print(f"Backing up project: {project_name}")
    if ignore_patterns:
        print(f"Using .gitignore patterns: {len(ignore_patterns)} patterns found")
    
    # Copy project with gitignore filtering
    try:
        copy_with_gitignore(src_dir, backup_path, ignore_patterns)
        print(f"Project backed up to: {backup_path}")
        return backup_path
    except Exception as e:
        print(f"Error during backup: {e}")
        return None


def main():
    """Main entry point"""
    project_name = None
    if len(sys.argv) > 1:
        project_name = sys.argv[1]
    
    backup_project(project_name)


if __name__ == "__main__":
    main()
================
File: Scripts/System/UpdateFiles.py
================
# File: CliveJob.py
# Path: ProjectHimalaya/UpdateFiles.py
# Standard: AIDEV-PascalCase-1.7
# Created: 2025-06-05
# Last Modified: 2025-06-26  17:45 PM
"""
Description: Clive's Job ‚Äì Himalaya-standard update/move/archive utility.
Processes Updates folder, reads header for intended path, enforces PascalCase for all
created directories and files (unless ecosystem exception), archives old copies,
generates audit/status report, with full error handling, logging, and audit trail.

Fixed: Now ignores base directory from header paths and uses relative paths from current directory.
Fixed: Regex now handles both comment-style (# Path:) and docstring-style (Path:) headers.
Fixed: Better handling of absolute paths with leading slashes.
"""

import os
import re
import shutil
import logging
from datetime import datetime

# --- CONSTANTS ---
UPDATES_DIR = 'Updates'
ARCHIVE_DIR = 'Archive'
DOCS_BASE = 'Docs'
DOCS_UPDATES = os.path.join(DOCS_BASE, 'Updates')
DATE_FMT = "%Y-%m-%d"
TS_FMT = "%Y-%m-%d_%H-%M-%S"

logging.basicConfig(
    level=logging.INFO,
    format='[CliveJob] %(levelname)s: %(message)s'
)

def ToPascalCase(Segment: str) -> str:
    """
    Converts any file or directory segment to Himalaya PascalCase.
    Preserves extension (lowercase), applies PascalCase to base.
    Preserves already-good PascalCase filenames.
    """
    # Ecosystem exceptions
    if Segment in ('__init__.py', 'setup.py'):
        return Segment

    # Handle file extension (only split at LAST dot)
    if '.' in Segment and not Segment.startswith('.'):
        Base, Ext = Segment.rsplit('.', 1)
        Ext = Ext.lower()
    else:
        Base, Ext = Segment, ''

    # Check if Base is already in good PascalCase format
    if IsAlreadyPascalCase(Base):
        logging.info(f"Preserving already-good PascalCase: '{Base}'")
        return f"{Base}.{Ext}" if Ext else Base

    # Remove all non-alphanumeric separators, PascalCase the rest
    Words = re.split(r'[\s_\-]+', Base)
    Pascal = ''.join(Word.capitalize() for Word in Words if Word)

    return f"{Pascal}.{Ext}" if Ext else Pascal

def IsAlreadyPascalCase(Text: str) -> bool:
    """
    Check if text is already in acceptable PascalCase format.
    Returns True if the text should be preserved as-is.
    """
    # Must start with uppercase letter
    if not Text or not Text[0].isupper():
        return False
    
    # Must be all alphanumeric
    if not Text.isalnum():
        return False
    
    # Check for reasonable PascalCase pattern:
    # - Starts with uppercase
    # - Has at least one more uppercase letter (indicating word boundaries)
    # - No consecutive uppercase letters (avoid ALL_CAPS)
    uppercase_count = sum(1 for c in Text if c.isupper())
    
    # If it's all one word (like "Script"), allow it
    if len(Text) <= 8 and uppercase_count == 1:
        return True
    
    # For longer names, require multiple uppercase letters (PascalCase pattern)
    # but not too many (avoid ALLCAPS)
    if uppercase_count >= 2 and uppercase_count <= len(Text) // 2:
        # Check for consecutive uppercase (avoid "XMLHTTPRequest" style)
        consecutive_upper = any(Text[i].isupper() and Text[i+1].isupper() 
                               for i in range(len(Text)-1))
        if not consecutive_upper:
            return True
    
    return False

def PascalCasePath(Path: str) -> str:
    """
    Applies ToPascalCase to every segment of a path (directories and filename).
    """
    Path = Path.replace('\\', '/')
    Segments = Path.split('/')
    PascalSegments = [ToPascalCase(Segment) for Segment in Segments if Segment]
    return '/'.join(PascalSegments)

def ReadHeaderTargetPath(FilePath: str) -> str:
    """
    Extracts intended path from file header ('Path: ...'), removes base directory,
    and PascalCases the remaining relative path.
    
    Example: 'Path: ProjectHimalaya/CliveJob.py' becomes './CliveJob.py'
    Example: 'Path: /BowersWorld-com/SetupSearchSystem_v2.py' becomes './SetupSearchSystem_v2.py'
    """
    try:
        with open(FilePath, 'r', encoding='utf-8') as File:
            for _ in range(15):  # Check first 15 lines for header (docstrings can be longer)
                Line = File.readline()
                if not Line:  # End of file
                    break
                    
                # Match both comment-style and docstring-style paths
                # Handles: # Path: ... OR Path: ... (without #)
                Match = re.match(r'(?:#\s*)?Path:\s*(.+)', Line.strip())
                if Match:
                    FullPath = Match.group(1).strip()
                    logging.info(f"Found header path: '{FullPath}' in {FilePath}")
                    
                    # Remove base directory and use relative path
                    RelativePath = StripBaseDirectory(FullPath)
                    
                    if RelativePath:
                        FinalPath = PascalCasePath(RelativePath)
                        logging.info(f"Processed path: '{FullPath}' -> '{RelativePath}' -> '{FinalPath}'")
                        return FinalPath
                    else:
                        logging.warning(f"Empty path after stripping base directory from: {FullPath}")
                        return None
    except Exception as Error:
        logging.warning(f"Error reading header from {FilePath}: {Error}")
    return None

def StripBaseDirectory(Path: str) -> str:
    """
    Removes the base directory from a path, returning the relative path.
    Handles both relative and absolute paths.
    
    Examples:
    - 'ProjectHimalaya/CliveJob.py' -> 'CliveJob.py'
    - '/BowersWorld-com/SetupSearchSystem_v2.py' -> 'SetupSearchSystem_v2.py' 
    - 'SomeProject/Scripts/AutoUpdate.py' -> 'Scripts/AutoUpdate.py'
    - 'SingleFile.py' -> 'SingleFile.py'
    """
    # Normalize path separators and remove leading/trailing slashes
    Path = Path.replace('\\', '/').strip('/')
    
    # Split into segments
    Segments = [Segment for Segment in Path.split('/') if Segment]
    
    if len(Segments) <= 1:
        # If only one segment (filename only), return as-is
        return Path
    else:
        # Remove first segment (base directory) and rejoin
        RelativeSegments = Segments[1:]
        RelativePath = '/'.join(RelativeSegments)
        logging.info(f"Stripped base directory: '{Path}' -> '{RelativePath}'")
        return RelativePath

def ArchiveExisting(TargetPath: str) -> str:
    """
    If file exists, moves it to Archive dir (PascalCase), adds timestamp.
    """
    if os.path.exists(TargetPath):
        ArchiveDir = os.path.join(ARCHIVE_DIR, os.path.dirname(TargetPath))
        os.makedirs(ArchiveDir, exist_ok=True)
        BaseName = os.path.basename(TargetPath)
        TimeStamp = datetime.now().strftime(TS_FMT)
        if '.' in BaseName and not BaseName.startswith('.'):
            Base, Ext = BaseName.rsplit('.', 1)
            Ext = Ext.lower()
        else:
            Base, Ext = BaseName, ''
        ArchiveName = f"{ToPascalCase(Base)}_{TimeStamp}{'.' + Ext if Ext else ''}"
        ArchivePath = os.path.join(ArchiveDir, ArchiveName)
        shutil.move(TargetPath, ArchivePath)
        logging.info(f"Archived old file: {TargetPath} ‚Üí {ArchivePath}")
        return ArchivePath
    return None

def MoveOrCopyFile(SourcePath: str, DestPath: str) -> None:
    """
    Moves file, archiving old if needed, ensuring PascalCase on all dirs/files.
    """
    # Ensure destination directory exists
    DestDir = os.path.dirname(DestPath)
    if DestDir:  # Only create if there's a directory component
        os.makedirs(DestDir, exist_ok=True)
    
    # Archive existing file if it exists
    ArchiveExisting(DestPath)
    
    # Move the file
    shutil.move(SourcePath, DestPath)
    logging.info(f"Moved: {SourcePath} ‚Üí {DestPath}")

def ProcessUpdates() -> None:
    """
    Processes all files in Updates folder with full Himalaya + PascalCase enforcement.
    Now correctly handles relative paths by stripping base directories from headers.
    """
    Today = datetime.now().strftime(DATE_FMT)
    StatusEntries = []
    os.makedirs(DOCS_UPDATES, exist_ok=True)

    # Check if Updates directory exists
    if not os.path.exists(UPDATES_DIR):
        logging.warning(f"Updates directory '{UPDATES_DIR}' does not exist!")
        return

    for FileName in os.listdir(UPDATES_DIR):
        SourcePath = os.path.join(UPDATES_DIR, FileName)
        if not os.path.isfile(SourcePath):
            continue
            
        HeaderPath = ReadHeaderTargetPath(SourcePath)
        FileExt = os.path.splitext(FileName)[1].lower()
        Status = {'File': FileName, 'Result': '', 'Detail': ''}
        
        try:
            # .md/.txt: move to Docs/YYYY-MM-DD/ (original name for doc provenance)
            if FileExt in ['.md', '.txt']:
                DocsDayDir = os.path.join(DOCS_BASE, Today)
                DestPath = os.path.join(DocsDayDir, FileName)
                MoveOrCopyFile(SourcePath, DestPath)
                Status['Result'] = 'Moved to Docs (dated, original filename)'
                Status['Detail'] = DestPath
                
            elif HeaderPath:
                # Use the relative path (base directory already stripped)
                DestPath = HeaderPath
                MoveOrCopyFile(SourcePath, DestPath)
                Status['Result'] = 'Moved by header path (base directory stripped, PascalCase applied)'
                Status['Detail'] = DestPath
                
            else:
                Status['Result'] = 'Skipped (no header path, not doc)'
                Status['Detail'] = f"Kept in: {SourcePath}"
                logging.warning(f"Skipped: {FileName} (no header path and not .md/.txt)")
                
        except Exception as Error:
            Status['Result'] = 'Error'
            Status['Detail'] = str(Error)
            logging.error(f"Failed processing {FileName}: {Error}")
            
        StatusEntries.append(Status)

    # Write status report
    ReportTimeStamp = datetime.now().strftime(TS_FMT)
    ReportPath = os.path.join(DOCS_UPDATES, f'Updates_{ReportTimeStamp}.md')
    
    with open(ReportPath, 'w', encoding='utf-8') as Report:
        Report.write(f"# Updates Status Report ‚Äî {ReportTimeStamp}\n\n")
        Report.write(f"**Total files processed:** {len(StatusEntries)}\n\n")
        
        # Summary counts
        Moved = sum(1 for entry in StatusEntries if 'Moved' in entry['Result'])
        Skipped = sum(1 for entry in StatusEntries if 'Skipped' in entry['Result'])
        Errors = sum(1 for entry in StatusEntries if 'Error' in entry['Result'])
        
        Report.write(f"**Summary:**\n")
        Report.write(f"- ‚úÖ Moved: {Moved}\n")
        Report.write(f"- ‚è≠Ô∏è Skipped: {Skipped}\n")
        Report.write(f"- ‚ùå Errors: {Errors}\n\n")
        Report.write(f"**Details:**\n\n")
        
        for Entry in StatusEntries:
            # Add emoji based on result
            if 'Moved' in Entry['Result']:
                Emoji = '‚úÖ'
            elif 'Skipped' in Entry['Result']:
                Emoji = '‚è≠Ô∏è'
            elif 'Error' in Entry['Result']:
                Emoji = '‚ùå'
            else:
                Emoji = '‚ùì'
                
            Report.write(f"- {Emoji} **{Entry['File']}**: {Entry['Result']}  \n")
            Report.write(f"    `{Entry['Detail']}`\n\n")
            
    print(f"\n[CliveJob] Status report written: {ReportPath}")
    print(f"[CliveJob] Summary - Moved: {Moved}, Skipped: {Skipped}, Errors: {Errors}")

if __name__ == "__main__":
    print("[CliveJob] Himalaya file processor starting...")
    print("[CliveJob] Fixed version - now strips base directories from header paths")
    ProcessUpdates()
    print("[CliveJob] All done. Review status report for details.")

================
File: Updates/..Old/firebase_auth_system (1).html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Firebase Auth - Anderson's Library</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .auth-container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 15px;
            max-width: 450px;
            width: 90%;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header {
            text-align: center;
            margin-bottom: 2rem;
        }

        .header h1 {
            color: #ffd93d;
            margin-bottom: 0.5rem;
            font-size: 2rem;
        }

        .header p {
            opacity: 0.9;
            font-size: 0.9rem;
        }

        .auth-tabs {
            display: flex;
            margin-bottom: 2rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 0.25rem;
        }

        .tab-button {
            flex: 1;
            padding: 0.75rem;
            background: none;
            border: none;
            color: white;
            cursor: pointer;
            border-radius: 7px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .tab-button.active {
            background: rgba(255, 217, 61, 0.2);
            color: #ffd93d;
        }

        .auth-form {
            display: none;
        }

        .auth-form.active {
            display: block;
        }

        .form-group {
            margin-bottom: 1.5rem;
        }

        .form-group label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 500;
            color: #ffd93d;
        }

        .form-group input, .form-group select, .form-group textarea {
            width: 100%;
            padding: 0.75rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 1rem;
        }

        .form-group input::placeholder {
            color: rgba(255, 255, 255, 0.7);
        }

        .form-row {
            display: flex;
            gap: 1rem;
        }

        .form-row .form-group {
            flex: 1;
        }

        .submit-btn {
            width: 100%;
            padding: 1rem;
            background: linear-gradient(45deg, #ffd93d, #ff6b6b);
            color: #1e3c72;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 1rem;
        }

        .submit-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(255, 217, 61, 0.4);
        }

        .submit-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .google-btn {
            width: 100%;
            padding: 1rem;
            background: white;
            color: #333;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .google-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .divider {
            text-align: center;
            margin: 1.5rem 0;
            position: relative;
        }

        .divider::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 0;
            right: 0;
            height: 1px;
            background: rgba(255, 255, 255, 0.3);
        }

        .divider span {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            padding: 0 1rem;
            color: rgba(255, 255, 255, 0.7);
            font-size: 0.9rem;
        }

        .checkbox-group {
            display: flex;
            align-items: flex-start;
            gap: 0.5rem;
            margin-bottom: 1.5rem;
        }

        .checkbox-group input[type="checkbox"] {
            width: auto;
            margin-top: 0.2rem;
        }

        .checkbox-group label {
            margin-bottom: 0;
            font-size: 0.9rem;
            line-height: 1.4;
        }

        .message {
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1rem;
            font-weight: 500;
            text-align: center;
        }

        .message.success {
            background: rgba(46, 213, 115, 0.2);
            border: 1px solid rgba(46, 213, 115, 0.5);
            color: #2ed573;
        }

        .message.error {
            background: rgba(255, 107, 107, 0.2);
            border: 1px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 2rem;
        }

        .spinner {
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 3px solid #ffd93d;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 1rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .footer {
            text-align: center;
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.2);
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .status {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 217, 61, 0.9);
            color: #1e3c72;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
        }

        @media (max-width: 480px) {
            .auth-container {
                margin: 1rem;
                padding: 1.5rem;
            }

            .form-row {
                flex-direction: column;
                gap: 0;
            }

            .header h1 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="status">üî• Firebase Ready</div>

    <div class="auth-container">
        <div class="header">
            <h1>üìö Anderson's Library</h1>
            <p>Secure access to thousands of digital resources</p>
        </div>

        <div class="auth-tabs">
            <button class="tab-button active" onclick="switchTab('login')">Sign In</button>
            <button class="tab-button" onclick="switchTab('register')">Register</button>
        </div>

        <div id="messageContainer"></div>

        <!-- Login Form -->
        <form id="loginForm" class="auth-form active">
            <div class="form-group">
                <label for="loginEmail">Email Address</label>
                <input type="email" id="loginEmail" placeholder="Enter your email" required>
            </div>
            <div class="form-group">
                <label for="loginPassword">Password</label>
                <input type="password" id="loginPassword" placeholder="Enter your password" required>
            </div>
            <button type="submit" class="submit-btn">Sign In to Library</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Continue with Google
            </button>
            
            <div style="text-align: center; margin-top: 1rem;">
                <a href="#" onclick="resetPassword()" style="color: #ffd93d; text-decoration: none; font-size: 0.9rem;">Forgot your password?</a>
            </div>
        </form>

        <!-- Registration Form -->
        <form id="registerForm" class="auth-form">
            <div class="form-row">
                <div class="form-group">
                    <label for="firstName">First Name</label>
                    <input type="text" id="firstName" placeholder="First name" required>
                </div>
                <div class="form-group">
                    <label for="lastName">Last Name</label>
                    <input type="text" id="lastName" placeholder="Last name" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="registerEmail">Email Address</label>
                <input type="email" id="registerEmail" placeholder="your.email@example.com" required>
            </div>
            
            <div class="form-row">
                <div class="form-group">
                    <label for="registerPassword">Password</label>
                    <input type="password" id="registerPassword" placeholder="Min 8 characters" required>
                </div>
                <div class="form-group">
                    <label for="confirmPassword">Confirm Password</label>
                    <input type="password" id="confirmPassword" placeholder="Confirm password" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="organization">Organization (Optional)</label>
                <input type="text" id="organization" placeholder="University, Company, etc.">
            </div>
            
            <div class="form-group">
                <label for="accessReason">Reason for Access</label>
                <select id="accessReason" required>
                    <option value="">Select your primary purpose</option>
                    <option value="Academic Research">Academic Research</option>
                    <option value="Professional Development">Professional Development</option>
                    <option value="Personal Learning">Personal Learning</option>
                    <option value="Teaching">Teaching</option>
                    <option value="Writing/Publishing">Writing/Publishing</option>
                    <option value="Other">Other</option>
                </select>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="agreeTerms" required>
                <label for="agreeTerms">I agree to the <a href="#" onclick="showTerms()" style="color: #ffd93d;">Terms of Service</a> and <a href="#" onclick="showPrivacy()" style="color: #ffd93d;">Privacy Policy</a></label>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="emailUpdates">
                <label for="emailUpdates">I'd like to receive email updates about new additions to the library</label>
            </div>
            
            <button type="submit" class="submit-btn">Create Account</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Sign up with Google
            </button>
        </form>

        <!-- Loading State -->
        <div id="loadingIndicator" class="loading">
            <div class="spinner"></div>
            <p>Connecting to Anderson's Library...</p>
        </div>

        <div class="footer">
            <p>¬© 2025 Project Himalaya | Powered by BowersWorld.com</p>
        </div>
    </div>

    <!-- Firebase SDK -->
    <script type="module">
        // Import Firebase modules
        import { initializeApp } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-app.js';
        import { 
            getAuth, 
            signInWithEmailAndPassword, 
            createUserWithEmailAndPassword,
            signInWithPopup,
            GoogleAuthProvider,
            sendEmailVerification,
            sendPasswordResetEmail,
            onAuthStateChanged
        } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js';

        // Firebase configuration - REPLACE WITH YOUR ACTUAL CONFIG
        // Get this from Firebase Console ‚Üí Project Settings ‚Üí General ‚Üí Your apps
        const firebaseConfig = {
            apiKey: "AIzaSyC-REPLACE-WITH-YOUR-ACTUAL-API-KEY",
            authDomain: "anderson-library-XXXXX.firebaseapp.com",
            projectId: "anderson-library-XXXXX",
            storageBucket: "anderson-library-XXXXX.appspot.com",
            messagingSenderId: "123456789012",
            appId: "1:123456789012:web:abcdef123456789"
        };

        // Validate configuration
        if (firebaseConfig.apiKey.includes('REPLACE') || firebaseConfig.apiKey === 'your-api-key-here') {
            console.error('‚ùå Firebase configuration not updated! Please replace with your actual config.');
            showMessage('Configuration Error: Please update Firebase credentials', 'error');
        }

        // Initialize Firebase
        const app = initializeApp(firebaseConfig);
        const auth = getAuth(app);
        const provider = new GoogleAuthProvider();

        // Make auth available globally
        window.firebaseAuth = auth;
        window.googleProvider = provider;

        // Auth state observer
        onAuthStateChanged(auth, (user) => {
            if (user) {
                console.log('User signed in:', user.email);
                // Redirect to library or dashboard
                redirectToLibrary(user);
            } else {
                console.log('User signed out');
            }
        });

        console.log('üî• Firebase initialized successfully');
    </script>

    <script>
        // Global functions for form handling
        function switchTab(tab) {
            // Update tab buttons
            document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            
            // Update forms
            document.querySelectorAll('.auth-form').forEach(form => form.classList.remove('active'));
            document.getElementById(tab + 'Form').classList.add('active');
            
            // Clear messages
            clearMessages();
        }

        function showMessage(message, type = 'info') {
            const container = document.getElementById('messageContainer');
            container.innerHTML = `<div class="message ${type}">${message}</div>`;
            
            // Auto-hide after 5 seconds
            setTimeout(() => {
                container.innerHTML = '';
            }, 5000);
        }

        function clearMessages() {
            document.getElementById('messageContainer').innerHTML = '';
        }

        function showLoading(show) {
            const loading = document.getElementById('loadingIndicator');
            const forms = document.querySelectorAll('.auth-form');
            
            if (show) {
                loading.style.display = 'block';
                forms.forEach(form => form.style.display = 'none');
            } else {
                loading.style.display = 'none';
                forms.forEach(form => form.style.display = 'block');
            }
        }

        // Enhanced error handling for form validation
        function isValidPassword(password) {
            if (!password || password.length < 8) return false;
            return /[A-Z]/.test(password) && 
                   /[a-z]/.test(password) && 
                   /[0-9]/.test(password);
        }

        // Safe form data extraction
        function getFormData(form) {
            const formData = new FormData(form);
            const data = {};
            
            for (let [key, value] of formData.entries()) {
                data[key] = value || '';
            }
            
            return data;
        }

        // Sign in with Google
        async function signInWithGoogle() {
            showLoading(true);
            
            try {
                const { signInWithPopup } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const result = await signInWithPopup(window.firebaseAuth, window.googleProvider);
                
                showMessage('Successfully signed in with Google!', 'success');
                
                // Save user to database
                await saveUserToDatabase({
                    userID: result.user.uid,
                    email: result.user.email,
                    fullName: result.user.displayName,
                    provider: 'google',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
            } catch (error) {
                console.error('Google sign-in error:', error);
                showMessage('Google sign-in failed: ' + error.message, 'error');
            } finally {
                showLoading(false);
            }
        }

        // Password reset
        async function resetPassword() {
            const email = prompt('Enter your email address for password reset:');
            if (!email) return;
            
            try {
                const { sendPasswordResetEmail } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                await sendPasswordResetEmail(window.firebaseAuth, email);
                showMessage('Password reset email sent! Check your inbox.', 'success');
            } catch (error) {
                showMessage('Error sending reset email: ' + error.message, 'error');
            }
        }

        // Save user to Google Sheets (you'll need to implement this)
        async function saveUserToDatabase(userData) {
            // This will connect to your Google Sheets API
            console.log('Saving user to database:', userData);
            
            // Implement Google Sheets API call here
            // For now, just log the data
        }

        // Redirect to library
        function redirectToLibrary(user) {
            // Check user status and redirect appropriately
            console.log('Redirecting user to library:', user.email);
            
            // For now, just show a success message
            showMessage(`Welcome ${user.displayName || user.email}! Redirecting to library...`, 'success');
            
            // Actual redirect would be:
            // window.location.href = '/library/app/library.html';
        }

        // Terms and Privacy
        function showTerms() {
            alert('Terms of Service\n\nBy using Anderson\'s Library, you agree to:\n\n‚Ä¢ Use the library for educational and research purposes only\n‚Ä¢ Not share your account credentials\n‚Ä¢ Respect copyright and licensing terms\n‚Ä¢ Report any technical issues or concerns\n\nFull terms available at: bowersworld.com/terms');
        }

        function showPrivacy() {
            alert('Privacy Policy\n\nWe protect your privacy by:\n\n‚Ä¢ Using Firebase for secure authentication\n‚Ä¢ Storing minimal personal data\n‚Ä¢ Not sharing information with third parties\n‚Ä¢ Allowing account deletion at any time\n\nFull privacy policy at: bowersworld.com/privacy');
        }

        // Form submissions
        document.getElementById('loginForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            const email = document.getElementById('loginEmail').value;
            const password = document.getElementById('loginPassword').value;
            
            try {
                const { signInWithEmailAndPassword } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const userCredential = await signInWithEmailAndPassword(window.firebaseAuth, email, password);
                
                showMessage('Successfully signed in!', 'success');
                
            } catch (error) {
                console.error('Login error:', error);
                let errorMessage = 'Login failed. Please check your credentials.';
                
                if (error.code === 'auth/user-not-found') {
                    errorMessage = 'No account found with this email address.';
                } else if (error.code === 'auth/wrong-password') {
                    errorMessage = 'Incorrect password.';
                } else if (error.code === 'auth/invalid-email') {
                    errorMessage = 'Invalid email address.';
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        document.getElementById('registerForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            try {
                const userData = getFormData(e.target);
                
                // Enhanced validation
                if (!userData.registerEmail || !userData.registerPassword) {
                    throw new Error('Email and password are required');
                }
                
                if (userData.registerPassword !== userData.confirmPassword) {
                    throw new Error('Passwords do not match');
                }
                
                if (!isValidPassword(userData.registerPassword)) {
                    throw new Error('Password must be at least 8 characters with uppercase, lowercase, and numbers');
                }
                
                if (!userData.agreeTerms) {
                    throw new Error('You must agree to the terms of service');
                }
                
                const { createUserWithEmailAndPassword, sendEmailVerification } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                
                const userCredential = await createUserWithEmailAndPassword(
                    window.firebaseAuth, 
                    userData.registerEmail, 
                    userData.registerPassword
                );
                
                // Send email verification
                await sendEmailVerification(userCredential.user);
                
                // Save to database (implement this function)
                await saveUserToDatabase({
                    userID: userCredential.user.uid,
                    email: userData.registerEmail,
                    fullName: `${userData.firstName || ''} ${userData.lastName || ''}`.trim(),
                    firstName: userData.firstName || '',
                    lastName: userData.lastName || '',
                    organization: userData.organization || '',
                    accessReason: userData.accessReason || '',
                    emailUpdates: userData.emailUpdates === 'on',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
                showMessage('Account created successfully! Please check your email for verification.', 'success');
                e.target.reset();
                
            } catch (error) {
                console.error('Registration error:', error);
                let errorMessage = 'Registration failed: ' + error.message;
                
                // Handle specific Firebase errors
                switch (error.code) {
                    case 'auth/email-already-in-use':
                        errorMessage = 'An account with this email already exists.';
                        break;
                    case 'auth/weak-password':
                        errorMessage = 'Password is too weak.';
                        break;
                    case 'auth/invalid-email':
                        errorMessage = 'Invalid email address.';
                        break;
                    case 'auth/network-request-failed':
                        errorMessage = 'Network error. Please check your connection.';
                        break;
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üöÄ Authentication system ready');
            
            // Check if user is already signed in
            if (window.firebaseAuth && window.firebaseAuth.currentUser) {
                redirectToLibrary(window.firebaseAuth.currentUser);
            }
        });
    </script>
</body>
</html>
================
File: Updates/..Old/firebase_auth_system (2).html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Firebase Auth - Anderson's Library</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .auth-container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 15px;
            max-width: 450px;
            width: 90%;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header {
            text-align: center;
            margin-bottom: 2rem;
        }

        .header h1 {
            color: #ffd93d;
            margin-bottom: 0.5rem;
            font-size: 2rem;
        }

        .header p {
            opacity: 0.9;
            font-size: 0.9rem;
        }

        .auth-tabs {
            display: flex;
            margin-bottom: 2rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 0.25rem;
        }

        .tab-button {
            flex: 1;
            padding: 0.75rem;
            background: none;
            border: none;
            color: white;
            cursor: pointer;
            border-radius: 7px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .tab-button.active {
            background: rgba(255, 217, 61, 0.2);
            color: #ffd93d;
        }

        .auth-form {
            display: none;
        }

        .auth-form.active {
            display: block;
        }

        .form-group {
            margin-bottom: 1.5rem;
        }

        .form-group label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 500;
            color: #ffd93d;
        }

        .form-group input, .form-group select, .form-group textarea {
            width: 100%;
            padding: 0.75rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 1rem;
        }

        .form-group input::placeholder {
            color: rgba(255, 255, 255, 0.7);
        }

        .form-row {
            display: flex;
            gap: 1rem;
        }

        .form-row .form-group {
            flex: 1;
        }

        .submit-btn {
            width: 100%;
            padding: 1rem;
            background: linear-gradient(45deg, #ffd93d, #ff6b6b);
            color: #1e3c72;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 1rem;
        }

        .submit-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(255, 217, 61, 0.4);
        }

        .submit-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .google-btn {
            width: 100%;
            padding: 1rem;
            background: white;
            color: #333;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .google-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .divider {
            text-align: center;
            margin: 1.5rem 0;
            position: relative;
        }

        .divider::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 0;
            right: 0;
            height: 1px;
            background: rgba(255, 255, 255, 0.3);
        }

        .divider span {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            padding: 0 1rem;
            color: rgba(255, 255, 255, 0.7);
            font-size: 0.9rem;
        }

        .checkbox-group {
            display: flex;
            align-items: flex-start;
            gap: 0.5rem;
            margin-bottom: 1.5rem;
        }

        .checkbox-group input[type="checkbox"] {
            width: auto;
            margin-top: 0.2rem;
        }

        .checkbox-group label {
            margin-bottom: 0;
            font-size: 0.9rem;
            line-height: 1.4;
        }

        .message {
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1rem;
            font-weight: 500;
            text-align: center;
        }

        .message.success {
            background: rgba(46, 213, 115, 0.2);
            border: 1px solid rgba(46, 213, 115, 0.5);
            color: #2ed573;
        }

        .message.error {
            background: rgba(255, 107, 107, 0.2);
            border: 1px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 2rem;
        }

        .spinner {
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 3px solid #ffd93d;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 1rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .footer {
            text-align: center;
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.2);
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .status {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 217, 61, 0.9);
            color: #1e3c72;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
        }

        @media (max-width: 480px) {
            .auth-container {
                margin: 1rem;
                padding: 1.5rem;
            }

            .form-row {
                flex-direction: column;
                gap: 0;
            }

            .header h1 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="status">üî• Firebase Ready</div>

    <div class="auth-container">
        <div class="header">
            <h1>üìö Anderson's Library</h1>
            <p>Secure access to thousands of digital resources</p>
        </div>

        <div class="auth-tabs">
            <button class="tab-button active" onclick="switchTab('login')">Sign In</button>
            <button class="tab-button" onclick="switchTab('register')">Register</button>
        </div>

        <div id="messageContainer"></div>

        <!-- Login Form -->
        <form id="loginForm" class="auth-form active">
            <div class="form-group">
                <label for="loginEmail">Email Address</label>
                <input type="email" id="loginEmail" placeholder="Enter your email" required>
            </div>
            <div class="form-group">
                <label for="loginPassword">Password</label>
                <input type="password" id="loginPassword" placeholder="Enter your password" required>
            </div>
            <button type="submit" class="submit-btn">Sign In to Library</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Continue with Google
            </button>
            
            <div style="text-align: center; margin-top: 1rem;">
                <a href="#" onclick="resetPassword()" style="color: #ffd93d; text-decoration: none; font-size: 0.9rem;">Forgot your password?</a>
            </div>
        </form>

        <!-- Registration Form -->
        <form id="registerForm" class="auth-form">
            <div class="form-row">
                <div class="form-group">
                    <label for="firstName">First Name</label>
                    <input type="text" id="firstName" placeholder="First name" required>
                </div>
                <div class="form-group">
                    <label for="lastName">Last Name</label>
                    <input type="text" id="lastName" placeholder="Last name" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="registerEmail">Email Address</label>
                <input type="email" id="registerEmail" placeholder="your.email@example.com" required>
            </div>
            
            <div class="form-row">
                <div class="form-group">
                    <label for="registerPassword">Password</label>
                    <input type="password" id="registerPassword" placeholder="Min 8 characters" required>
                </div>
                <div class="form-group">
                    <label for="confirmPassword">Confirm Password</label>
                    <input type="password" id="confirmPassword" placeholder="Confirm password" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="organization">Organization (Optional)</label>
                <input type="text" id="organization" placeholder="University, Company, etc.">
            </div>
            
            <div class="form-group">
                <label for="accessReason">Reason for Access</label>
                <select id="accessReason" required>
                    <option value="">Select your primary purpose</option>
                    <option value="Academic Research">Academic Research</option>
                    <option value="Professional Development">Professional Development</option>
                    <option value="Personal Learning">Personal Learning</option>
                    <option value="Teaching">Teaching</option>
                    <option value="Writing/Publishing">Writing/Publishing</option>
                    <option value="Other">Other</option>
                </select>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="agreeTerms" required>
                <label for="agreeTerms">I agree to the <a href="#" onclick="showTerms()" style="color: #ffd93d;">Terms of Service</a> and <a href="#" onclick="showPrivacy()" style="color: #ffd93d;">Privacy Policy</a></label>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="emailUpdates">
                <label for="emailUpdates">I'd like to receive email updates about new additions to the library</label>
            </div>
            
            <button type="submit" class="submit-btn">Create Account</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Sign up with Google
            </button>
        </form>

        <!-- Loading State -->
        <div id="loadingIndicator" class="loading">
            <div class="spinner"></div>
            <p>Connecting to Anderson's Library...</p>
        </div>

        <div class="footer">
            <p>¬© 2025 Project Himalaya | Powered by BowersWorld.com</p>
        </div>
    </div>

    <!-- Firebase SDK -->
    <script type="module">
        // Import Firebase modules
        import { initializeApp } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-app.js';
        import { 
            getAuth, 
            signInWithEmailAndPassword, 
            createUserWithEmailAndPassword,
            signInWithPopup,
            GoogleAuthProvider,
            sendEmailVerification,
            sendPasswordResetEmail,
            onAuthStateChanged
        } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js';

        // Firebase configuration - BowersWorld Digital Alexandria
        const firebaseConfig = {
            apiKey: "AIzaSyB2LPmuXM2WZp6aB6vrSxs5NFNP4CIVApE",
            authDomain: "bowersworld-digital-alexandria.firebaseapp.com",
            projectId: "bowersworld-digital-alexandria",
            storageBucket: "bowersworld-digital-alexandria.appspot.com",
            messagingSenderId: "486786884647",
            appId: "1:486786884647:web:85806a519fe582e6fd5a02"
        };

        // Configuration validation
        console.log('üî• Using Firebase config for:', firebaseConfig.projectId);

        // Initialize Firebase
        const app = initializeApp(firebaseConfig);
        const auth = getAuth(app);
        const provider = new GoogleAuthProvider();

        // Make auth available globally
        window.firebaseAuth = auth;
        window.googleProvider = provider;

        // Auth state observer
        onAuthStateChanged(auth, (user) => {
            if (user) {
                console.log('User signed in:', user.email);
                // Redirect to library or dashboard
                redirectToLibrary(user);
            } else {
                console.log('User signed out');
            }
        });

        console.log('üî• Firebase initialized successfully');
    </script>

    <script>
        // Global functions for form handling
        function switchTab(tab) {
            // Update tab buttons
            document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            
            // Update forms
            document.querySelectorAll('.auth-form').forEach(form => form.classList.remove('active'));
            document.getElementById(tab + 'Form').classList.add('active');
            
            // Clear messages
            clearMessages();
        }

        function showMessage(message, type = 'info') {
            const container = document.getElementById('messageContainer');
            container.innerHTML = `<div class="message ${type}">${message}</div>`;
            
            // Auto-hide after 5 seconds
            setTimeout(() => {
                container.innerHTML = '';
            }, 5000);
        }

        function clearMessages() {
            document.getElementById('messageContainer').innerHTML = '';
        }

        function showLoading(show) {
            const loading = document.getElementById('loadingIndicator');
            const forms = document.querySelectorAll('.auth-form');
            
            if (show) {
                loading.style.display = 'block';
                forms.forEach(form => form.style.display = 'none');
            } else {
                loading.style.display = 'none';
                forms.forEach(form => form.style.display = 'block');
            }
        }

        // Enhanced error handling for form validation
        function isValidPassword(password) {
            if (!password || password.length < 8) return false;
            return /[A-Z]/.test(password) && 
                   /[a-z]/.test(password) && 
                   /[0-9]/.test(password);
        }

        // Safe form data extraction
        function getFormData(form) {
            const formData = new FormData(form);
            const data = {};
            
            for (let [key, value] of formData.entries()) {
                data[key] = value || '';
            }
            
            return data;
        }

        // Sign in with Google
        async function signInWithGoogle() {
            showLoading(true);
            
            try {
                const { signInWithPopup } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const result = await signInWithPopup(window.firebaseAuth, window.googleProvider);
                
                showMessage('Successfully signed in with Google!', 'success');
                
                // Save user to database
                await saveUserToDatabase({
                    userID: result.user.uid,
                    email: result.user.email,
                    fullName: result.user.displayName,
                    provider: 'google',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
            } catch (error) {
                console.error('Google sign-in error:', error);
                showMessage('Google sign-in failed: ' + error.message, 'error');
            } finally {
                showLoading(false);
            }
        }

        // Password reset
        async function resetPassword() {
            const email = prompt('Enter your email address for password reset:');
            if (!email) return;
            
            try {
                const { sendPasswordResetEmail } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                await sendPasswordResetEmail(window.firebaseAuth, email);
                showMessage('Password reset email sent! Check your inbox.', 'success');
            } catch (error) {
                showMessage('Error sending reset email: ' + error.message, 'error');
            }
        }

        // Save user to Google Sheets (you'll need to implement this)
        async function saveUserToDatabase(userData) {
            // This will connect to your Google Sheets API
            console.log('Saving user to database:', userData);
            
            // Implement Google Sheets API call here
            // For now, just log the data
        }

        // Redirect to library
        function redirectToLibrary(user) {
            // Check user status and redirect appropriately
            console.log('Redirecting user to library:', user.email);
            
            // For now, just show a success message
            showMessage(`Welcome ${user.displayName || user.email}! Redirecting to library...`, 'success');
            
            // Actual redirect would be:
            // window.location.href = '/library/app/library.html';
        }

        // Terms and Privacy
        function showTerms() {
            alert('Terms of Service\n\nBy using Anderson\'s Library, you agree to:\n\n‚Ä¢ Use the library for educational and research purposes only\n‚Ä¢ Not share your account credentials\n‚Ä¢ Respect copyright and licensing terms\n‚Ä¢ Report any technical issues or concerns\n\nFull terms available at: bowersworld.com/terms');
        }

        function showPrivacy() {
            alert('Privacy Policy\n\nWe protect your privacy by:\n\n‚Ä¢ Using Firebase for secure authentication\n‚Ä¢ Storing minimal personal data\n‚Ä¢ Not sharing information with third parties\n‚Ä¢ Allowing account deletion at any time\n\nFull privacy policy at: bowersworld.com/privacy');
        }

        // Form submissions
        document.getElementById('loginForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            const email = document.getElementById('loginEmail').value;
            const password = document.getElementById('loginPassword').value;
            
            try {
                const { signInWithEmailAndPassword } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const userCredential = await signInWithEmailAndPassword(window.firebaseAuth, email, password);
                
                showMessage('Successfully signed in!', 'success');
                
            } catch (error) {
                console.error('Login error:', error);
                let errorMessage = 'Login failed. Please check your credentials.';
                
                if (error.code === 'auth/user-not-found') {
                    errorMessage = 'No account found with this email address.';
                } else if (error.code === 'auth/wrong-password') {
                    errorMessage = 'Incorrect password.';
                } else if (error.code === 'auth/invalid-email') {
                    errorMessage = 'Invalid email address.';
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        document.getElementById('registerForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            try {
                const userData = getFormData(e.target);
                
                // Enhanced validation
                if (!userData.registerEmail || !userData.registerPassword) {
                    throw new Error('Email and password are required');
                }
                
                if (userData.registerPassword !== userData.confirmPassword) {
                    throw new Error('Passwords do not match');
                }
                
                if (!isValidPassword(userData.registerPassword)) {
                    throw new Error('Password must be at least 8 characters with uppercase, lowercase, and numbers');
                }
                
                if (!userData.agreeTerms) {
                    throw new Error('You must agree to the terms of service');
                }
                
                const { createUserWithEmailAndPassword, sendEmailVerification } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                
                const userCredential = await createUserWithEmailAndPassword(
                    window.firebaseAuth, 
                    userData.registerEmail, 
                    userData.registerPassword
                );
                
                // Send email verification
                await sendEmailVerification(userCredential.user);
                
                // Save to database (implement this function)
                await saveUserToDatabase({
                    userID: userCredential.user.uid,
                    email: userData.registerEmail,
                    fullName: `${userData.firstName || ''} ${userData.lastName || ''}`.trim(),
                    firstName: userData.firstName || '',
                    lastName: userData.lastName || '',
                    organization: userData.organization || '',
                    accessReason: userData.accessReason || '',
                    emailUpdates: userData.emailUpdates === 'on',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
                showMessage('Account created successfully! Please check your email for verification.', 'success');
                e.target.reset();
                
            } catch (error) {
                console.error('Registration error:', error);
                let errorMessage = 'Registration failed: ' + error.message;
                
                // Handle specific Firebase errors
                switch (error.code) {
                    case 'auth/email-already-in-use':
                        errorMessage = 'An account with this email already exists.';
                        break;
                    case 'auth/weak-password':
                        errorMessage = 'Password is too weak.';
                        break;
                    case 'auth/invalid-email':
                        errorMessage = 'Invalid email address.';
                        break;
                    case 'auth/network-request-failed':
                        errorMessage = 'Network error. Please check your connection.';
                        break;
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üöÄ Authentication system ready');
            
            // Check if user is already signed in
            if (window.firebaseAuth && window.firebaseAuth.currentUser) {
                redirectToLibrary(window.firebaseAuth.currentUser);
            }
        });
    </script>
</body>
</html>
================
File: Updates/..Old/firebase_auth_system.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Firebase Auth - Anderson's Library</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .auth-container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 2rem;
            border-radius: 15px;
            max-width: 450px;
            width: 90%;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .header {
            text-align: center;
            margin-bottom: 2rem;
        }

        .header h1 {
            color: #ffd93d;
            margin-bottom: 0.5rem;
            font-size: 2rem;
        }

        .header p {
            opacity: 0.9;
            font-size: 0.9rem;
        }

        .auth-tabs {
            display: flex;
            margin-bottom: 2rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 0.25rem;
        }

        .tab-button {
            flex: 1;
            padding: 0.75rem;
            background: none;
            border: none;
            color: white;
            cursor: pointer;
            border-radius: 7px;
            transition: all 0.3s ease;
            font-weight: 500;
        }

        .tab-button.active {
            background: rgba(255, 217, 61, 0.2);
            color: #ffd93d;
        }

        .auth-form {
            display: none;
        }

        .auth-form.active {
            display: block;
        }

        .form-group {
            margin-bottom: 1.5rem;
        }

        .form-group label {
            display: block;
            margin-bottom: 0.5rem;
            font-weight: 500;
            color: #ffd93d;
        }

        .form-group input, .form-group select, .form-group textarea {
            width: 100%;
            padding: 0.75rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 1rem;
        }

        .form-group input::placeholder {
            color: rgba(255, 255, 255, 0.7);
        }

        .form-row {
            display: flex;
            gap: 1rem;
        }

        .form-row .form-group {
            flex: 1;
        }

        .submit-btn {
            width: 100%;
            padding: 1rem;
            background: linear-gradient(45deg, #ffd93d, #ff6b6b);
            color: #1e3c72;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin-bottom: 1rem;
        }

        .submit-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(255, 217, 61, 0.4);
        }

        .submit-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .google-btn {
            width: 100%;
            padding: 1rem;
            background: white;
            color: #333;
            border: none;
            border-radius: 8px;
            font-size: 1rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .google-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .divider {
            text-align: center;
            margin: 1.5rem 0;
            position: relative;
        }

        .divider::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 0;
            right: 0;
            height: 1px;
            background: rgba(255, 255, 255, 0.3);
        }

        .divider span {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            padding: 0 1rem;
            color: rgba(255, 255, 255, 0.7);
            font-size: 0.9rem;
        }

        .checkbox-group {
            display: flex;
            align-items: flex-start;
            gap: 0.5rem;
            margin-bottom: 1.5rem;
        }

        .checkbox-group input[type="checkbox"] {
            width: auto;
            margin-top: 0.2rem;
        }

        .checkbox-group label {
            margin-bottom: 0;
            font-size: 0.9rem;
            line-height: 1.4;
        }

        .message {
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1rem;
            font-weight: 500;
            text-align: center;
        }

        .message.success {
            background: rgba(46, 213, 115, 0.2);
            border: 1px solid rgba(46, 213, 115, 0.5);
            color: #2ed573;
        }

        .message.error {
            background: rgba(255, 107, 107, 0.2);
            border: 1px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
        }

        .loading {
            display: none;
            text-align: center;
            padding: 2rem;
        }

        .spinner {
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 3px solid #ffd93d;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 1rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .footer {
            text-align: center;
            margin-top: 1.5rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.2);
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .status {
            position: fixed;
            top: 20px;
            right: 20px;
            background: rgba(255, 217, 61, 0.9);
            color: #1e3c72;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
        }

        @media (max-width: 480px) {
            .auth-container {
                margin: 1rem;
                padding: 1.5rem;
            }

            .form-row {
                flex-direction: column;
                gap: 0;
            }

            .header h1 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="status">üî• Firebase Ready</div>

    <div class="auth-container">
        <div class="header">
            <h1>üìö Anderson's Library</h1>
            <p>Secure access to thousands of digital resources</p>
        </div>

        <div class="auth-tabs">
            <button class="tab-button active" onclick="switchTab('login')">Sign In</button>
            <button class="tab-button" onclick="switchTab('register')">Register</button>
        </div>

        <div id="messageContainer"></div>

        <!-- Login Form -->
        <form id="loginForm" class="auth-form active">
            <div class="form-group">
                <label for="loginEmail">Email Address</label>
                <input type="email" id="loginEmail" placeholder="Enter your email" required>
            </div>
            <div class="form-group">
                <label for="loginPassword">Password</label>
                <input type="password" id="loginPassword" placeholder="Enter your password" required>
            </div>
            <button type="submit" class="submit-btn">Sign In to Library</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Continue with Google
            </button>
            
            <div style="text-align: center; margin-top: 1rem;">
                <a href="#" onclick="resetPassword()" style="color: #ffd93d; text-decoration: none; font-size: 0.9rem;">Forgot your password?</a>
            </div>
        </form>

        <!-- Registration Form -->
        <form id="registerForm" class="auth-form">
            <div class="form-row">
                <div class="form-group">
                    <label for="firstName">First Name</label>
                    <input type="text" id="firstName" placeholder="First name" required>
                </div>
                <div class="form-group">
                    <label for="lastName">Last Name</label>
                    <input type="text" id="lastName" placeholder="Last name" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="registerEmail">Email Address</label>
                <input type="email" id="registerEmail" placeholder="your.email@example.com" required>
            </div>
            
            <div class="form-row">
                <div class="form-group">
                    <label for="registerPassword">Password</label>
                    <input type="password" id="registerPassword" placeholder="Min 8 characters" required>
                </div>
                <div class="form-group">
                    <label for="confirmPassword">Confirm Password</label>
                    <input type="password" id="confirmPassword" placeholder="Confirm password" required>
                </div>
            </div>
            
            <div class="form-group">
                <label for="organization">Organization (Optional)</label>
                <input type="text" id="organization" placeholder="University, Company, etc.">
            </div>
            
            <div class="form-group">
                <label for="accessReason">Reason for Access</label>
                <select id="accessReason" required>
                    <option value="">Select your primary purpose</option>
                    <option value="Academic Research">Academic Research</option>
                    <option value="Professional Development">Professional Development</option>
                    <option value="Personal Learning">Personal Learning</option>
                    <option value="Teaching">Teaching</option>
                    <option value="Writing/Publishing">Writing/Publishing</option>
                    <option value="Other">Other</option>
                </select>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="agreeTerms" required>
                <label for="agreeTerms">I agree to the <a href="#" onclick="showTerms()" style="color: #ffd93d;">Terms of Service</a> and <a href="#" onclick="showPrivacy()" style="color: #ffd93d;">Privacy Policy</a></label>
            </div>
            
            <div class="checkbox-group">
                <input type="checkbox" id="emailUpdates">
                <label for="emailUpdates">I'd like to receive email updates about new additions to the library</label>
            </div>
            
            <button type="submit" class="submit-btn">Create Account</button>
            
            <div class="divider"><span>or</span></div>
            
            <button type="button" class="google-btn" onclick="signInWithGoogle()">
                <svg width="18" height="18" viewBox="0 0 24 24">
                    <path fill="#4285F4" d="M22.56 12.25c0-.78-.07-1.53-.2-2.25H12v4.26h5.92c-.26 1.37-1.04 2.53-2.21 3.31v2.77h3.57c2.08-1.92 3.28-4.74 3.28-8.09z"/>
                    <path fill="#34A853" d="M12 23c2.97 0 5.46-.98 7.28-2.66l-3.57-2.77c-.98.66-2.23 1.06-3.71 1.06-2.86 0-5.29-1.93-6.16-4.53H2.18v2.84C3.99 20.53 7.7 23 12 23z"/>
                    <path fill="#FBBC05" d="M5.84 14.09c-.22-.66-.35-1.36-.35-2.09s.13-1.43.35-2.09V7.07H2.18C1.43 8.55 1 10.22 1 12s.43 3.45 1.18 4.93l2.85-2.22.81-.62z"/>
                    <path fill="#EA4335" d="M12 5.38c1.62 0 3.06.56 4.21 1.64l3.15-3.15C17.45 2.09 14.97 1 12 1 7.7 1 3.99 3.47 2.18 7.07l3.66 2.84c.87-2.6 3.3-4.53 6.16-4.53z"/>
                </svg>
                Sign up with Google
            </button>
        </form>

        <!-- Loading State -->
        <div id="loadingIndicator" class="loading">
            <div class="spinner"></div>
            <p>Connecting to Anderson's Library...</p>
        </div>

        <div class="footer">
            <p>¬© 2025 Project Himalaya | Powered by BowersWorld.com</p>
        </div>
    </div>

    <!-- Firebase SDK -->
    <script type="module">
        // Import Firebase modules
        import { initializeApp } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-app.js';
        import { 
            getAuth, 
            signInWithEmailAndPassword, 
            createUserWithEmailAndPassword,
            signInWithPopup,
            GoogleAuthProvider,
            sendEmailVerification,
            sendPasswordResetEmail,
            onAuthStateChanged
        } from 'https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js';

        // Firebase configuration - REPLACE WITH YOUR CONFIG
        const firebaseConfig = {
            apiKey: "your-api-key-here",
            authDomain: "your-project.firebaseapp.com",
            projectId: "your-project-id",
            storageBucket: "your-project.appspot.com",
            messagingSenderId: "123456789",
            appId: "your-app-id"
        };

        // Initialize Firebase
        const app = initializeApp(firebaseConfig);
        const auth = getAuth(app);
        const provider = new GoogleAuthProvider();

        // Make auth available globally
        window.firebaseAuth = auth;
        window.googleProvider = provider;

        // Auth state observer
        onAuthStateChanged(auth, (user) => {
            if (user) {
                console.log('User signed in:', user.email);
                // Redirect to library or dashboard
                redirectToLibrary(user);
            } else {
                console.log('User signed out');
            }
        });

        console.log('üî• Firebase initialized successfully');
    </script>

    <script>
        // Global functions for form handling
        function switchTab(tab) {
            // Update tab buttons
            document.querySelectorAll('.tab-button').forEach(btn => btn.classList.remove('active'));
            event.target.classList.add('active');
            
            // Update forms
            document.querySelectorAll('.auth-form').forEach(form => form.classList.remove('active'));
            document.getElementById(tab + 'Form').classList.add('active');
            
            // Clear messages
            clearMessages();
        }

        function showMessage(message, type = 'info') {
            const container = document.getElementById('messageContainer');
            container.innerHTML = `<div class="message ${type}">${message}</div>`;
            
            // Auto-hide after 5 seconds
            setTimeout(() => {
                container.innerHTML = '';
            }, 5000);
        }

        function clearMessages() {
            document.getElementById('messageContainer').innerHTML = '';
        }

        function showLoading(show) {
            const loading = document.getElementById('loadingIndicator');
            const forms = document.querySelectorAll('.auth-form');
            
            if (show) {
                loading.style.display = 'block';
                forms.forEach(form => form.style.display = 'none');
            } else {
                loading.style.display = 'none';
                forms.forEach(form => form.style.display = 'block');
            }
        }

        function isValidPassword(password) {
            return password.length >= 8 && 
                   /[A-Z]/.test(password) && 
                   /[a-z]/.test(password) && 
                   /[0-9]/.test(password);
        }

        // Sign in with Google
        async function signInWithGoogle() {
            showLoading(true);
            
            try {
                const { signInWithPopup } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const result = await signInWithPopup(window.firebaseAuth, window.googleProvider);
                
                showMessage('Successfully signed in with Google!', 'success');
                
                // Save user to database
                await saveUserToDatabase({
                    userID: result.user.uid,
                    email: result.user.email,
                    fullName: result.user.displayName,
                    provider: 'google',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
            } catch (error) {
                console.error('Google sign-in error:', error);
                showMessage('Google sign-in failed: ' + error.message, 'error');
            } finally {
                showLoading(false);
            }
        }

        // Password reset
        async function resetPassword() {
            const email = prompt('Enter your email address for password reset:');
            if (!email) return;
            
            try {
                const { sendPasswordResetEmail } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                await sendPasswordResetEmail(window.firebaseAuth, email);
                showMessage('Password reset email sent! Check your inbox.', 'success');
            } catch (error) {
                showMessage('Error sending reset email: ' + error.message, 'error');
            }
        }

        // Save user to Google Sheets (you'll need to implement this)
        async function saveUserToDatabase(userData) {
            // This will connect to your Google Sheets API
            console.log('Saving user to database:', userData);
            
            // Implement Google Sheets API call here
            // For now, just log the data
        }

        // Redirect to library
        function redirectToLibrary(user) {
            // Check user status and redirect appropriately
            console.log('Redirecting user to library:', user.email);
            
            // For now, just show a success message
            showMessage(`Welcome ${user.displayName || user.email}! Redirecting to library...`, 'success');
            
            // Actual redirect would be:
            // window.location.href = '/library/app/library.html';
        }

        // Terms and Privacy
        function showTerms() {
            alert('Terms of Service\n\nBy using Anderson\'s Library, you agree to:\n\n‚Ä¢ Use the library for educational and research purposes only\n‚Ä¢ Not share your account credentials\n‚Ä¢ Respect copyright and licensing terms\n‚Ä¢ Report any technical issues or concerns\n\nFull terms available at: bowersworld.com/terms');
        }

        function showPrivacy() {
            alert('Privacy Policy\n\nWe protect your privacy by:\n\n‚Ä¢ Using Firebase for secure authentication\n‚Ä¢ Storing minimal personal data\n‚Ä¢ Not sharing information with third parties\n‚Ä¢ Allowing account deletion at any time\n\nFull privacy policy at: bowersworld.com/privacy');
        }

        // Form submissions
        document.getElementById('loginForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            const email = document.getElementById('loginEmail').value;
            const password = document.getElementById('loginPassword').value;
            
            try {
                const { signInWithEmailAndPassword } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                const userCredential = await signInWithEmailAndPassword(window.firebaseAuth, email, password);
                
                showMessage('Successfully signed in!', 'success');
                
            } catch (error) {
                console.error('Login error:', error);
                let errorMessage = 'Login failed. Please check your credentials.';
                
                if (error.code === 'auth/user-not-found') {
                    errorMessage = 'No account found with this email address.';
                } else if (error.code === 'auth/wrong-password') {
                    errorMessage = 'Incorrect password.';
                } else if (error.code === 'auth/invalid-email') {
                    errorMessage = 'Invalid email address.';
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        document.getElementById('registerForm').addEventListener('submit', async function(e) {
            e.preventDefault();
            showLoading(true);
            
            const formData = new FormData(e.target);
            const userData = Object.fromEntries(formData.entries());
            
            // Validation
            if (userData.registerPassword !== userData.confirmPassword) {
                showMessage('Passwords do not match.', 'error');
                showLoading(false);
                return;
            }
            
            if (!isValidPassword(userData.registerPassword)) {
                showMessage('Password must be at least 8 characters with uppercase, lowercase, and numbers.', 'error');
                showLoading(false);
                return;
            }
            
            try {
                const { createUserWithEmailAndPassword, sendEmailVerification } = await import('https://www.gstatic.com/firebasejs/10.8.0/firebase-auth.js');
                
                const userCredential = await createUserWithEmailAndPassword(
                    window.firebaseAuth, 
                    userData.registerEmail, 
                    userData.registerPassword
                );
                
                // Send email verification
                await sendEmailVerification(userCredential.user);
                
                // Save to database
                await saveUserToDatabase({
                    userID: userCredential.user.uid,
                    email: userData.registerEmail,
                    fullName: `${userData.firstName} ${userData.lastName}`,
                    firstName: userData.firstName,
                    lastName: userData.lastName,
                    organization: userData.organization,
                    accessReason: userData.accessReason,
                    emailUpdates: userData.emailUpdates === 'on',
                    role: 'guest',
                    status: 'pending',
                    registrationDate: new Date().toISOString()
                });
                
                showMessage('Account created successfully! Please check your email for verification.', 'success');
                
                // Clear form
                e.target.reset();
                
            } catch (error) {
                console.error('Registration error:', error);
                let errorMessage = 'Registration failed. Please try again.';
                
                if (error.code === 'auth/email-already-in-use') {
                    errorMessage = 'An account with this email already exists.';
                } else if (error.code === 'auth/weak-password') {
                    errorMessage = 'Password is too weak.';
                } else if (error.code === 'auth/invalid-email') {
                    errorMessage = 'Invalid email address.';
                }
                
                showMessage(errorMessage, 'error');
            } finally {
                showLoading(false);
            }
        });

        // Initialize on load
        document.addEventListener('DOMContentLoaded', function() {
            console.log('üöÄ Authentication system ready');
            
            // Check if user is already signed in
            if (window.firebaseAuth && window.firebaseAuth.currentUser) {
                redirectToLibrary(window.firebaseAuth.currentUser);
            }
        });
    </script>
</body>
</html>
================
File: Updates/..Old/library_interface.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Anderson's Library - Digital Collection</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            min-height: 100vh;
        }

        .header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 1rem 2rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 1rem;
        }

        .logo {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            font-size: 1.5rem;
            font-weight: bold;
            color: #ffd93d;
        }

        .user-info {
            display: flex;
            align-items: center;
            gap: 1rem;
        }

        .user-avatar {
            width: 40px;
            height: 40px;
            background: #ffd93d;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #1e3c72;
            font-weight: bold;
        }

        .search-container {
            padding: 2rem;
            max-width: 1200px;
            margin: 0 auto;
        }

        .search-box {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .search-input-container {
            position: relative;
            margin-bottom: 1.5rem;
        }

        .search-input {
            width: 100%;
            padding: 1rem 1rem 1rem 3rem;
            font-size: 1.1rem;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            transition: all 0.3s ease;
        }

        .search-input:focus {
            outline: none;
            border-color: #ffd93d;
            box-shadow: 0 0 20px rgba(255, 217, 61, 0.3);
        }

        .search-input::placeholder {
            color: rgba(255, 255, 255, 0.7);
        }

        .search-icon {
            position: absolute;
            left: 1rem;
            top: 50%;
            transform: translateY(-50%);
            color: #ffd93d;
            font-size: 1.2rem;
        }

        .filters {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            align-items: center;
        }

        .filter-select {
            padding: 0.5rem 1rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            font-size: 0.9rem;
        }

        .stats {
            display: flex;
            gap: 2rem;
            margin-bottom: 2rem;
            flex-wrap: wrap;
        }

        .stat-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            padding: 1.5rem;
            border-radius: 10px;
            text-align: center;
            flex: 1;
            min-width: 150px;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            color: #ffd93d;
            display: block;
        }

        .stat-label {
            font-size: 0.9rem;
            opacity: 0.8;
            margin-top: 0.5rem;
        }

        .books-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 1.5rem;
            margin-top: 2rem;
        }

        .book-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 1.5rem;
            border: 1px solid rgba(255, 255, 255, 0.2);
            transition: all 0.3s ease;
            cursor: pointer;
            position: relative;
            overflow: hidden;
        }

        .book-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            border-color: #ffd93d;
        }

        .book-title {
            font-size: 1.1rem;
            font-weight: bold;
            color: #ffd93d;
            margin-bottom: 0.5rem;
            line-height: 1.3;
            display: -webkit-box;
            -webkit-line-clamp: 2;
            -webkit-box-orient: vertical;
            overflow: hidden;
        }

        .book-meta {
            display: flex;
            flex-direction: column;
            gap: 0.5rem;
            margin-bottom: 1rem;
        }

        .book-category {
            display: inline-block;
            padding: 0.25rem 0.75rem;
            background: rgba(255, 217, 61, 0.2);
            color: #ffd93d;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
            width: fit-content;
        }

        .book-confidence {
            font-size: 0.8rem;
            opacity: 0.8;
        }

        .book-info {
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .confidence-bar {
            width: 60px;
            height: 4px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 2px;
            overflow: hidden;
        }

        .confidence-fill {
            height: 100%;
            background: linear-gradient(90deg, #ff6b6b, #ffd93d, #4ecdc4);
            border-radius: 2px;
            transition: width 0.3s ease;
        }

        .book-actions {
            display: flex;
            gap: 0.5rem;
            margin-top: 1rem;
        }

        .btn {
            padding: 0.5rem 1rem;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 0.9rem;
            font-weight: 500;
            transition: all 0.3s ease;
            flex: 1;
        }

        .btn-primary {
            background: #ffd93d;
            color: #1e3c72;
        }

        .btn-secondary {
            background: rgba(255, 255, 255, 0.1);
            color: white;
            border: 1px solid rgba(255, 255, 255, 0.3);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .pagination {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 1rem;
            margin: 3rem 0;
        }

        .pagination button {
            padding: 0.75rem 1rem;
            border: 1px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .pagination button:hover {
            background: rgba(255, 217, 61, 0.2);
            border-color: #ffd93d;
        }

        .pagination button.active {
            background: #ffd93d;
            color: #1e3c72;
            border-color: #ffd93d;
        }

        .pagination button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .loading {
            text-align: center;
            padding: 3rem;
            font-size: 1.1rem;
        }

        .spinner {
            border: 3px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 3px solid #ffd93d;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 1rem;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .no-results {
            text-align: center;
            padding: 3rem;
            opacity: 0.8;
        }

        .quick-stats {
            display: flex;
            gap: 1rem;
            margin-bottom: 1rem;
            font-size: 0.9rem;
        }

        .quick-stat {
            background: rgba(255, 255, 255, 0.1);
            padding: 0.5rem 1rem;
            border-radius: 20px;
        }

        @media (max-width: 768px) {
            .header {
                padding: 1rem;
                flex-direction: column;
                text-align: center;
            }

            .search-container {
                padding: 1rem;
            }

            .books-grid {
                grid-template-columns: 1fr;
            }

            .filters {
                justify-content: center;
            }

            .stats {
                flex-direction: column;
                gap: 1rem;
            }
        }

        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.8);
            z-index: 1000;
            backdrop-filter: blur(5px);
        }

        .modal-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            border-radius: 15px;
            padding: 2rem;
            max-width: 600px;
            width: 90%;
            max-height: 80vh;
            overflow-y: auto;
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 1.5rem;
        }

        .modal-title {
            color: #ffd93d;
            font-size: 1.3rem;
            font-weight: bold;
        }

        .close-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            padding: 0.25rem;
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="logo">
            üìö Anderson's Library
        </div>
        <div class="user-info">
            <span id="userEmail">user@example.com</span>
            <div class="user-avatar" id="userAvatar">A</div>
            <button class="btn btn-secondary" onclick="signOut()">Sign Out</button>
        </div>
    </div>

    <div class="search-container">
        <div class="search-box">
            <div class="search-input-container">
                <div class="search-icon">üîç</div>
                <input 
                    type="text" 
                    class="search-input" 
                    id="searchInput"
                    placeholder="Search by title, author, category, or content..."
                    onkeyup="handleSearch()"
                >
            </div>
            
            <div class="filters">
                <select id="categoryFilter" class="filter-select" onchange="applyFilters()">
                    <option value="">All Categories</option>
                </select>
                <select id="subjectFilter" class="filter-select" onchange="applyFilters()">
                    <option value="">All Subjects</option>
                </select>
                <select id="confidenceFilter" class="filter-select" onchange="applyFilters()">
                    <option value="">All Confidence Levels</option>
                    <option value="high">High Confidence (80%+)</option>
                    <option value="medium">Medium Confidence (50-79%)</option>
                    <option value="low">Low Confidence (<50%)</option>
                </select>
                <select id="sortBy" class="filter-select" onchange="applyFilters()">
                    <option value="title">Sort by Title</option>
                    <option value="category">Sort by Category</option>
                    <option value="confidence">Sort by Confidence</option>
                    <option value="size">Sort by Size</option>
                </select>
            </div>
        </div>

        <div class="stats">
            <div class="stat-card">
                <span class="stat-number" id="totalBooks">1,219</span>
                <div class="stat-label">Total Books</div>
            </div>
            <div class="stat-card">
                <span class="stat-number" id="categorizedBooks">987</span>
                <div class="stat-label">Categorized</div>
            </div>
            <div class="stat-card">
                <span class="stat-number" id="highConfidence">756</span>
                <div class="stat-label">High Confidence</div>
            </div>
            <div class="stat-card">
                <span class="stat-number" id="totalSize">24.7 GB</span>
                <div class="stat-label">Total Size</div>
            </div>
        </div>

        <div class="quick-stats">
            <div class="quick-stat">üìä <span id="searchResults">Showing all 1,219 books</span></div>
            <div class="quick-stat">‚è±Ô∏è Last updated: June 27, 2025</div>
            <div class="quick-stat">üéØ AI Confidence: 87% average</div>
        </div>

        <div id="loadingIndicator" class="loading" style="display: none;">
            <div class="spinner"></div>
            <p>Loading your library...</p>
        </div>

        <div id="booksContainer" class="books-grid"></div>

        <div id="noResults" class="no-results" style="display: none;">
            <h3>üìö No books found</h3>
            <p>Try adjusting your search terms or filters</p>
        </div>

        <div class="pagination" id="pagination"></div>
    </div>

    <!-- Book Details Modal -->
    <div id="bookModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <div class="modal-title" id="modalTitle">Book Details</div>
                <button class="close-btn" onclick="closeModal()">&times;</button>
            </div>
            <div id="modalBody"></div>
        </div>
    </div>

    <script>
        // Sample book data based on your processing report
        let booksData = [];
        let filteredBooks = [];
        let currentPage = 1;
        const booksPerPage = 12;

        // Initialize the application
        document.addEventListener('DOMContentLoaded', function() {
            loadSampleData();
            setupEventListeners();
            renderBooks();
            updateStats();
            populateFilters();
        });

        // Load sample data (in production, this would come from your database)
        function loadSampleData() {
            // Sample data based on your processing report
            booksData = [
                {
                    filename: "Essentials of Materials Science & Engineering.pdf",
                    title: "Essentials of Materials Science & Engineering",
                    category: "Engineering",
                    subject: "Materials Science",
                    categoryConfidence: 100,
                    subjectConfidence: 98,
                    overallConfidence: 99,
                    similarBooks: ["Fundamentals of Materials Science and Engineering", "Materials Science and Engineering"],
                    flags: [],
                    fileSize: 15.2,
                    pageCount: 624
                },
                {
                    filename: "Encyclopedia of Virology.pdf",
                    title: "Encyclopedia of Virology, Third Edition",
                    category: "Biology",
                    subject: "Virology",
                    categoryConfidence: 53,
                    subjectConfidence: 67,
                    overallConfidence: 60,
                    similarBooks: ["Introduction to Modern Virology", "Principles of Virology"],
                    flags: ["low_category_confidence"],
                    fileSize: 42.8,
                    pageCount: 1256
                },
                {
                    filename: "Chess For Dummies.pdf",
                    title: "Chess For Dummies",
                    category: "Games",
                    subject: "Chess",
                    categoryConfidence: 97,
                    subjectConfidence: 98,
                    overallConfidence: 97.5,
                    similarBooks: ["Chess the Complete Guide", "Chess the Complete Beginner's Guide"],
                    flags: [],
                    fileSize: 8.4,
                    pageCount: 384
                },
                {
                    filename: "Core Java¬Æ Vol Two.pdf",
                    title: "Core Java Volume II‚ÄîAdvanced Features",
                    category: "Programming Languages",
                    subject: "Java",
                    categoryConfidence: 95.3,
                    subjectConfidence: 81,
                    overallConfidence: 88,
                    similarBooks: ["Core Java¬Æ Vol One", "Introduction to Java Programming"],
                    flags: [],
                    fileSize: 12.7,
                    pageCount: 892
                },
                {
                    filename: "Clinical Forensic Medicine.pdf",
                    title: "Clinical Forensic Medicine: A Physician's Guide, 3rd Edition",
                    category: "Forensic Science",
                    subject: "Forensic Medicine",
                    categoryConfidence: 99,
                    subjectConfidence: 100,
                    overallConfidence: 99.5,
                    similarBooks: ["Handbook of Forensic Medicine", "The Essentials of Forensic Medicine"],
                    flags: [],
                    fileSize: 18.9,
                    pageCount: 567
                }
                // Add more sample books as needed
            ];

            // Generate additional sample books to reach a good number for demo
            const categories = ["Programming Languages", "Engineering", "Biology", "Games", "Forensic Science", "Mathematics", "Physics", "Chemistry", "History", "Literature"];
            const subjects = ["Java", "Python", "C++", "Materials Science", "Molecular Biology", "Chess", "Forensic Medicine", "Calculus", "Quantum Physics", "Organic Chemistry"];

            for (let i = 5; i < 50; i++) {
                const randomCategory = categories[Math.floor(Math.random() * categories.length)];
                const randomSubject = subjects[Math.floor(Math.random() * subjects.length)];
                
                booksData.push({
                    filename: `Book_${i + 1}.pdf`,
                    title: `Sample Book Title ${i + 1}`,
                    category: randomCategory,
                    subject: randomSubject,
                    categoryConfidence: Math.floor(Math.random() * 50) + 50,
                    subjectConfidence: Math.floor(Math.random() * 50) + 50,
                    overallConfidence: Math.floor(Math.random() * 50) + 50,
                    similarBooks: [`Similar Book A`, `Similar Book B`],
                    flags: Math.random() > 0.7 ? ["needs_review"] : [],
                    fileSize: (Math.random() * 30) + 1,
                    pageCount: Math.floor(Math.random() * 800) + 100
                });
            }

            filteredBooks = [...booksData];
        }

        function setupEventListeners() {
            document.getElementById('searchInput').addEventListener('input', debounce(handleSearch, 300));
        }

        function debounce(func, wait) {
            let timeout;
            return function executedFunction(...args) {
                const later = () => {
                    clearTimeout(timeout);
                    func(...args);
                };
                clearTimeout(timeout);
                timeout = setTimeout(later, wait);
            };
        }

        function handleSearch() {
            const searchTerm = document.getElementById('searchInput').value.toLowerCase();
            
            if (searchTerm === '') {
                filteredBooks = [...booksData];
            } else {
                filteredBooks = booksData.filter(book => 
                    book.title.toLowerCase().includes(searchTerm) ||
                    book.category.toLowerCase().includes(searchTerm) ||
                    book.subject.toLowerCase().includes(searchTerm) ||
                    book.filename.toLowerCase().includes(searchTerm)
                );
            }
            
            currentPage = 1;
            applyFilters();
        }

        function applyFilters() {
            let filtered = [...filteredBooks];
            
            const categoryFilter = document.getElementById('categoryFilter').value;
            const subjectFilter = document.getElementById('subjectFilter').value;
            const confidenceFilter = document.getElementById('confidenceFilter').value;
            const sortBy = document.getElementById('sortBy').value;
            
            // Apply category filter
            if (categoryFilter) {
                filtered = filtered.filter(book => book.category === categoryFilter);
            }
            
            // Apply subject filter
            if (subjectFilter) {
                filtered = filtered.filter(book => book.subject === subjectFilter);
            }
            
            // Apply confidence filter
            if (confidenceFilter) {
                switch (confidenceFilter) {
                    case 'high':
                        filtered = filtered.filter(book => book.overallConfidence >= 80);
                        break;
                    case 'medium':
                        filtered = filtered.filter(book => book.overallConfidence >= 50 && book.overallConfidence < 80);
                        break;
                    case 'low':
                        filtered = filtered.filter(book => book.overallConfidence < 50);
                        break;
                }
            }
            
            // Apply sorting
            filtered.sort((a, b) => {
                switch (sortBy) {
                    case 'title':
                        return a.title.localeCompare(b.title);
                    case 'category':
                        return a.category.localeCompare(b.category);
                    case 'confidence':
                        return b.overallConfidence - a.overallConfidence;
                    case 'size':
                        return b.fileSize - a.fileSize;
                    default:
                        return a.title.localeCompare(b.title);
                }
            });
            
            filteredBooks = filtered;
            currentPage = 1;
            renderBooks();
            updateSearchResults();
        }

        function renderBooks() {
            const container = document.getElementById('booksContainer');
            const noResults = document.getElementById('noResults');
            
            if (filteredBooks.length === 0) {
                container.innerHTML = '';
                noResults.style.display = 'block';
                document.getElementById('pagination').innerHTML = '';
                return;
            }
            
            noResults.style.display = 'none';
            
            const startIndex = (currentPage - 1) * booksPerPage;
            const endIndex = startIndex + booksPerPage;
            const booksToShow = filteredBooks.slice(startIndex, endIndex);
            
            container.innerHTML = booksToShow.map(book => `
                <div class="book-card" onclick="showBookDetails('${book.filename}')">
                    <div class="book-title">${book.title}</div>
                    <div class="book-meta">
                        <div class="book-category">${book.category}</div>
                        <div class="book-confidence">Subject: ${book.subject} (${book.subjectConfidence}% confidence)</div>
                    </div>
                    <div class="book-info">
                        <span>${book.fileSize.toFixed(1)} MB ‚Ä¢ ${book.pageCount} pages</span>
                        <div class="confidence-bar">
                            <div class="confidence-fill" style="width: ${book.overallConfidence}%"></div>
                        </div>
                    </div>
                    ${book.flags.length > 0 ? `<div style="margin-top: 0.5rem; font-size: 0.8rem; color: #ff6b6b;">‚ö†Ô∏è ${book.flags.join(', ')}</div>` : ''}
                    <div class="book-actions">
                        <button class="btn btn-primary" onclick="event.stopPropagation(); openBook('${book.filename}')">
                            üìñ Read
                        </button>
                        <button class="btn btn-secondary" onclick="event.stopPropagation(); downloadBook('${book.filename}')">
                            üíæ Download
                        </button>
                    </div>
                </div>
            `).join('');
            
            renderPagination();
        }

        function renderPagination() {
            const totalPages = Math.ceil(filteredBooks.length / booksPerPage);
            const pagination = document.getElementById('pagination');
            
            if (totalPages <= 1) {
                pagination.innerHTML = '';
                return;
            }
            
            let paginationHTML = '';
            
            // Previous button
            paginationHTML += `<button ${currentPage === 1 ? 'disabled' : ''} onclick="changePage(${currentPage - 1})">‚Äπ Previous</button>`;
            
            // Page numbers
            for (let i = 1; i <= Math.min(totalPages, 5); i++) {
                const page = i;
                paginationHTML += `<button class="${page === currentPage ? 'active' : ''}" onclick="changePage(${page})">${page}</button>`;
            }
            
            if (totalPages > 5) {
                paginationHTML += `<span>...</span>`;
                paginationHTML += `<button class="${totalPages === currentPage ? 'active' : ''}" onclick="changePage(${totalPages})">${totalPages}</button>`;
            }
            
            // Next button
            paginationHTML += `<button ${currentPage === totalPages ? 'disabled' : ''} onclick="changePage(${currentPage + 1})">Next ‚Ä∫</button>`;
            
            pagination.innerHTML = paginationHTML;
        }

        function changePage(page) {
            currentPage = page;
            renderBooks();
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }

        function populateFilters() {
            const categories = [...new Set(booksData.map(book => book.category))].sort();
            const subjects = [...new Set(booksData.map(book => book.subject))].sort();
            
            const categorySelect = document.getElementById('categoryFilter');
            const subjectSelect = document.getElementById('subjectFilter');
            
            categorySelect.innerHTML = '<option value="">All Categories</option>' + 
                categories.map(cat => `<option value="${cat}">${cat}</option>`).join('');
            
            subjectSelect.innerHTML = '<option value="">All Subjects</option>' + 
                subjects.map(sub => `<option value="${sub}">${sub}</option>`).join('');
        }

        function updateStats() {
            const totalBooks = booksData.length;
            const categorizedBooks = booksData.filter(book => book.category && book.category !== '').length;
            const highConfidenceBooks = booksData.filter(book => book.overallConfidence >= 80).length;
            const totalSize = booksData.reduce((sum, book) => sum + book.fileSize, 0);
            
            document.getElementById('totalBooks').textContent = totalBooks.toLocaleString();
            document.getElementById('categorizedBooks').textContent = categorizedBooks.toLocaleString();
            document.getElementById('highConfidence').textContent = highConfidenceBooks.toLocaleString();
            document.getElementById('totalSize').textContent = (totalSize / 1000).toFixed(1) + ' GB';
        }

        function updateSearchResults() {
            const searchResults = document.getElementById('searchResults');
            if (filteredBooks.length === booksData.length) {
                searchResults.textContent = `Showing all ${filteredBooks.length.toLocaleString()} books`;
            } else {
                searchResults.textContent = `Showing ${filteredBooks.length.toLocaleString()} of ${booksData.length.toLocaleString()} books`;
            }
        }

        function showBookDetails(filename) {
            const book = booksData.find(b => b.filename === filename);
            if (!book) return;
            
            const modal = document.getElementById('bookModal');
            const modalTitle = document.getElementById('modalTitle');
            const modalBody = document.getElementById('modalBody');
            
            modalTitle.textContent = book.title;
            modalBody.innerHTML = `
                <div style="margin-bottom: 1.5rem;">
                    <h4 style="color: #ffd93d; margin-bottom: 1rem;">üìÑ Book Information</h4>
                    <p><strong>Filename:</strong> ${book.filename}</p>
                    <p><strong>Category:</strong> ${book.category} (${book.categoryConfidence}% confidence)</p>
                    <p><strong>Subject:</strong> ${book.subject} (${book.subjectConfidence}% confidence)</p>
                    <p><strong>Overall Confidence:</strong> ${book.overallConfidence}%</p>
                    <p><strong>File Size:</strong> ${book.fileSize.toFixed(1)} MB</p>
                    <p><strong>Page Count:</strong> ${book.pageCount}</p>
                </div>
                
                ${book.similarBooks.length > 0 ? `
                <div style="margin-bottom: 1.5rem;">
                    <h4 style="color: #ffd93d; margin-bottom: 1rem;">üìö Similar Books</h4>
                    <ul style="margin-left: 1rem;">
                        ${book.similarBooks.map(title => `<li>${title}</li>`).join('')}
                    </ul>
                </div>
                ` : ''}
                
                ${book.flags.length > 0 ? `
                <div style="margin-bottom: 1.5rem;">
                    <h4 style="color: #ff6b6b; margin-bottom: 1rem;">‚ö†Ô∏è Processing Flags</h4>
                    <p style="color: #ff6b6b;">${book.flags.join(', ')}</p>
                </div>
                ` : ''}
                
                <div class="book-actions">
                    <button class="btn btn-primary" onclick="openBook('${book.filename}')">üìñ Read Book</button>
                    <button class="btn btn-secondary" onclick="downloadBook('${book.filename}')">üíæ Download</button>
                </div>
            `;
            
            modal.style.display = 'block';
        }

        function closeModal() {
            document.getElementById('bookModal').style.display = 'none';
        }

        function openBook(filename) {
            // This would integrate with PDF.js viewer
            alert(`Opening ${filename} in PDF viewer...\n\nThis would normally open the PDF in a reader interface.`);
            closeModal();
        }

        function downloadBook(filename) {
            // This would trigger a download from Google Drive
            alert(`Downloading ${filename}...\n\nThis would normally start a download from your Google Drive.`);
            closeModal();
        }

        function signOut() {
            if (confirm('Are you sure you want to sign out?')) {
                // Firebase sign out logic would go here
                alert('Signed out successfully');
                window.location.href = '/library/auth/login.html';
            }
        }

        // Close modal when clicking outside
        window.onclick = function(event) {
            const modal = document.getElementById('bookModal');
            if (event.target === modal) {
                closeModal();
            }
        }

        // Initialize user info (this would come from Firebase auth)
        document.addEventListener('DOMContentLoaded', function() {
            const userEmail = 'user@example.com'; // Get from Firebase auth
            const userAvatar = document.getElementById('userAvatar');
            
            document.getElementById('userEmail').textContent = userEmail;
            userAvatar.textContent = userEmail.charAt(0).toUpperCase();
        });
    </script>
</body>
</html>
================
File: Updates/..Old/local_server_setup.sh
================
# Local Development Server Setup
# Choose ONE of these methods to serve your files:

# METHOD 1: Python HTTP Server (Recommended)
cd /home/herb/Desktop/BowersWorld-com
python3 -m http.server 8080
# Then access: http://localhost:8080/Updates/firebase_auth_system.html

# METHOD 2: Node.js HTTP Server
# First install: npm install -g http-server
cd /home/herb/Desktop/BowersWorld-com
http-server -p 8080 -c-1
# Then access: http://localhost:8080/Updates/firebase_auth_system.html

# METHOD 3: PHP Server (if PHP installed)
cd /home/herb/Desktop/BowersWorld-com
php -S localhost:8080
# Then access: http://localhost:8080/Updates/firebase_auth_system.html

# METHOD 4: VS Code Live Server Extension
# 1. Install "Live Server" extension in VS Code
# 2. Right-click your HTML file ‚Üí "Open with Live Server"

# WHY THIS IS NEEDED:
# - Google APIs require HTTP/HTTPS protocol
# - Firebase Auth needs proper origin headers
# - CORS policies block file:// protocol
# - Local server simulates production environment
================
File: Updates/..Old/quick_config_guide.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Firebase Config Helper</title>
    <style>
        body {
            font-family: 'Segoe UI', sans-serif;
            max-width: 800px;
            margin: 2rem auto;
            padding: 1rem;
            background: #f5f5f5;
        }
        .step {
            background: white;
            padding: 1.5rem;
            margin: 1rem 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .step h3 {
            color: #4285f4;
            margin-top: 0;
        }
        .code-block {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 1rem;
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            overflow-x: auto;
        }
        .highlight {
            background: #fff3cd;
            padding: 0.5rem;
            border-left: 4px solid #ffc107;
            margin: 1rem 0;
        }
        .success {
            background: #d4edda;
            padding: 0.5rem;
            border-left: 4px solid #28a745;
            margin: 1rem 0;
        }
        .navigation {
            background: #e3f2fd;
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 2rem;
        }
        .navigation strong {
            color: #1976d2;
        }
    </style>
</head>
<body>
    <div class="navigation">
        <strong>üéØ Current Status:</strong> You have Firebase project "BowersWorld-Digital-Alexandria" with Email/Password and Google auth enabled. Now you need the config values!
    </div>

    <div class="step">
        <h3>üî• Step 1: Get Your Config from Firebase Console</h3>
        <p>In your current Firebase Console tab:</p>
        <ol>
            <li>Click the <strong>gear icon ‚öôÔ∏è</strong> next to "Project Overview" (top left)</li>
            <li>Select <strong>"Project settings"</strong></li>
            <li>Scroll down to <strong>"Your apps"</strong> section</li>
            <li>If you see a web app, click on it. If not, click <strong>"Add app"</strong> ‚Üí <strong>Web</strong></li>
            <li>Copy the entire <code>firebaseConfig</code> object</li>
        </ol>
        
        <div class="highlight">
            <strong>‚ö†Ô∏è Important:</strong> Your project name suggests the config will look like this:
        </div>
        
        <div class="code-block">
const firebaseConfig = {
  apiKey: "AIzaSyC-your-long-api-key-here",
  authDomain: "bowersworld-digital-alexandria.firebaseapp.com",
  projectId: "bowersworld-digital-alexandria",
  storageBucket: "bowersworld-digital-alexandria.appspot.com",
  messagingSenderId: "your-sender-id",
  appId: "your-app-id"
};
        </div>
    </div>

    <div class="step">
        <h3>üåê Step 2: Add Authorized Domains (Do This Now)</h3>
        <p>In your Firebase Console (stay in Authentication section):</p>
        <ol>
            <li>Click <strong>"Settings"</strong> tab (next to "Sign-in method")</li>
            <li>Scroll to <strong>"Authorized domains"</strong></li>
            <li>Click <strong>"Add domain"</strong> for each of these:</li>
        </ol>
        
        <div class="code-block">
localhost
127.0.0.1
bowersworld.com
www.bowersworld.com
        </div>
    </div>

    <div class="step">
        <h3>üíª Step 3: Update Your Local File</h3>
        <p>Replace the placeholder config in your HTML file with your actual values:</p>
        
        <div class="code-block">
// In your firebase_auth_system.html file, replace this section:
const firebaseConfig = {
    apiKey: "AIzaSyC-REPLACE-WITH-YOUR-ACTUAL-API-KEY",
    authDomain: "anderson-library-XXXXX.firebaseapp.com",
    projectId: "anderson-library-XXXXX",
    storageBucket: "anderson-library-XXXXX.appspot.com",
    messagingSenderId: "123456789012",
    appId: "1:123456789012:web:abcdef123456789"
};

// With your actual config values from Step 1
        </div>
    </div>

    <div class="step">
        <h3>üöÄ Step 4: Test Locally</h3>
        <p>Start your local server and test:</p>
        
        <div class="code-block">
cd /home/herb/Desktop/BowersWorld-com
python3 -m http.server 8080
        </div>
        
        <p>Then visit: <strong>http://localhost:8080/Updates/firebase_auth_system.html</strong></p>
        
        <div class="success">
            <strong>‚úÖ Success indicators:</strong>
            <ul>
                <li>Console shows "üî• Firebase initialized successfully"</li>
                <li>No API key errors</li>
                <li>Registration form accepts input</li>
                <li>Status shows "üî• Firebase Ready"</li>
            </ul>
        </div>
    </div>

    <div class="step">
        <h3>üêõ Common Issues & Solutions</h3>
        
        <h4>"API key not valid"</h4>
        <ul>
            <li>Double-check you copied the config correctly</li>
            <li>Make sure there are no extra spaces or quotes</li>
            <li>Verify the project ID matches exactly</li>
        </ul>
        
        <h4>"auth/unauthorized-domain"</h4>
        <ul>
            <li>Add authorized domains in Firebase Console</li>
            <li>Wait 5-10 minutes for changes to take effect</li>
            <li>Make sure you're using http://localhost:8080, not file://</li>
        </ul>
        
        <h4>CORS errors</h4>
        <ul>
            <li>Must use local server (python3 -m http.server 8080)</li>
            <li>Cannot use file:// protocol</li>
            <li>Check authorized domains are set up</li>
        </ul>
    </div>

    <div class="step">
        <h3>üìã Next Steps After Config Works</h3>
        <ol>
            <li><strong>Test user registration</strong> - Create a test account</li>
            <li><strong>Set up Google Sheets</strong> - For user management database</li>
            <li><strong>Upload book data</strong> - Your processed 1,219 books to Google Drive</li>
            <li><strong>Deploy to GitHub Pages</strong> - Make it live on bowersworld.com</li>
        </ol>
    </div>

    <script>
        console.log('üîß Firebase Configuration Helper Loaded');
        console.log('üìç Follow the steps above to get your Firebase config working');
        
        // Helper function to validate config format
        function validateFirebaseConfig(config) {
            const required = ['apiKey', 'authDomain', 'projectId', 'storageBucket', 'messagingSenderId', 'appId'];
            const missing = required.filter(key => !config[key] || config[key].includes('REPLACE') || config[key].includes('XXXXX'));
            
            if (missing.length > 0) {
                console.warn('‚ùå Missing or placeholder values in Firebase config:', missing);
                return false;
            }
            
            console.log('‚úÖ Firebase config appears valid');
            return true;
        }
        
        // Make validation function available globally
        window.validateFirebaseConfig = validateFirebaseConfig;
        
        console.log('üí° Tip: After updating your config, you can test it by running validateFirebaseConfig(firebaseConfig) in the console');
    </script>
</body>
</html>
================
File: Updates/next_steps_plan.md
================
# Anderson's Library - Next Steps Priority Plan

## üö® Immediate Actions (Next 2 Weeks)

### 1. Complete Firebase Authentication Setup

- **Status**: Code exists, needs configuration completion
- **Action**: Update Firebase config in `firebase_auth_system.html` with actual credentials
- **Files**: `Updates/firebase_auth_system (2).html` has the working version
- **Test**: Local server setup with `python3 -m http.server 8080`

### 2. Establish Google Drive File Structure

- **Action**: Organize your 1,219 PDFs in Google Drive folders

- **Structure**:
  
  ```
  Anderson's Library/
  ‚îú‚îÄ‚îÄ Books/ (your 1,219 PDFs)
  ‚îú‚îÄ‚îÄ Covers/ (book cover images) 
  ‚îú‚îÄ‚îÄ Database/ (SQLite files)
  ‚îî‚îÄ‚îÄ Users/ (Google Sheets for user management)
  ```

### 3. Deploy Working Demo

- **Action**: Get basic version live on GitHub Pages
- **Current**: You have `index.html` ready
- **Add**: Working library interface from `Updates/library_interface.html`

## üéØ Phase 1: Core Functionality (Month 1)

### Week 1: Authentication & Access

- [ ] Complete Firebase auth integration
- [ ] Set up Google Sheets user management
- [ ] Test user registration/approval workflow
- [ ] Deploy to GitHub Pages

### Week 2: File Management

- [ ] Upload processed book collection to Google Drive
- [ ] Implement PDF streaming from Drive API
- [ ] Test download/viewing functionality
- [ ] Create book metadata API

### Week 3: Search & Browse

- [ ] Implement basic search functionality
- [ ] Add category/subject filtering
- [ ] Create responsive book grid interface
- [ ] Add pagination for large collections

### Week 4: Polish & Test

- [ ] User testing with beta group
- [ ] Performance optimization
- [ ] Mobile interface refinement
- [ ] Documentation completion

## üöÄ Phase 2: Enhanced Features (Month 2-3)

### Advanced Search

- Full-text search within PDFs
- Semantic similarity search
- AI-powered recommendations

### User Experience

- Reading progress tracking
- Personal collections/bookmarks
- Annotation system
- Offline reading capability

### AI Integration

- Book classification refinement
- Content analysis and tagging
- Knowledge graph construction
- Research assistant features

## üìä Success Metrics

### Technical

- [ ] Sub-second search across all 1,219 books
- [ ] 99%+ uptime for web interface
- [ ] Mobile-responsive design
- [ ] Secure user authentication

### User Experience

- [ ] Intuitive navigation for all skill levels
- [ ] Fast PDF loading/streaming
- [ ] Effective search results
- [ ] Seamless multi-device access

## üõ†Ô∏è Development Environment

### Required Tools

- Local web server for testing
- Firebase project with auth enabled
- Google Cloud project with Drive/Sheets APIs
- GitHub repository for deployment

### Key Files to Focus On

1. `Updates/firebase_auth_system (2).html` - Authentication
2. `Updates/library_interface.html` - Main UI
3. `library/js/GoogleDriveAuth.js` - Drive integration
4. `Scripts/System/GitHubAutoUpdate.py` - Deployment

## üí° Quick Wins Available Now

### 1. Demo Deployment (2 hours)

- Push current `index.html` to GitHub Pages
- Add library portal link to existing interface
- Show working authentication form

### 2. Book Collection Upload (4 hours)

- Organize 1,219 PDFs in Google Drive
- Create folder structure with proper permissions
- Test file access via Drive API

### 3. Basic Search (6 hours)

- Implement JavaScript search in library interface  
- Add category filtering from your existing data
- Create responsive book grid display

## üéØ The Vision Realized

When complete, users will:

1. **Register** via Firebase auth with admin approval
2. **Browse** 1,219+ books in categorized interface
3. **Search** across titles, authors, content with AI assistance
4. **Read** PDFs streamed directly from Google Drive
5. **Collaborate** through annotations and shared collections

## Next Conversation Focus

Let's discuss:

1. Which phase should we tackle first?
2. What's your comfort level with Firebase/Google Cloud setup?
3. Do you want to start with a simple demo or go straight to full features?
4. Any specific technical roadblocks you're facing
================
File: index.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Himalaya - BowersWorld.com</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            min-height: 100vh;
        }

        .header {
            background: linear-gradient(rgba(0,0,0,0.3), rgba(0,0,0,0.3));
            padding: 2rem 0;
            text-align: center;
            border-bottom: 2px solid rgba(255,255,255,0.1);
        }

        .sponsored {
            position: absolute;
            top: 10px;
            right: 20px;
            font-size: 0.8rem;
            opacity: 0.7;
        }

        .hero-image {
            width: 100%;
            max-width: 800px;
            height: 200px;
            background: linear-gradient(45deg, #4a90e2, #7b68ee);
            border-radius: 10px;
            margin: 0 auto 2rem;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }

        .hands {
            font-size: 4rem;
            display: flex;
            align-items: center;
            gap: 2rem;
        }

        .robot-hand { color: #ff6b6b; }
        .human-hand { color: #4ecdc4; }
        .connection { 
            color: #ffd93d; 
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }

        h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .description {
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        .section-title {
            text-align: center;
            font-size: 2rem;
            margin: 2rem 0;
            color: #a78bfa;
        }

        .cards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin-bottom: 2rem;
        }

        .card {
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            padding: 1.5rem;
            border: 1px solid rgba(255,255,255,0.2);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .card:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            border-color: rgba(255,255,255,0.3);
        }

        .card h3 {
            font-size: 1.3rem;
            margin-bottom: 0.5rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .card p {
            opacity: 0.8;
            line-height: 1.5;
        }

        /* Library Card Styling */
        .library-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: 2px solid #ffd93d;
            position: relative;
            overflow: hidden;
        }

        .library-card::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
            transform: rotate(45deg);
            animation: shine 3s infinite;
        }

        @keyframes shine {
            0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
            50% { transform: translateX(0%) translateY(0%) rotate(45deg); }
            100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
        }

        .library-card h3 {
            color: #ffd93d;
            font-size: 1.5rem;
        }

        .library-badge {
            background: #ffd93d;
            color: #1e3c72;
            padding: 0.3rem 0.8rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: bold;
        }

        .footer {
            text-align: center;
            padding: 2rem;
            border-top: 1px solid rgba(255,255,255,0.1);
            opacity: 0.7;
            font-size: 0.9rem;
        }

        .chevron {
            transition: transform 0.3s ease;
        }

        .card:hover .chevron {
            transform: translateX(5px);
        }

        .success-banner {
            background: rgba(76, 175, 80, 0.3);
            border: 1px solid #4CAF50;
            border-radius: 5px;
            padding: 1rem;
            margin: 1rem 0;
            text-align: center;
        }

        .live-indicator {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: rgba(76, 175, 80, 0.9);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.9rem;
            font-weight: bold;
            box-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }

        .live-indicator::before {
            content: 'üü¢';
            margin-right: 0.5rem;
        }
    </style>
</head>
<body>
    <div class="sponsored">Sponsored by BowersWorld.com</div>
    
    <header class="header">
        <div class="hero-image">
            <div class="hands">
                <span class="robot-hand">ü§ñ</span>
                <span class="connection">‚ú®</span>
                <span class="human-hand">üë§</span>
            </div>
        </div>
        
        <h1>Project Himalaya</h1>
        
        <div class="description">
            <p>Project Himalaya pioneers a new symbiotic partnership between humans and AI, transcending traditional models where AI serves merely as a tool. We envision AI and humans working together, each contributing unique strengths to achieve what neither could accomplish alone.</p>
            <br>
            <p>Our work focuses on developing methodologies, frameworks, and tools that enable seamless knowledge transfer between humans and AI agents. We address key challenges in building complex AI systems‚Äîmaintaining context across sessions, ensuring knowledge persistence, and facilitating effective communication. Together, we're creating a future where AI is not just a tool, but a true partner in human innovation.</p>
        </div>
    </header>

    <main class="container">
        <!-- Success Banner -->
        <div class="success-banner">
            <strong>üéâ GitHub Pages is now live!</strong> Your BowersWorld.com test site is successfully deployed.
        </div>

        <h2 class="section-title">Project Documentation</h2>
        
        <div class="cards-grid">
            <div class="card">
                <h3>
                    Navigation & Status
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Current project status, roadmap, and navigation tools for Project Himalaya development.</p>
            </div>

            <div class="card">
                <h3>
                    Project Vision
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Core philosophy and long-term goals for human-AI collaboration methodologies.</p>
            </div>

            <div class="card">
                <h3>
                    Standards
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>AIDEV-PascalCase-1.7 coding standards and development guidelines.</p>
            </div>

            <div class="card">
                <h3>
                    Templates
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Reusable code templates and project scaffolding tools.</p>
            </div>

            <div class="card">
                <h3>
                    Knowledge Organization
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Frameworks for organizing and transferring knowledge between human and AI collaborators.</p>
            </div>

            <div class="card">
                <h3>
                    Framework Implementation
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Technical implementation details and architectural patterns.</p>
            </div>

            <!-- NEW LIBRARY CARD -->
            <div class="card library-card" onclick="showLibraryInfo()">
                <h3>
                    Anderson's Digital Library
                    <span class="library-badge">NEW</span>
                </h3>
                <p>Access our comprehensive digital book collection. Browse, search, and read thousands of titles in our secure online library. <strong>Registration required.</strong></p>
            </div>
        </div>
    </main>

    <footer class="footer">
        <p>¬© 2025 Project Himalaya. All rights reserved. Sponsored by BowersWorld.com</p>
        <p style="margin-top: 0.5rem; font-size: 0.8rem; opacity: 0.6;">
            Test deployment: https://callmechewy.github.io/BowersWorld-com/
        </p>
    </footer>

    <!-- Live Indicator -->
    <div class="live-indicator">GitHub Pages Live</div>

    <script>
        function showLibraryInfo() {
            alert('üöß Anderson\'s Library - Coming Soon!\n\nThis digital library system is under development. Features will include:\n\nüìö Thousands of books\nüîç Advanced search\nüì± Mobile interface\nüîí User authentication\nüíæ Offline reading\n\nFull functionality available soon!');
        }

        // Add click handlers for existing cards (expandable sections)
        document.querySelectorAll('.card:not(.library-card)').forEach(card => {
            card.addEventListener('click', function() {
                const chevron = this.querySelector('.chevron');
                if (chevron) {
                    if (chevron.textContent === '‚ñº') {
                        chevron.textContent = '‚ñ≤';
                        // Add expansion logic here later
                    } else {
                        chevron.textContent = '‚ñº';
                        // Add collapse logic here later
                    }
                }
            });
        });

        // Development mode logging
        console.log('üöÄ BowersWorld.com - GitHub Pages Test Site');
        console.log('üìç Current URL:', window.location.href);
        console.log('‚úÖ Site successfully deployed!');
    </script>
</body>
</html>
================
File: library/auth/login.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Login - Anderson's Library</title>
</head>
<body style="background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); color: white; font-family: 'Segoe UI', sans-serif; min-height: 100vh; display: flex; align-items: center; justify-content: center;">
    <div style="background: rgba(255,255,255,0.1); padding: 2rem; border-radius: 10px; max-width: 400px; width: 90%; text-align: center;">
        <h1 style="color: #ffd93d; margin-bottom: 1rem;">üîê Login</h1>
        <p style="margin-bottom: 2rem;">Coming soon! Authentication system in development.</p>
        <a href="../" style="background: #ffd93d; color: #1e3c72; padding: 0.8rem 1.5rem; border-radius: 5px; text-decoration: none; font-weight: bold;">‚Üê Back to Library</a>
    </div>
</body>
</html>

================
File: library/auth/register.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Register - Anderson's Library</title>
</head>
<body style="background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); color: white; font-family: 'Segoe UI', sans-serif; min-height: 100vh; display: flex; align-items: center; justify-content: center;">
    <div style="background: rgba(255,255,255,0.1); padding: 2rem; border-radius: 10px; max-width: 400px; width: 90%; text-align: center;">
        <h1 style="color: #ffd93d; margin-bottom: 1rem;">üìù Registration</h1>
        <p style="margin-bottom: 2rem;">Coming soon! Registration system in development.</p>
        <a href="../" style="background: #ffd93d; color: #1e3c72; padding: 0.8rem 1.5rem; border-radius: 5px; text-decoration: none; font-weight: bold;">‚Üê Back to Library</a>
    </div>
</body>
</html>

================
File: library/index.html
================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Himalaya - BowersWorld.com</title>
    <link rel="stylesheet" href="shared/css/himalaya-theme.css">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            color: white;
            min-height: 100vh;
        }

        .header {
            background: linear-gradient(rgba(0,0,0,0.3), rgba(0,0,0,0.3)), 
                        url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1200 400"><path d="M0,400 C200,300 400,350 600,250 C800,150 1000,200 1200,100 L1200,400 Z" fill="%23ffffff10"/></svg>');
            background-size: cover;
            background-position: center;
            padding: 2rem 0;
            text-align: center;
            border-bottom: 2px solid rgba(255,255,255,0.1);
        }

        .sponsored {
            position: absolute;
            top: 10px;
            right: 20px;
            font-size: 0.8rem;
            opacity: 0.7;
        }

        .hero-image {
            width: 100%;
            max-width: 800px;
            height: 200px;
            background: linear-gradient(45deg, #4a90e2, #7b68ee);
            border-radius: 10px;
            margin: 0 auto 2rem;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }

        .hands {
            font-size: 4rem;
            display: flex;
            align-items: center;
            gap: 2rem;
        }

        .robot-hand { color: #ff6b6b; }
        .human-hand { color: #4ecdc4; }
        .connection { 
            color: #ffd93d; 
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; transform: scale(1); }
            50% { opacity: 0.7; transform: scale(1.1); }
        }

        h1 {
            font-size: 3rem;
            margin-bottom: 1rem;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .description {
            max-width: 800px;
            margin: 0 auto;
            line-height: 1.6;
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        .section-title {
            text-align: center;
            font-size: 2rem;
            margin: 2rem 0;
            color: #a78bfa;
        }

        .cards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 1.5rem;
            margin-bottom: 2rem;
        }

        .card {
            background: rgba(255,255,255,0.1);
            border-radius: 10px;
            padding: 1.5rem;
            border: 1px solid rgba(255,255,255,0.2);
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .card:hover {
            transform: translateY(-5px);
            background: rgba(255,255,255,0.15);
            border-color: rgba(255,255,255,0.3);
        }

        .card h3 {
            font-size: 1.3rem;
            margin-bottom: 0.5rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
        }

        .card-icon {
            font-size: 1.5rem;
        }

        .card p {
            opacity: 0.8;
            line-height: 1.5;
        }

        /* Library Card Styling */
        .library-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: 2px solid #ffd93d;
            position: relative;
            overflow: hidden;
        }

        .library-card::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: linear-gradient(45deg, transparent, rgba(255,255,255,0.1), transparent);
            transform: rotate(45deg);
            animation: shine 3s infinite;
        }

        @keyframes shine {
            0% { transform: translateX(-100%) translateY(-100%) rotate(45deg); }
            50% { transform: translateX(0%) translateY(0%) rotate(45deg); }
            100% { transform: translateX(100%) translateY(100%) rotate(45deg); }
        }

        .library-card h3 {
            color: #ffd93d;
            font-size: 1.5rem;
        }

        .library-badge {
            background: #ffd93d;
            color: #1e3c72;
            padding: 0.3rem 0.8rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: bold;
        }

        .footer {
            text-align: center;
            padding: 2rem;
            border-top: 1px solid rgba(255,255,255,0.1);
            opacity: 0.7;
            font-size: 0.9rem;
        }

        .chevron {
            transition: transform 0.3s ease;
        }

        .card:hover .chevron {
            transform: translateX(5px);
        }

        /* Modal styles */
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0,0,0,0.8);
            z-index: 1000;
        }

        .modal-content {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
            padding: 2rem;
            border-radius: 10px;
            border: 1px solid rgba(255,255,255,0.2);
            max-width: 400px;
            width: 90%;
        }

        .btn {
            background: #ffd93d;
            color: #1e3c72;
            border: none;
            padding: 0.8rem 1.5rem;
            border-radius: 5px;
            cursor: pointer;
            font-weight: bold;
            text-decoration: none;
            display: inline-block;
            margin: 0.5rem;
            transition: all 0.3s ease;
        }

        .btn:hover {
            background: #ffed4e;
            transform: translateY(-2px);
        }

        .btn-secondary {
            background: transparent;
            color: white;
            border: 1px solid white;
        }

        .btn-secondary:hover {
            background: rgba(255,255,255,0.1);
            color: white;
        }
    </style>
</head>
<body>
    <div class="sponsored">Sponsored by BowersWorld.com</div>
    
    <header class="header">
        <div class="hero-image">
            <div class="hands">
                <span class="robot-hand">ü§ñ</span>
                <span class="connection">‚ú®</span>
                <span class="human-hand">üë§</span>
            </div>
        </div>
        
        <h1>Project Himalaya</h1>
        
        <div class="description">
            <p>Project Himalaya pioneers a new symbiotic partnership between humans and AI, transcending traditional models where AI serves merely as a tool. We envision AI and humans working together, each contributing unique strengths to achieve what neither could accomplish alone.</p>
            <br>
            <p>Our work focuses on developing methodologies, frameworks, and tools that enable seamless knowledge transfer between humans and AI agents. We address key challenges in building complex AI systems‚Äîmaintaining context across sessions, ensuring knowledge persistence, and facilitating effective communication. Together, we're creating a future where AI is not just a tool, but a true partner in human innovation.</p>
        </div>
    </header>

    <main class="container">
        <h2 class="section-title">Project Documentation</h2>
        
        <div class="cards-grid">
            <div class="card">
                <h3>
                    Navigation & Status
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Current project status, roadmap, and navigation tools for Project Himalaya development.</p>
            </div>

            <div class="card">
                <h3>
                    Project Vision
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Core philosophy and long-term goals for human-AI collaboration methodologies.</p>
            </div>

            <div class="card">
                <h3>
                    Standards
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>AIDEV-PascalCase-1.7 coding standards and development guidelines.</p>
            </div>

            <div class="card">
                <h3>
                    Templates
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Reusable code templates and project scaffolding tools.</p>
            </div>

            <div class="card">
                <h3>
                    Knowledge Organization
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Frameworks for organizing and transferring knowledge between human and AI collaborators.</p>
            </div>

            <div class="card">
                <h3>
                    Framework Implementation
                    <span class="chevron">‚ñº</span>
                </h3>
                <p>Technical implementation details and architectural patterns.</p>
            </div>

            <!-- NEW LIBRARY CARD -->
            <div class="card library-card" onclick="openLibraryPortal()">
                <h3>
                    Anderson's Digital Library
                    <span class="library-badge">NEW</span>
                </h3>
                <p>Access our comprehensive digital book collection. Browse, search, and read thousands of titles in our secure online library. <strong>Registration required.</strong></p>
            </div>
        </div>
    </main>

    <footer class="footer">
        <p>¬© 2025 Project Himalaya. All rights reserved. Sponsored by BowersWorld.com</p>
    </footer>

    <!-- Library Portal Modal -->
    <div id="libraryModal" class="modal">
        <div class="modal-content">
            <h3 style="margin-bottom: 1rem; color: #ffd93d;">üìö Anderson's Digital Library</h3>
            <p style="margin-bottom: 1rem;">Welcome to our comprehensive digital book collection! Access requires registration and approval.</p>
            
            <div style="margin-bottom: 1.5rem;">
                <strong>Library Features:</strong><br>
                ‚Ä¢ Thousands of books across multiple categories<br>
                ‚Ä¢ Advanced search and filtering<br>
                ‚Ä¢ Secure user authentication<br>
                ‚Ä¢ Mobile-friendly interface
            </div>
            
            <a href="library/" class="btn">Enter Library Portal</a>
            <button onclick="closeModal()" class="btn btn-secondary">Close</button>
        </div>
    </div>

    <script>
        function openLibraryPortal() {
            document.getElementById('libraryModal').style.display = 'block';
        }

        function closeModal() {
            document.getElementById('libraryModal').style.display = 'none';
        }

        // Close modal when clicking outside
        window.onclick = function(event) {
            const modal = document.getElementById('libraryModal');
            if (event.target === modal) {
                modal.style.display = 'none';
            }
        }

        // Add click handlers for existing cards (expandable sections)
        document.querySelectorAll('.card:not(.library-card)').forEach(card => {
            card.addEventListener('click', function() {
                const chevron = this.querySelector('.chevron');
                if (chevron.textContent === '‚ñº') {
                    chevron.textContent = '‚ñ≤';
                    // Add expansion logic here later
                } else {
                    chevron.textContent = '‚ñº';
                    // Add collapse logic here later
                }
            });
        });

        // Development mode indicator
        if (window.location.hostname.includes('github.io')) {
            console.log('üöÄ Running on GitHub Pages test environment');
            console.log('üîß Development mode: All features may not be fully functional');
        }
    </script>
</body>
</html>
================
File: requirements.txt
================
annotated-types==0.7.0
anyio==4.9.0
black==25.1.0
blis==1.3.0
catalogue==2.0.10
certifi==2025.6.15
cffi==1.17.1
charset-normalizer==3.4.2
click==8.2.1
cloudpathlib==0.21.1
confection==0.1.5
contourpy==1.3.2
cryptography==45.0.5
cycler==0.12.1
cymem==2.0.11
et_xmlfile==2.0.0
fastapi==0.115.14
filelock==3.18.0
flake8==7.3.0
fonttools==4.58.4
fsspec==2025.5.1
greenlet==3.2.3
h11==0.16.0
hf-xet==1.1.5
httptools==0.6.4
huggingface-hub==0.33.1
idna==3.10
iniconfig==2.1.0
Jinja2==3.1.6
joblib==1.5.1
kiwisolver==1.4.8
langcodes==3.5.0
language_data==1.3.0
llvmlite==0.44.0
marisa-trie==1.2.1
markdown-it-py==3.0.0
MarkupSafe==3.0.2
matplotlib==3.10.3
mccabe==0.7.0
mdurl==0.1.2
mpmath==1.3.0
murmurhash==1.0.13
mypy_extensions==1.1.0
networkx==3.5
numba==0.61.2
numpy==2.2.6
nvidia-cublas-cu12==12.6.4.1
nvidia-cuda-cupti-cu12==12.6.80
nvidia-cuda-nvrtc-cu12==12.6.77
nvidia-cuda-runtime-cu12==12.6.77
nvidia-cudnn-cu12==9.5.1.17
nvidia-cufft-cu12==11.3.0.4
nvidia-cufile-cu12==1.11.1.6
nvidia-curand-cu12==10.3.7.77
nvidia-cusolver-cu12==11.7.1.2
nvidia-cusparse-cu12==12.5.4.2
nvidia-cusparselt-cu12==0.6.3
nvidia-nccl-cu12==2.26.2
nvidia-nvjitlink-cu12==12.6.85
nvidia-nvtx-cu12==12.6.77
opencv-python==4.11.0.86
openpyxl==3.1.5
packaging==25.0
pandas==2.3.0
pathspec==0.12.1
pdf2image==1.17.0
pdfminer.six==20250506
pdfplumber==0.11.7
pillow==11.2.1
platformdirs==4.3.8
pluggy==1.6.0
preshed==3.0.10
pu==0.20.1
pycodestyle==2.14.0
pycparser==2.22
pydantic==2.11.7
pydantic_core==2.33.2
pyflakes==3.4.0
pygame==2.6.1
Pygments==2.19.2
PyMuPDF==1.26.1
pyparsing==3.2.3
PyPDF2==3.0.1
pypdfium2==4.30.1
pytesseract==0.3.13
pytest==8.4.1
python-dateutil==2.9.0.post0
python-dotenv==1.1.1
pytz==2025.2
PyYAML==6.0.2
regex==2024.11.6
requests==2.32.4
rich==14.0.0
safetensors==0.5.3
scikit-learn==1.7.0
scipy==1.16.0
seaborn==0.13.2
sentence-transformers==4.1.0
shellingham==1.5.4
six==1.17.0
smart-open==7.1.0
sniffio==1.3.1
spacy==3.8.7
spacy-legacy==3.0.12
spacy-loggers==1.0.5
SQLAlchemy==2.0.41
srsly==2.5.1
starlette==0.46.2
sympy==1.14.0
thinc==8.3.6
threadpoolctl==3.6.0
tokenizers==0.21.2
torch==2.7.1
tqdm==4.67.1
transformers==4.53.0
triton==3.3.1
typer==0.16.0
typing-inspection==0.4.1
typing_extensions==4.14.0
tzdata==2025.2
urllib3==2.5.0
uvicorn==0.34.3
uvloop==0.21.0
wasabi==1.1.3
watchfiles==1.1.0
weasel==0.4.1
websockets==15.0.1
wrapt==1.17.2


================================================================
List of Included Files
================================================================

Files included:
AGENTS.md
CLAUDE.md
CreateLibraryCSV/Complete Anderson's Library Collection Analysis.py
CreateLibraryCSV/DigitalAlexandria.py
CreateLibraryCSV/Resumable PDF Metadata Extractor.py
CreateThumbs/ConvertToThumbnails.py
CreateThumbs/ConvertToThumbnailsPart2.py
HIMALAYA PROGRESS REPORT.md
HTML/GoogleAuthorzeTest.html
HimalayaGPUExtractor_Protected.py
MigrateToEnhancedSchema.py
README.md
Scripts/Development/BowersWorldSetup.py
Scripts/System/CodebaseSum.py
Scripts/System/GPU OCR Speed Test.py
Scripts/System/GitHubAutoUpdate.py
Scripts/System/GitHubUpdateSite.py
Scripts/System/ListFilesByDate.py
Scripts/System/MarkdownToText.py
Scripts/System/Project_Backup.py
Scripts/System/UpdateFiles.py
Updates/..Old/firebase_auth_system (1).html
Updates/..Old/firebase_auth_system (2).html
Updates/..Old/firebase_auth_system.html
Updates/..Old/library_interface.html
Updates/..Old/local_server_setup.sh
Updates/..Old/quick_config_guide.html
Updates/next_steps_plan.md
index.html
library/auth/login.html
library/auth/register.html
library/index.html
requirements.txt

There are 33 files included in the Files section of the CodebaseSummary document.
